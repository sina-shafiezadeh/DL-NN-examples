{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Task\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C3y6hyL8pUUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcFlSrX2chRT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1' #force Environment variable to synchronous computation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, SubsetRandomSampler\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P regression_dataset https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/train_data.csv\n",
        "!wget -P regression_dataset https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/test_data.csv "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkVzdSEXK2S-",
        "outputId": "94fcd02d-15d7-444f-cfa8-85ed9719e7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-22 10:12:19--  https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/train_data.csv\n",
            "Resolving gitlab.dei.unipd.it (gitlab.dei.unipd.it)... 147.162.2.85\n",
            "Connecting to gitlab.dei.unipd.it (gitlab.dei.unipd.it)|147.162.2.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3776 (3.7K) [text/plain]\n",
            "Saving to: ‘regression_dataset/train_data.csv’\n",
            "\n",
            "train_data.csv      100%[===================>]   3.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-22 10:12:19 (46.3 MB/s) - ‘regression_dataset/train_data.csv’ saved [3776/3776]\n",
            "\n",
            "--2022-08-22 10:12:19--  https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/test_data.csv\n",
            "Resolving gitlab.dei.unipd.it (gitlab.dei.unipd.it)... 147.162.2.85\n",
            "Connecting to gitlab.dei.unipd.it (gitlab.dei.unipd.it)|147.162.2.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3788 (3.7K) [text/plain]\n",
            "Saving to: ‘regression_dataset/test_data.csv’\n",
            "\n",
            "test_data.csv       100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-22 10:12:19 (84.9 MB/s) - ‘regression_dataset/test_data.csv’ saved [3788/3788]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CsvDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.transform = transform\n",
        "        # Read the file and split the lines in a list\n",
        "        with open(csv_file, 'r') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "        # Get x and y values from each line and append to self.data\n",
        "        self.data = []\n",
        "        for line in lines[1:-1]:\n",
        "            sample = line.split(',')\n",
        "            self.data.append((float(sample[0]), float(sample[1])))\n",
        "        # Now self.data contains all our dataset.\n",
        "        # Each element of the list self.data is a tuple: (input, output)\n",
        "\n",
        "    def __len__(self):\n",
        "        # The length of the dataset is simply the length of the self.data list\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Our sample is the element idx of the list self.data\n",
        "        sample = self.data[idx]\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample"
      ],
      "metadata": {
        "id": "zIAJmAklO0-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "    \"\"\"Convert sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        x, y = sample\n",
        "        return (torch.tensor([x]).float(),\n",
        "                torch.tensor([y]).float())"
      ],
      "metadata": {
        "id": "925EypjEO4wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composed_transform = transforms.Compose([ToTensor()])\n",
        "\n",
        "train_dataset = CsvDataset('regression_dataset/train_data.csv', transform=composed_transform)\n",
        "test_dataset = CsvDataset('regression_dataset/test_data.csv', transform=composed_transform)"
      ],
      "metadata": {
        "id": "YXbN0qrdO6_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=1, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=256)\n",
        "        self.out = nn.Linear(in_features=256, out_features=1)\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = self.act(self.fc1(x))\n",
        "        x = self.act(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "rMPIBIGpuRyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "dataset = ConcatDataset([train_dataset, test_dataset])\n",
        "\n",
        "num_epochs=3000\n",
        "batch_size=32\n",
        "k=5\n",
        "splits=KFold(n_splits=k,shuffle=True,random_state=42)"
      ],
      "metadata": {
        "id": "_aOZyQmO-55m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foldperf={}\n",
        "\n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "  print('Fold {}'.format(fold + 1))\n",
        "\n",
        "  train_sampler = SubsetRandomSampler(train_idx)\n",
        "  test_sampler = SubsetRandomSampler(val_idx)\n",
        "  train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "  test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "  \n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "  model = ConvNet()\n",
        "  model.to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "  history = {'train_loss': [], 'test_loss': []}\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for data, labels in train_loader:\n",
        "      data,labels = data.to(device),labels.to(device)\n",
        "      output = model(data)\n",
        "      loss = criterion(output,labels)\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss = loss.detach().cpu().numpy()\n",
        "\n",
        "    model.eval()\n",
        "    for data, labels in test_loader:\n",
        "      data,labels = data.to(device),labels.to(device)\n",
        "      output = model(data)\n",
        "      loss=criterion(output,labels)\n",
        "      test_loss = loss.detach().cpu().numpy()\n",
        "\n",
        "    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f}\".format(epoch + 1, num_epochs, train_loss, test_loss))\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    \n",
        "  foldperf['fold{}'.format(fold+1)] = history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXbUZ3W-5--",
        "outputId": "94ef2f14-a50b-407c-d13d-da62ff1692fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch:1002/3000 AVG Training Loss:0.192 AVG Test Loss:0.175\n",
            "Epoch:1003/3000 AVG Training Loss:0.109 AVG Test Loss:0.440\n",
            "Epoch:1004/3000 AVG Training Loss:0.186 AVG Test Loss:0.230\n",
            "Epoch:1005/3000 AVG Training Loss:0.167 AVG Test Loss:0.081\n",
            "Epoch:1006/3000 AVG Training Loss:0.174 AVG Test Loss:0.185\n",
            "Epoch:1007/3000 AVG Training Loss:0.115 AVG Test Loss:0.186\n",
            "Epoch:1008/3000 AVG Training Loss:0.142 AVG Test Loss:0.162\n",
            "Epoch:1009/3000 AVG Training Loss:0.143 AVG Test Loss:0.313\n",
            "Epoch:1010/3000 AVG Training Loss:0.116 AVG Test Loss:0.260\n",
            "Epoch:1011/3000 AVG Training Loss:0.241 AVG Test Loss:0.271\n",
            "Epoch:1012/3000 AVG Training Loss:0.145 AVG Test Loss:0.287\n",
            "Epoch:1013/3000 AVG Training Loss:0.169 AVG Test Loss:0.208\n",
            "Epoch:1014/3000 AVG Training Loss:0.257 AVG Test Loss:0.155\n",
            "Epoch:1015/3000 AVG Training Loss:0.163 AVG Test Loss:0.278\n",
            "Epoch:1016/3000 AVG Training Loss:0.148 AVG Test Loss:0.405\n",
            "Epoch:1017/3000 AVG Training Loss:0.237 AVG Test Loss:0.207\n",
            "Epoch:1018/3000 AVG Training Loss:0.104 AVG Test Loss:0.127\n",
            "Epoch:1019/3000 AVG Training Loss:0.173 AVG Test Loss:0.201\n",
            "Epoch:1020/3000 AVG Training Loss:0.220 AVG Test Loss:0.183\n",
            "Epoch:1021/3000 AVG Training Loss:0.217 AVG Test Loss:0.256\n",
            "Epoch:1022/3000 AVG Training Loss:0.312 AVG Test Loss:0.161\n",
            "Epoch:1023/3000 AVG Training Loss:0.276 AVG Test Loss:0.145\n",
            "Epoch:1024/3000 AVG Training Loss:0.272 AVG Test Loss:0.176\n",
            "Epoch:1025/3000 AVG Training Loss:0.452 AVG Test Loss:0.060\n",
            "Epoch:1026/3000 AVG Training Loss:0.214 AVG Test Loss:0.173\n",
            "Epoch:1027/3000 AVG Training Loss:0.250 AVG Test Loss:0.363\n",
            "Epoch:1028/3000 AVG Training Loss:0.167 AVG Test Loss:0.167\n",
            "Epoch:1029/3000 AVG Training Loss:0.216 AVG Test Loss:0.166\n",
            "Epoch:1030/3000 AVG Training Loss:0.179 AVG Test Loss:0.182\n",
            "Epoch:1031/3000 AVG Training Loss:0.165 AVG Test Loss:0.264\n",
            "Epoch:1032/3000 AVG Training Loss:0.160 AVG Test Loss:0.299\n",
            "Epoch:1033/3000 AVG Training Loss:0.169 AVG Test Loss:0.152\n",
            "Epoch:1034/3000 AVG Training Loss:0.125 AVG Test Loss:0.437\n",
            "Epoch:1035/3000 AVG Training Loss:0.156 AVG Test Loss:0.217\n",
            "Epoch:1036/3000 AVG Training Loss:0.138 AVG Test Loss:0.192\n",
            "Epoch:1037/3000 AVG Training Loss:0.200 AVG Test Loss:0.182\n",
            "Epoch:1038/3000 AVG Training Loss:0.138 AVG Test Loss:0.247\n",
            "Epoch:1039/3000 AVG Training Loss:0.195 AVG Test Loss:0.201\n",
            "Epoch:1040/3000 AVG Training Loss:0.165 AVG Test Loss:0.210\n",
            "Epoch:1041/3000 AVG Training Loss:0.166 AVG Test Loss:0.166\n",
            "Epoch:1042/3000 AVG Training Loss:0.163 AVG Test Loss:0.141\n",
            "Epoch:1043/3000 AVG Training Loss:0.216 AVG Test Loss:0.151\n",
            "Epoch:1044/3000 AVG Training Loss:0.138 AVG Test Loss:0.416\n",
            "Epoch:1045/3000 AVG Training Loss:0.128 AVG Test Loss:0.341\n",
            "Epoch:1046/3000 AVG Training Loss:0.288 AVG Test Loss:0.343\n",
            "Epoch:1047/3000 AVG Training Loss:0.218 AVG Test Loss:0.214\n",
            "Epoch:1048/3000 AVG Training Loss:0.125 AVG Test Loss:0.250\n",
            "Epoch:1049/3000 AVG Training Loss:0.266 AVG Test Loss:0.108\n",
            "Epoch:1050/3000 AVG Training Loss:0.299 AVG Test Loss:0.239\n",
            "Epoch:1051/3000 AVG Training Loss:0.206 AVG Test Loss:0.254\n",
            "Epoch:1052/3000 AVG Training Loss:0.194 AVG Test Loss:0.193\n",
            "Epoch:1053/3000 AVG Training Loss:0.110 AVG Test Loss:0.279\n",
            "Epoch:1054/3000 AVG Training Loss:0.157 AVG Test Loss:0.312\n",
            "Epoch:1055/3000 AVG Training Loss:0.183 AVG Test Loss:0.185\n",
            "Epoch:1056/3000 AVG Training Loss:0.251 AVG Test Loss:0.173\n",
            "Epoch:1057/3000 AVG Training Loss:0.178 AVG Test Loss:0.260\n",
            "Epoch:1058/3000 AVG Training Loss:0.207 AVG Test Loss:0.165\n",
            "Epoch:1059/3000 AVG Training Loss:0.187 AVG Test Loss:0.166\n",
            "Epoch:1060/3000 AVG Training Loss:0.147 AVG Test Loss:0.274\n",
            "Epoch:1061/3000 AVG Training Loss:0.208 AVG Test Loss:0.238\n",
            "Epoch:1062/3000 AVG Training Loss:0.152 AVG Test Loss:0.113\n",
            "Epoch:1063/3000 AVG Training Loss:0.262 AVG Test Loss:0.266\n",
            "Epoch:1064/3000 AVG Training Loss:0.236 AVG Test Loss:0.208\n",
            "Epoch:1065/3000 AVG Training Loss:0.213 AVG Test Loss:0.132\n",
            "Epoch:1066/3000 AVG Training Loss:0.218 AVG Test Loss:0.263\n",
            "Epoch:1067/3000 AVG Training Loss:0.157 AVG Test Loss:0.259\n",
            "Epoch:1068/3000 AVG Training Loss:0.207 AVG Test Loss:0.182\n",
            "Epoch:1069/3000 AVG Training Loss:0.175 AVG Test Loss:0.266\n",
            "Epoch:1070/3000 AVG Training Loss:0.176 AVG Test Loss:0.177\n",
            "Epoch:1071/3000 AVG Training Loss:0.308 AVG Test Loss:0.404\n",
            "Epoch:1072/3000 AVG Training Loss:0.153 AVG Test Loss:0.049\n",
            "Epoch:1073/3000 AVG Training Loss:0.187 AVG Test Loss:0.253\n",
            "Epoch:1074/3000 AVG Training Loss:0.110 AVG Test Loss:0.227\n",
            "Epoch:1075/3000 AVG Training Loss:0.247 AVG Test Loss:0.224\n",
            "Epoch:1076/3000 AVG Training Loss:0.111 AVG Test Loss:0.393\n",
            "Epoch:1077/3000 AVG Training Loss:0.209 AVG Test Loss:0.303\n",
            "Epoch:1078/3000 AVG Training Loss:0.125 AVG Test Loss:0.161\n",
            "Epoch:1079/3000 AVG Training Loss:0.205 AVG Test Loss:0.151\n",
            "Epoch:1080/3000 AVG Training Loss:0.364 AVG Test Loss:0.098\n",
            "Epoch:1081/3000 AVG Training Loss:0.147 AVG Test Loss:0.109\n",
            "Epoch:1082/3000 AVG Training Loss:0.178 AVG Test Loss:0.275\n",
            "Epoch:1083/3000 AVG Training Loss:0.189 AVG Test Loss:0.241\n",
            "Epoch:1084/3000 AVG Training Loss:0.175 AVG Test Loss:0.169\n",
            "Epoch:1085/3000 AVG Training Loss:0.231 AVG Test Loss:0.140\n",
            "Epoch:1086/3000 AVG Training Loss:0.210 AVG Test Loss:0.174\n",
            "Epoch:1087/3000 AVG Training Loss:0.290 AVG Test Loss:0.245\n",
            "Epoch:1088/3000 AVG Training Loss:0.171 AVG Test Loss:0.187\n",
            "Epoch:1089/3000 AVG Training Loss:0.148 AVG Test Loss:0.363\n",
            "Epoch:1090/3000 AVG Training Loss:0.278 AVG Test Loss:0.273\n",
            "Epoch:1091/3000 AVG Training Loss:0.171 AVG Test Loss:0.251\n",
            "Epoch:1092/3000 AVG Training Loss:0.261 AVG Test Loss:0.359\n",
            "Epoch:1093/3000 AVG Training Loss:0.241 AVG Test Loss:0.236\n",
            "Epoch:1094/3000 AVG Training Loss:0.166 AVG Test Loss:0.190\n",
            "Epoch:1095/3000 AVG Training Loss:0.171 AVG Test Loss:0.194\n",
            "Epoch:1096/3000 AVG Training Loss:0.249 AVG Test Loss:0.080\n",
            "Epoch:1097/3000 AVG Training Loss:0.168 AVG Test Loss:0.272\n",
            "Epoch:1098/3000 AVG Training Loss:0.200 AVG Test Loss:0.170\n",
            "Epoch:1099/3000 AVG Training Loss:0.218 AVG Test Loss:0.219\n",
            "Epoch:1100/3000 AVG Training Loss:0.170 AVG Test Loss:0.528\n",
            "Epoch:1101/3000 AVG Training Loss:0.152 AVG Test Loss:0.208\n",
            "Epoch:1102/3000 AVG Training Loss:0.146 AVG Test Loss:0.347\n",
            "Epoch:1103/3000 AVG Training Loss:0.128 AVG Test Loss:0.200\n",
            "Epoch:1104/3000 AVG Training Loss:0.187 AVG Test Loss:0.072\n",
            "Epoch:1105/3000 AVG Training Loss:0.220 AVG Test Loss:0.127\n",
            "Epoch:1106/3000 AVG Training Loss:0.153 AVG Test Loss:0.248\n",
            "Epoch:1107/3000 AVG Training Loss:0.103 AVG Test Loss:0.067\n",
            "Epoch:1108/3000 AVG Training Loss:0.189 AVG Test Loss:0.171\n",
            "Epoch:1109/3000 AVG Training Loss:0.173 AVG Test Loss:0.129\n",
            "Epoch:1110/3000 AVG Training Loss:0.173 AVG Test Loss:0.345\n",
            "Epoch:1111/3000 AVG Training Loss:0.362 AVG Test Loss:0.203\n",
            "Epoch:1112/3000 AVG Training Loss:0.155 AVG Test Loss:0.142\n",
            "Epoch:1113/3000 AVG Training Loss:0.264 AVG Test Loss:0.162\n",
            "Epoch:1114/3000 AVG Training Loss:0.190 AVG Test Loss:0.281\n",
            "Epoch:1115/3000 AVG Training Loss:0.182 AVG Test Loss:0.129\n",
            "Epoch:1116/3000 AVG Training Loss:0.158 AVG Test Loss:0.191\n",
            "Epoch:1117/3000 AVG Training Loss:0.282 AVG Test Loss:0.546\n",
            "Epoch:1118/3000 AVG Training Loss:0.220 AVG Test Loss:0.113\n",
            "Epoch:1119/3000 AVG Training Loss:0.162 AVG Test Loss:0.122\n",
            "Epoch:1120/3000 AVG Training Loss:0.233 AVG Test Loss:0.244\n",
            "Epoch:1121/3000 AVG Training Loss:0.196 AVG Test Loss:0.139\n",
            "Epoch:1122/3000 AVG Training Loss:0.226 AVG Test Loss:0.175\n",
            "Epoch:1123/3000 AVG Training Loss:0.180 AVG Test Loss:0.270\n",
            "Epoch:1124/3000 AVG Training Loss:0.200 AVG Test Loss:0.128\n",
            "Epoch:1125/3000 AVG Training Loss:0.187 AVG Test Loss:0.113\n",
            "Epoch:1126/3000 AVG Training Loss:0.130 AVG Test Loss:0.109\n",
            "Epoch:1127/3000 AVG Training Loss:0.248 AVG Test Loss:0.206\n",
            "Epoch:1128/3000 AVG Training Loss:0.141 AVG Test Loss:0.275\n",
            "Epoch:1129/3000 AVG Training Loss:0.173 AVG Test Loss:0.195\n",
            "Epoch:1130/3000 AVG Training Loss:0.171 AVG Test Loss:0.224\n",
            "Epoch:1131/3000 AVG Training Loss:0.089 AVG Test Loss:0.231\n",
            "Epoch:1132/3000 AVG Training Loss:0.154 AVG Test Loss:0.352\n",
            "Epoch:1133/3000 AVG Training Loss:0.125 AVG Test Loss:0.188\n",
            "Epoch:1134/3000 AVG Training Loss:0.146 AVG Test Loss:0.127\n",
            "Epoch:1135/3000 AVG Training Loss:0.122 AVG Test Loss:0.102\n",
            "Epoch:1136/3000 AVG Training Loss:0.299 AVG Test Loss:0.182\n",
            "Epoch:1137/3000 AVG Training Loss:0.194 AVG Test Loss:0.154\n",
            "Epoch:1138/3000 AVG Training Loss:0.134 AVG Test Loss:0.222\n",
            "Epoch:1139/3000 AVG Training Loss:0.188 AVG Test Loss:0.181\n",
            "Epoch:1140/3000 AVG Training Loss:0.176 AVG Test Loss:0.153\n",
            "Epoch:1141/3000 AVG Training Loss:0.179 AVG Test Loss:0.164\n",
            "Epoch:1142/3000 AVG Training Loss:0.112 AVG Test Loss:0.140\n",
            "Epoch:1143/3000 AVG Training Loss:0.203 AVG Test Loss:0.223\n",
            "Epoch:1144/3000 AVG Training Loss:0.145 AVG Test Loss:0.243\n",
            "Epoch:1145/3000 AVG Training Loss:0.226 AVG Test Loss:0.056\n",
            "Epoch:1146/3000 AVG Training Loss:0.116 AVG Test Loss:0.256\n",
            "Epoch:1147/3000 AVG Training Loss:0.122 AVG Test Loss:0.351\n",
            "Epoch:1148/3000 AVG Training Loss:0.149 AVG Test Loss:0.276\n",
            "Epoch:1149/3000 AVG Training Loss:0.134 AVG Test Loss:0.308\n",
            "Epoch:1150/3000 AVG Training Loss:0.274 AVG Test Loss:0.395\n",
            "Epoch:1151/3000 AVG Training Loss:0.249 AVG Test Loss:0.088\n",
            "Epoch:1152/3000 AVG Training Loss:0.169 AVG Test Loss:0.278\n",
            "Epoch:1153/3000 AVG Training Loss:0.182 AVG Test Loss:0.141\n",
            "Epoch:1154/3000 AVG Training Loss:0.142 AVG Test Loss:0.260\n",
            "Epoch:1155/3000 AVG Training Loss:0.268 AVG Test Loss:0.227\n",
            "Epoch:1156/3000 AVG Training Loss:0.184 AVG Test Loss:0.379\n",
            "Epoch:1157/3000 AVG Training Loss:0.142 AVG Test Loss:0.355\n",
            "Epoch:1158/3000 AVG Training Loss:0.148 AVG Test Loss:0.302\n",
            "Epoch:1159/3000 AVG Training Loss:0.243 AVG Test Loss:0.172\n",
            "Epoch:1160/3000 AVG Training Loss:0.259 AVG Test Loss:0.094\n",
            "Epoch:1161/3000 AVG Training Loss:0.159 AVG Test Loss:0.391\n",
            "Epoch:1162/3000 AVG Training Loss:0.209 AVG Test Loss:0.300\n",
            "Epoch:1163/3000 AVG Training Loss:0.105 AVG Test Loss:0.277\n",
            "Epoch:1164/3000 AVG Training Loss:0.128 AVG Test Loss:0.274\n",
            "Epoch:1165/3000 AVG Training Loss:0.212 AVG Test Loss:0.234\n",
            "Epoch:1166/3000 AVG Training Loss:0.153 AVG Test Loss:0.313\n",
            "Epoch:1167/3000 AVG Training Loss:0.217 AVG Test Loss:0.185\n",
            "Epoch:1168/3000 AVG Training Loss:0.167 AVG Test Loss:0.263\n",
            "Epoch:1169/3000 AVG Training Loss:0.258 AVG Test Loss:0.135\n",
            "Epoch:1170/3000 AVG Training Loss:0.116 AVG Test Loss:0.148\n",
            "Epoch:1171/3000 AVG Training Loss:0.152 AVG Test Loss:0.304\n",
            "Epoch:1172/3000 AVG Training Loss:0.124 AVG Test Loss:0.283\n",
            "Epoch:1173/3000 AVG Training Loss:0.194 AVG Test Loss:0.247\n",
            "Epoch:1174/3000 AVG Training Loss:0.243 AVG Test Loss:0.318\n",
            "Epoch:1175/3000 AVG Training Loss:0.147 AVG Test Loss:0.125\n",
            "Epoch:1176/3000 AVG Training Loss:0.223 AVG Test Loss:0.123\n",
            "Epoch:1177/3000 AVG Training Loss:0.175 AVG Test Loss:0.114\n",
            "Epoch:1178/3000 AVG Training Loss:0.174 AVG Test Loss:0.192\n",
            "Epoch:1179/3000 AVG Training Loss:0.086 AVG Test Loss:0.233\n",
            "Epoch:1180/3000 AVG Training Loss:0.142 AVG Test Loss:0.262\n",
            "Epoch:1181/3000 AVG Training Loss:0.215 AVG Test Loss:0.093\n",
            "Epoch:1182/3000 AVG Training Loss:0.100 AVG Test Loss:0.135\n",
            "Epoch:1183/3000 AVG Training Loss:0.182 AVG Test Loss:0.211\n",
            "Epoch:1184/3000 AVG Training Loss:0.231 AVG Test Loss:0.178\n",
            "Epoch:1185/3000 AVG Training Loss:0.207 AVG Test Loss:0.186\n",
            "Epoch:1186/3000 AVG Training Loss:0.080 AVG Test Loss:0.247\n",
            "Epoch:1187/3000 AVG Training Loss:0.097 AVG Test Loss:0.201\n",
            "Epoch:1188/3000 AVG Training Loss:0.187 AVG Test Loss:0.238\n",
            "Epoch:1189/3000 AVG Training Loss:0.206 AVG Test Loss:0.354\n",
            "Epoch:1190/3000 AVG Training Loss:0.201 AVG Test Loss:0.323\n",
            "Epoch:1191/3000 AVG Training Loss:0.181 AVG Test Loss:0.031\n",
            "Epoch:1192/3000 AVG Training Loss:0.105 AVG Test Loss:0.205\n",
            "Epoch:1193/3000 AVG Training Loss:0.164 AVG Test Loss:0.220\n",
            "Epoch:1194/3000 AVG Training Loss:0.146 AVG Test Loss:0.112\n",
            "Epoch:1195/3000 AVG Training Loss:0.121 AVG Test Loss:0.400\n",
            "Epoch:1196/3000 AVG Training Loss:0.240 AVG Test Loss:0.121\n",
            "Epoch:1197/3000 AVG Training Loss:0.321 AVG Test Loss:0.114\n",
            "Epoch:1198/3000 AVG Training Loss:0.159 AVG Test Loss:0.244\n",
            "Epoch:1199/3000 AVG Training Loss:0.186 AVG Test Loss:0.348\n",
            "Epoch:1200/3000 AVG Training Loss:0.137 AVG Test Loss:0.261\n",
            "Epoch:1201/3000 AVG Training Loss:0.222 AVG Test Loss:0.298\n",
            "Epoch:1202/3000 AVG Training Loss:0.140 AVG Test Loss:0.317\n",
            "Epoch:1203/3000 AVG Training Loss:0.158 AVG Test Loss:0.205\n",
            "Epoch:1204/3000 AVG Training Loss:0.120 AVG Test Loss:0.109\n",
            "Epoch:1205/3000 AVG Training Loss:0.214 AVG Test Loss:0.161\n",
            "Epoch:1206/3000 AVG Training Loss:0.121 AVG Test Loss:0.112\n",
            "Epoch:1207/3000 AVG Training Loss:0.196 AVG Test Loss:0.168\n",
            "Epoch:1208/3000 AVG Training Loss:0.168 AVG Test Loss:0.209\n",
            "Epoch:1209/3000 AVG Training Loss:0.176 AVG Test Loss:0.136\n",
            "Epoch:1210/3000 AVG Training Loss:0.198 AVG Test Loss:0.251\n",
            "Epoch:1211/3000 AVG Training Loss:0.254 AVG Test Loss:0.414\n",
            "Epoch:1212/3000 AVG Training Loss:0.278 AVG Test Loss:0.197\n",
            "Epoch:1213/3000 AVG Training Loss:0.137 AVG Test Loss:0.270\n",
            "Epoch:1214/3000 AVG Training Loss:0.249 AVG Test Loss:0.209\n",
            "Epoch:1215/3000 AVG Training Loss:0.174 AVG Test Loss:0.122\n",
            "Epoch:1216/3000 AVG Training Loss:0.146 AVG Test Loss:0.065\n",
            "Epoch:1217/3000 AVG Training Loss:0.110 AVG Test Loss:0.085\n",
            "Epoch:1218/3000 AVG Training Loss:0.162 AVG Test Loss:0.132\n",
            "Epoch:1219/3000 AVG Training Loss:0.189 AVG Test Loss:0.195\n",
            "Epoch:1220/3000 AVG Training Loss:0.189 AVG Test Loss:0.077\n",
            "Epoch:1221/3000 AVG Training Loss:0.102 AVG Test Loss:0.151\n",
            "Epoch:1222/3000 AVG Training Loss:0.193 AVG Test Loss:0.155\n",
            "Epoch:1223/3000 AVG Training Loss:0.194 AVG Test Loss:0.295\n",
            "Epoch:1224/3000 AVG Training Loss:0.187 AVG Test Loss:0.180\n",
            "Epoch:1225/3000 AVG Training Loss:0.166 AVG Test Loss:0.519\n",
            "Epoch:1226/3000 AVG Training Loss:0.202 AVG Test Loss:0.221\n",
            "Epoch:1227/3000 AVG Training Loss:0.139 AVG Test Loss:0.196\n",
            "Epoch:1228/3000 AVG Training Loss:0.137 AVG Test Loss:0.170\n",
            "Epoch:1229/3000 AVG Training Loss:0.184 AVG Test Loss:0.147\n",
            "Epoch:1230/3000 AVG Training Loss:0.293 AVG Test Loss:0.128\n",
            "Epoch:1231/3000 AVG Training Loss:0.141 AVG Test Loss:0.202\n",
            "Epoch:1232/3000 AVG Training Loss:0.215 AVG Test Loss:0.143\n",
            "Epoch:1233/3000 AVG Training Loss:0.140 AVG Test Loss:0.299\n",
            "Epoch:1234/3000 AVG Training Loss:0.214 AVG Test Loss:0.134\n",
            "Epoch:1235/3000 AVG Training Loss:0.146 AVG Test Loss:0.163\n",
            "Epoch:1236/3000 AVG Training Loss:0.086 AVG Test Loss:0.388\n",
            "Epoch:1237/3000 AVG Training Loss:0.187 AVG Test Loss:0.210\n",
            "Epoch:1238/3000 AVG Training Loss:0.154 AVG Test Loss:0.214\n",
            "Epoch:1239/3000 AVG Training Loss:0.118 AVG Test Loss:0.162\n",
            "Epoch:1240/3000 AVG Training Loss:0.223 AVG Test Loss:0.238\n",
            "Epoch:1241/3000 AVG Training Loss:0.170 AVG Test Loss:0.108\n",
            "Epoch:1242/3000 AVG Training Loss:0.192 AVG Test Loss:0.227\n",
            "Epoch:1243/3000 AVG Training Loss:0.180 AVG Test Loss:0.137\n",
            "Epoch:1244/3000 AVG Training Loss:0.226 AVG Test Loss:0.106\n",
            "Epoch:1245/3000 AVG Training Loss:0.316 AVG Test Loss:0.138\n",
            "Epoch:1246/3000 AVG Training Loss:0.130 AVG Test Loss:0.228\n",
            "Epoch:1247/3000 AVG Training Loss:0.367 AVG Test Loss:0.199\n",
            "Epoch:1248/3000 AVG Training Loss:0.142 AVG Test Loss:0.247\n",
            "Epoch:1249/3000 AVG Training Loss:0.144 AVG Test Loss:0.293\n",
            "Epoch:1250/3000 AVG Training Loss:0.172 AVG Test Loss:0.147\n",
            "Epoch:1251/3000 AVG Training Loss:0.189 AVG Test Loss:0.218\n",
            "Epoch:1252/3000 AVG Training Loss:0.149 AVG Test Loss:0.327\n",
            "Epoch:1253/3000 AVG Training Loss:0.184 AVG Test Loss:0.127\n",
            "Epoch:1254/3000 AVG Training Loss:0.096 AVG Test Loss:0.148\n",
            "Epoch:1255/3000 AVG Training Loss:0.201 AVG Test Loss:0.093\n",
            "Epoch:1256/3000 AVG Training Loss:0.111 AVG Test Loss:0.137\n",
            "Epoch:1257/3000 AVG Training Loss:0.149 AVG Test Loss:0.115\n",
            "Epoch:1258/3000 AVG Training Loss:0.206 AVG Test Loss:0.193\n",
            "Epoch:1259/3000 AVG Training Loss:0.163 AVG Test Loss:0.154\n",
            "Epoch:1260/3000 AVG Training Loss:0.131 AVG Test Loss:0.323\n",
            "Epoch:1261/3000 AVG Training Loss:0.217 AVG Test Loss:0.268\n",
            "Epoch:1262/3000 AVG Training Loss:0.203 AVG Test Loss:0.291\n",
            "Epoch:1263/3000 AVG Training Loss:0.161 AVG Test Loss:0.315\n",
            "Epoch:1264/3000 AVG Training Loss:0.260 AVG Test Loss:0.324\n",
            "Epoch:1265/3000 AVG Training Loss:0.242 AVG Test Loss:0.105\n",
            "Epoch:1266/3000 AVG Training Loss:0.237 AVG Test Loss:0.334\n",
            "Epoch:1267/3000 AVG Training Loss:0.232 AVG Test Loss:0.321\n",
            "Epoch:1268/3000 AVG Training Loss:0.184 AVG Test Loss:0.146\n",
            "Epoch:1269/3000 AVG Training Loss:0.158 AVG Test Loss:0.225\n",
            "Epoch:1270/3000 AVG Training Loss:0.183 AVG Test Loss:0.301\n",
            "Epoch:1271/3000 AVG Training Loss:0.224 AVG Test Loss:0.130\n",
            "Epoch:1272/3000 AVG Training Loss:0.233 AVG Test Loss:0.161\n",
            "Epoch:1273/3000 AVG Training Loss:0.126 AVG Test Loss:0.101\n",
            "Epoch:1274/3000 AVG Training Loss:0.118 AVG Test Loss:0.219\n",
            "Epoch:1275/3000 AVG Training Loss:0.156 AVG Test Loss:0.280\n",
            "Epoch:1276/3000 AVG Training Loss:0.218 AVG Test Loss:0.232\n",
            "Epoch:1277/3000 AVG Training Loss:0.243 AVG Test Loss:0.324\n",
            "Epoch:1278/3000 AVG Training Loss:0.141 AVG Test Loss:0.252\n",
            "Epoch:1279/3000 AVG Training Loss:0.248 AVG Test Loss:0.354\n",
            "Epoch:1280/3000 AVG Training Loss:0.160 AVG Test Loss:0.063\n",
            "Epoch:1281/3000 AVG Training Loss:0.202 AVG Test Loss:0.228\n",
            "Epoch:1282/3000 AVG Training Loss:0.178 AVG Test Loss:0.119\n",
            "Epoch:1283/3000 AVG Training Loss:0.215 AVG Test Loss:0.303\n",
            "Epoch:1284/3000 AVG Training Loss:0.183 AVG Test Loss:0.259\n",
            "Epoch:1285/3000 AVG Training Loss:0.165 AVG Test Loss:0.219\n",
            "Epoch:1286/3000 AVG Training Loss:0.306 AVG Test Loss:0.273\n",
            "Epoch:1287/3000 AVG Training Loss:0.203 AVG Test Loss:0.182\n",
            "Epoch:1288/3000 AVG Training Loss:0.265 AVG Test Loss:0.193\n",
            "Epoch:1289/3000 AVG Training Loss:0.125 AVG Test Loss:0.114\n",
            "Epoch:1290/3000 AVG Training Loss:0.146 AVG Test Loss:0.265\n",
            "Epoch:1291/3000 AVG Training Loss:0.179 AVG Test Loss:0.301\n",
            "Epoch:1292/3000 AVG Training Loss:0.136 AVG Test Loss:0.139\n",
            "Epoch:1293/3000 AVG Training Loss:0.229 AVG Test Loss:0.190\n",
            "Epoch:1294/3000 AVG Training Loss:0.081 AVG Test Loss:0.150\n",
            "Epoch:1295/3000 AVG Training Loss:0.180 AVG Test Loss:0.094\n",
            "Epoch:1296/3000 AVG Training Loss:0.187 AVG Test Loss:0.221\n",
            "Epoch:1297/3000 AVG Training Loss:0.115 AVG Test Loss:0.227\n",
            "Epoch:1298/3000 AVG Training Loss:0.168 AVG Test Loss:0.108\n",
            "Epoch:1299/3000 AVG Training Loss:0.200 AVG Test Loss:0.196\n",
            "Epoch:1300/3000 AVG Training Loss:0.199 AVG Test Loss:0.101\n",
            "Epoch:1301/3000 AVG Training Loss:0.152 AVG Test Loss:0.265\n",
            "Epoch:1302/3000 AVG Training Loss:0.141 AVG Test Loss:0.178\n",
            "Epoch:1303/3000 AVG Training Loss:0.253 AVG Test Loss:0.258\n",
            "Epoch:1304/3000 AVG Training Loss:0.114 AVG Test Loss:0.189\n",
            "Epoch:1305/3000 AVG Training Loss:0.146 AVG Test Loss:0.189\n",
            "Epoch:1306/3000 AVG Training Loss:0.213 AVG Test Loss:0.207\n",
            "Epoch:1307/3000 AVG Training Loss:0.209 AVG Test Loss:0.066\n",
            "Epoch:1308/3000 AVG Training Loss:0.143 AVG Test Loss:0.161\n",
            "Epoch:1309/3000 AVG Training Loss:0.179 AVG Test Loss:0.185\n",
            "Epoch:1310/3000 AVG Training Loss:0.146 AVG Test Loss:0.172\n",
            "Epoch:1311/3000 AVG Training Loss:0.113 AVG Test Loss:0.186\n",
            "Epoch:1312/3000 AVG Training Loss:0.182 AVG Test Loss:0.192\n",
            "Epoch:1313/3000 AVG Training Loss:0.159 AVG Test Loss:0.267\n",
            "Epoch:1314/3000 AVG Training Loss:0.127 AVG Test Loss:0.209\n",
            "Epoch:1315/3000 AVG Training Loss:0.165 AVG Test Loss:0.286\n",
            "Epoch:1316/3000 AVG Training Loss:0.205 AVG Test Loss:0.193\n",
            "Epoch:1317/3000 AVG Training Loss:0.147 AVG Test Loss:0.161\n",
            "Epoch:1318/3000 AVG Training Loss:0.108 AVG Test Loss:0.296\n",
            "Epoch:1319/3000 AVG Training Loss:0.318 AVG Test Loss:0.062\n",
            "Epoch:1320/3000 AVG Training Loss:0.097 AVG Test Loss:0.279\n",
            "Epoch:1321/3000 AVG Training Loss:0.118 AVG Test Loss:0.138\n",
            "Epoch:1322/3000 AVG Training Loss:0.181 AVG Test Loss:0.155\n",
            "Epoch:1323/3000 AVG Training Loss:0.147 AVG Test Loss:0.177\n",
            "Epoch:1324/3000 AVG Training Loss:0.182 AVG Test Loss:0.067\n",
            "Epoch:1325/3000 AVG Training Loss:0.156 AVG Test Loss:0.326\n",
            "Epoch:1326/3000 AVG Training Loss:0.157 AVG Test Loss:0.077\n",
            "Epoch:1327/3000 AVG Training Loss:0.094 AVG Test Loss:0.161\n",
            "Epoch:1328/3000 AVG Training Loss:0.091 AVG Test Loss:0.224\n",
            "Epoch:1329/3000 AVG Training Loss:0.195 AVG Test Loss:0.109\n",
            "Epoch:1330/3000 AVG Training Loss:0.101 AVG Test Loss:0.104\n",
            "Epoch:1331/3000 AVG Training Loss:0.185 AVG Test Loss:0.163\n",
            "Epoch:1332/3000 AVG Training Loss:0.145 AVG Test Loss:0.021\n",
            "Epoch:1333/3000 AVG Training Loss:0.267 AVG Test Loss:0.133\n",
            "Epoch:1334/3000 AVG Training Loss:0.099 AVG Test Loss:0.286\n",
            "Epoch:1335/3000 AVG Training Loss:0.148 AVG Test Loss:0.170\n",
            "Epoch:1336/3000 AVG Training Loss:0.185 AVG Test Loss:0.206\n",
            "Epoch:1337/3000 AVG Training Loss:0.118 AVG Test Loss:0.319\n",
            "Epoch:1338/3000 AVG Training Loss:0.177 AVG Test Loss:0.128\n",
            "Epoch:1339/3000 AVG Training Loss:0.228 AVG Test Loss:0.125\n",
            "Epoch:1340/3000 AVG Training Loss:0.129 AVG Test Loss:0.191\n",
            "Epoch:1341/3000 AVG Training Loss:0.143 AVG Test Loss:0.179\n",
            "Epoch:1342/3000 AVG Training Loss:0.211 AVG Test Loss:0.223\n",
            "Epoch:1343/3000 AVG Training Loss:0.119 AVG Test Loss:0.124\n",
            "Epoch:1344/3000 AVG Training Loss:0.144 AVG Test Loss:0.235\n",
            "Epoch:1345/3000 AVG Training Loss:0.290 AVG Test Loss:0.176\n",
            "Epoch:1346/3000 AVG Training Loss:0.107 AVG Test Loss:0.252\n",
            "Epoch:1347/3000 AVG Training Loss:0.167 AVG Test Loss:0.096\n",
            "Epoch:1348/3000 AVG Training Loss:0.229 AVG Test Loss:0.176\n",
            "Epoch:1349/3000 AVG Training Loss:0.151 AVG Test Loss:0.131\n",
            "Epoch:1350/3000 AVG Training Loss:0.147 AVG Test Loss:0.234\n",
            "Epoch:1351/3000 AVG Training Loss:0.191 AVG Test Loss:0.180\n",
            "Epoch:1352/3000 AVG Training Loss:0.183 AVG Test Loss:0.194\n",
            "Epoch:1353/3000 AVG Training Loss:0.186 AVG Test Loss:0.130\n",
            "Epoch:1354/3000 AVG Training Loss:0.233 AVG Test Loss:0.281\n",
            "Epoch:1355/3000 AVG Training Loss:0.213 AVG Test Loss:0.170\n",
            "Epoch:1356/3000 AVG Training Loss:0.189 AVG Test Loss:0.286\n",
            "Epoch:1357/3000 AVG Training Loss:0.183 AVG Test Loss:0.336\n",
            "Epoch:1358/3000 AVG Training Loss:0.208 AVG Test Loss:0.224\n",
            "Epoch:1359/3000 AVG Training Loss:0.183 AVG Test Loss:0.224\n",
            "Epoch:1360/3000 AVG Training Loss:0.203 AVG Test Loss:0.408\n",
            "Epoch:1361/3000 AVG Training Loss:0.275 AVG Test Loss:0.294\n",
            "Epoch:1362/3000 AVG Training Loss:0.303 AVG Test Loss:0.158\n",
            "Epoch:1363/3000 AVG Training Loss:0.327 AVG Test Loss:0.227\n",
            "Epoch:1364/3000 AVG Training Loss:0.133 AVG Test Loss:0.227\n",
            "Epoch:1365/3000 AVG Training Loss:0.144 AVG Test Loss:0.312\n",
            "Epoch:1366/3000 AVG Training Loss:0.294 AVG Test Loss:0.483\n",
            "Epoch:1367/3000 AVG Training Loss:0.169 AVG Test Loss:0.288\n",
            "Epoch:1368/3000 AVG Training Loss:0.199 AVG Test Loss:0.197\n",
            "Epoch:1369/3000 AVG Training Loss:0.238 AVG Test Loss:0.176\n",
            "Epoch:1370/3000 AVG Training Loss:0.174 AVG Test Loss:0.290\n",
            "Epoch:1371/3000 AVG Training Loss:0.098 AVG Test Loss:0.222\n",
            "Epoch:1372/3000 AVG Training Loss:0.113 AVG Test Loss:0.303\n",
            "Epoch:1373/3000 AVG Training Loss:0.194 AVG Test Loss:0.118\n",
            "Epoch:1374/3000 AVG Training Loss:0.115 AVG Test Loss:0.069\n",
            "Epoch:1375/3000 AVG Training Loss:0.140 AVG Test Loss:0.261\n",
            "Epoch:1376/3000 AVG Training Loss:0.139 AVG Test Loss:0.147\n",
            "Epoch:1377/3000 AVG Training Loss:0.093 AVG Test Loss:0.322\n",
            "Epoch:1378/3000 AVG Training Loss:0.147 AVG Test Loss:0.243\n",
            "Epoch:1379/3000 AVG Training Loss:0.208 AVG Test Loss:0.086\n",
            "Epoch:1380/3000 AVG Training Loss:0.153 AVG Test Loss:0.260\n",
            "Epoch:1381/3000 AVG Training Loss:0.151 AVG Test Loss:0.256\n",
            "Epoch:1382/3000 AVG Training Loss:0.233 AVG Test Loss:0.165\n",
            "Epoch:1383/3000 AVG Training Loss:0.174 AVG Test Loss:0.232\n",
            "Epoch:1384/3000 AVG Training Loss:0.179 AVG Test Loss:0.292\n",
            "Epoch:1385/3000 AVG Training Loss:0.153 AVG Test Loss:0.113\n",
            "Epoch:1386/3000 AVG Training Loss:0.213 AVG Test Loss:0.180\n",
            "Epoch:1387/3000 AVG Training Loss:0.130 AVG Test Loss:0.177\n",
            "Epoch:1388/3000 AVG Training Loss:0.145 AVG Test Loss:0.174\n",
            "Epoch:1389/3000 AVG Training Loss:0.138 AVG Test Loss:0.189\n",
            "Epoch:1390/3000 AVG Training Loss:0.197 AVG Test Loss:0.077\n",
            "Epoch:1391/3000 AVG Training Loss:0.171 AVG Test Loss:0.104\n",
            "Epoch:1392/3000 AVG Training Loss:0.181 AVG Test Loss:0.152\n",
            "Epoch:1393/3000 AVG Training Loss:0.155 AVG Test Loss:0.099\n",
            "Epoch:1394/3000 AVG Training Loss:0.121 AVG Test Loss:0.226\n",
            "Epoch:1395/3000 AVG Training Loss:0.053 AVG Test Loss:0.175\n",
            "Epoch:1396/3000 AVG Training Loss:0.173 AVG Test Loss:0.150\n",
            "Epoch:1397/3000 AVG Training Loss:0.211 AVG Test Loss:0.189\n",
            "Epoch:1398/3000 AVG Training Loss:0.156 AVG Test Loss:0.310\n",
            "Epoch:1399/3000 AVG Training Loss:0.184 AVG Test Loss:0.242\n",
            "Epoch:1400/3000 AVG Training Loss:0.242 AVG Test Loss:0.125\n",
            "Epoch:1401/3000 AVG Training Loss:0.209 AVG Test Loss:0.144\n",
            "Epoch:1402/3000 AVG Training Loss:0.151 AVG Test Loss:0.410\n",
            "Epoch:1403/3000 AVG Training Loss:0.230 AVG Test Loss:0.293\n",
            "Epoch:1404/3000 AVG Training Loss:0.238 AVG Test Loss:0.121\n",
            "Epoch:1405/3000 AVG Training Loss:0.147 AVG Test Loss:0.142\n",
            "Epoch:1406/3000 AVG Training Loss:0.123 AVG Test Loss:0.297\n",
            "Epoch:1407/3000 AVG Training Loss:0.230 AVG Test Loss:0.064\n",
            "Epoch:1408/3000 AVG Training Loss:0.116 AVG Test Loss:0.344\n",
            "Epoch:1409/3000 AVG Training Loss:0.081 AVG Test Loss:0.431\n",
            "Epoch:1410/3000 AVG Training Loss:0.216 AVG Test Loss:0.244\n",
            "Epoch:1411/3000 AVG Training Loss:0.087 AVG Test Loss:0.268\n",
            "Epoch:1412/3000 AVG Training Loss:0.175 AVG Test Loss:0.049\n",
            "Epoch:1413/3000 AVG Training Loss:0.158 AVG Test Loss:0.325\n",
            "Epoch:1414/3000 AVG Training Loss:0.214 AVG Test Loss:0.216\n",
            "Epoch:1415/3000 AVG Training Loss:0.129 AVG Test Loss:0.147\n",
            "Epoch:1416/3000 AVG Training Loss:0.100 AVG Test Loss:0.178\n",
            "Epoch:1417/3000 AVG Training Loss:0.121 AVG Test Loss:0.264\n",
            "Epoch:1418/3000 AVG Training Loss:0.166 AVG Test Loss:0.164\n",
            "Epoch:1419/3000 AVG Training Loss:0.144 AVG Test Loss:0.334\n",
            "Epoch:1420/3000 AVG Training Loss:0.208 AVG Test Loss:0.355\n",
            "Epoch:1421/3000 AVG Training Loss:0.118 AVG Test Loss:0.365\n",
            "Epoch:1422/3000 AVG Training Loss:0.149 AVG Test Loss:0.257\n",
            "Epoch:1423/3000 AVG Training Loss:0.136 AVG Test Loss:0.150\n",
            "Epoch:1424/3000 AVG Training Loss:0.190 AVG Test Loss:0.121\n",
            "Epoch:1425/3000 AVG Training Loss:0.150 AVG Test Loss:0.431\n",
            "Epoch:1426/3000 AVG Training Loss:0.186 AVG Test Loss:0.120\n",
            "Epoch:1427/3000 AVG Training Loss:0.167 AVG Test Loss:0.230\n",
            "Epoch:1428/3000 AVG Training Loss:0.104 AVG Test Loss:0.095\n",
            "Epoch:1429/3000 AVG Training Loss:0.148 AVG Test Loss:0.292\n",
            "Epoch:1430/3000 AVG Training Loss:0.134 AVG Test Loss:0.090\n",
            "Epoch:1431/3000 AVG Training Loss:0.262 AVG Test Loss:0.267\n",
            "Epoch:1432/3000 AVG Training Loss:0.239 AVG Test Loss:0.105\n",
            "Epoch:1433/3000 AVG Training Loss:0.119 AVG Test Loss:0.270\n",
            "Epoch:1434/3000 AVG Training Loss:0.143 AVG Test Loss:0.130\n",
            "Epoch:1435/3000 AVG Training Loss:0.104 AVG Test Loss:0.041\n",
            "Epoch:1436/3000 AVG Training Loss:0.189 AVG Test Loss:0.218\n",
            "Epoch:1437/3000 AVG Training Loss:0.153 AVG Test Loss:0.211\n",
            "Epoch:1438/3000 AVG Training Loss:0.154 AVG Test Loss:0.213\n",
            "Epoch:1439/3000 AVG Training Loss:0.228 AVG Test Loss:0.272\n",
            "Epoch:1440/3000 AVG Training Loss:0.196 AVG Test Loss:0.330\n",
            "Epoch:1441/3000 AVG Training Loss:0.197 AVG Test Loss:0.203\n",
            "Epoch:1442/3000 AVG Training Loss:0.191 AVG Test Loss:0.097\n",
            "Epoch:1443/3000 AVG Training Loss:0.129 AVG Test Loss:0.194\n",
            "Epoch:1444/3000 AVG Training Loss:0.166 AVG Test Loss:0.151\n",
            "Epoch:1445/3000 AVG Training Loss:0.188 AVG Test Loss:0.188\n",
            "Epoch:1446/3000 AVG Training Loss:0.253 AVG Test Loss:0.278\n",
            "Epoch:1447/3000 AVG Training Loss:0.117 AVG Test Loss:0.309\n",
            "Epoch:1448/3000 AVG Training Loss:0.302 AVG Test Loss:0.300\n",
            "Epoch:1449/3000 AVG Training Loss:0.130 AVG Test Loss:0.242\n",
            "Epoch:1450/3000 AVG Training Loss:0.170 AVG Test Loss:0.156\n",
            "Epoch:1451/3000 AVG Training Loss:0.119 AVG Test Loss:0.176\n",
            "Epoch:1452/3000 AVG Training Loss:0.132 AVG Test Loss:0.107\n",
            "Epoch:1453/3000 AVG Training Loss:0.108 AVG Test Loss:0.172\n",
            "Epoch:1454/3000 AVG Training Loss:0.236 AVG Test Loss:0.328\n",
            "Epoch:1455/3000 AVG Training Loss:0.189 AVG Test Loss:0.119\n",
            "Epoch:1456/3000 AVG Training Loss:0.209 AVG Test Loss:0.072\n",
            "Epoch:1457/3000 AVG Training Loss:0.113 AVG Test Loss:0.311\n",
            "Epoch:1458/3000 AVG Training Loss:0.174 AVG Test Loss:0.028\n",
            "Epoch:1459/3000 AVG Training Loss:0.168 AVG Test Loss:0.148\n",
            "Epoch:1460/3000 AVG Training Loss:0.216 AVG Test Loss:0.181\n",
            "Epoch:1461/3000 AVG Training Loss:0.157 AVG Test Loss:0.252\n",
            "Epoch:1462/3000 AVG Training Loss:0.168 AVG Test Loss:0.094\n",
            "Epoch:1463/3000 AVG Training Loss:0.143 AVG Test Loss:0.186\n",
            "Epoch:1464/3000 AVG Training Loss:0.094 AVG Test Loss:0.198\n",
            "Epoch:1465/3000 AVG Training Loss:0.180 AVG Test Loss:0.319\n",
            "Epoch:1466/3000 AVG Training Loss:0.087 AVG Test Loss:0.153\n",
            "Epoch:1467/3000 AVG Training Loss:0.141 AVG Test Loss:0.318\n",
            "Epoch:1468/3000 AVG Training Loss:0.177 AVG Test Loss:0.118\n",
            "Epoch:1469/3000 AVG Training Loss:0.153 AVG Test Loss:0.361\n",
            "Epoch:1470/3000 AVG Training Loss:0.147 AVG Test Loss:0.131\n",
            "Epoch:1471/3000 AVG Training Loss:0.126 AVG Test Loss:0.210\n",
            "Epoch:1472/3000 AVG Training Loss:0.140 AVG Test Loss:0.156\n",
            "Epoch:1473/3000 AVG Training Loss:0.214 AVG Test Loss:0.187\n",
            "Epoch:1474/3000 AVG Training Loss:0.239 AVG Test Loss:0.241\n",
            "Epoch:1475/3000 AVG Training Loss:0.129 AVG Test Loss:0.182\n",
            "Epoch:1476/3000 AVG Training Loss:0.126 AVG Test Loss:0.202\n",
            "Epoch:1477/3000 AVG Training Loss:0.146 AVG Test Loss:0.246\n",
            "Epoch:1478/3000 AVG Training Loss:0.111 AVG Test Loss:0.359\n",
            "Epoch:1479/3000 AVG Training Loss:0.273 AVG Test Loss:0.134\n",
            "Epoch:1480/3000 AVG Training Loss:0.231 AVG Test Loss:0.138\n",
            "Epoch:1481/3000 AVG Training Loss:0.201 AVG Test Loss:0.177\n",
            "Epoch:1482/3000 AVG Training Loss:0.155 AVG Test Loss:0.278\n",
            "Epoch:1483/3000 AVG Training Loss:0.132 AVG Test Loss:0.166\n",
            "Epoch:1484/3000 AVG Training Loss:0.235 AVG Test Loss:0.243\n",
            "Epoch:1485/3000 AVG Training Loss:0.220 AVG Test Loss:0.271\n",
            "Epoch:1486/3000 AVG Training Loss:0.172 AVG Test Loss:0.157\n",
            "Epoch:1487/3000 AVG Training Loss:0.106 AVG Test Loss:0.316\n",
            "Epoch:1488/3000 AVG Training Loss:0.165 AVG Test Loss:0.099\n",
            "Epoch:1489/3000 AVG Training Loss:0.110 AVG Test Loss:0.254\n",
            "Epoch:1490/3000 AVG Training Loss:0.172 AVG Test Loss:0.071\n",
            "Epoch:1491/3000 AVG Training Loss:0.343 AVG Test Loss:0.211\n",
            "Epoch:1492/3000 AVG Training Loss:0.448 AVG Test Loss:0.125\n",
            "Epoch:1493/3000 AVG Training Loss:0.095 AVG Test Loss:0.280\n",
            "Epoch:1494/3000 AVG Training Loss:0.256 AVG Test Loss:0.325\n",
            "Epoch:1495/3000 AVG Training Loss:0.186 AVG Test Loss:0.495\n",
            "Epoch:1496/3000 AVG Training Loss:0.150 AVG Test Loss:0.284\n",
            "Epoch:1497/3000 AVG Training Loss:0.135 AVG Test Loss:0.061\n",
            "Epoch:1498/3000 AVG Training Loss:0.127 AVG Test Loss:0.112\n",
            "Epoch:1499/3000 AVG Training Loss:0.190 AVG Test Loss:0.350\n",
            "Epoch:1500/3000 AVG Training Loss:0.190 AVG Test Loss:0.199\n",
            "Epoch:1501/3000 AVG Training Loss:0.128 AVG Test Loss:0.111\n",
            "Epoch:1502/3000 AVG Training Loss:0.124 AVG Test Loss:0.390\n",
            "Epoch:1503/3000 AVG Training Loss:0.153 AVG Test Loss:0.139\n",
            "Epoch:1504/3000 AVG Training Loss:0.116 AVG Test Loss:0.155\n",
            "Epoch:1505/3000 AVG Training Loss:0.132 AVG Test Loss:0.268\n",
            "Epoch:1506/3000 AVG Training Loss:0.149 AVG Test Loss:0.066\n",
            "Epoch:1507/3000 AVG Training Loss:0.190 AVG Test Loss:0.299\n",
            "Epoch:1508/3000 AVG Training Loss:0.102 AVG Test Loss:0.300\n",
            "Epoch:1509/3000 AVG Training Loss:0.174 AVG Test Loss:0.095\n",
            "Epoch:1510/3000 AVG Training Loss:0.163 AVG Test Loss:0.275\n",
            "Epoch:1511/3000 AVG Training Loss:0.175 AVG Test Loss:0.136\n",
            "Epoch:1512/3000 AVG Training Loss:0.096 AVG Test Loss:0.203\n",
            "Epoch:1513/3000 AVG Training Loss:0.175 AVG Test Loss:0.219\n",
            "Epoch:1514/3000 AVG Training Loss:0.122 AVG Test Loss:0.489\n",
            "Epoch:1515/3000 AVG Training Loss:0.242 AVG Test Loss:0.297\n",
            "Epoch:1516/3000 AVG Training Loss:0.177 AVG Test Loss:0.250\n",
            "Epoch:1517/3000 AVG Training Loss:0.165 AVG Test Loss:0.198\n",
            "Epoch:1518/3000 AVG Training Loss:0.163 AVG Test Loss:0.207\n",
            "Epoch:1519/3000 AVG Training Loss:0.109 AVG Test Loss:0.412\n",
            "Epoch:1520/3000 AVG Training Loss:0.208 AVG Test Loss:0.135\n",
            "Epoch:1521/3000 AVG Training Loss:0.153 AVG Test Loss:0.202\n",
            "Epoch:1522/3000 AVG Training Loss:0.171 AVG Test Loss:0.093\n",
            "Epoch:1523/3000 AVG Training Loss:0.129 AVG Test Loss:0.192\n",
            "Epoch:1524/3000 AVG Training Loss:0.225 AVG Test Loss:0.144\n",
            "Epoch:1525/3000 AVG Training Loss:0.120 AVG Test Loss:0.246\n",
            "Epoch:1526/3000 AVG Training Loss:0.142 AVG Test Loss:0.214\n",
            "Epoch:1527/3000 AVG Training Loss:0.084 AVG Test Loss:0.251\n",
            "Epoch:1528/3000 AVG Training Loss:0.210 AVG Test Loss:0.060\n",
            "Epoch:1529/3000 AVG Training Loss:0.099 AVG Test Loss:0.125\n",
            "Epoch:1530/3000 AVG Training Loss:0.127 AVG Test Loss:0.198\n",
            "Epoch:1531/3000 AVG Training Loss:0.176 AVG Test Loss:0.324\n",
            "Epoch:1532/3000 AVG Training Loss:0.120 AVG Test Loss:0.249\n",
            "Epoch:1533/3000 AVG Training Loss:0.127 AVG Test Loss:0.216\n",
            "Epoch:1534/3000 AVG Training Loss:0.249 AVG Test Loss:0.131\n",
            "Epoch:1535/3000 AVG Training Loss:0.237 AVG Test Loss:0.137\n",
            "Epoch:1536/3000 AVG Training Loss:0.124 AVG Test Loss:0.283\n",
            "Epoch:1537/3000 AVG Training Loss:0.136 AVG Test Loss:0.238\n",
            "Epoch:1538/3000 AVG Training Loss:0.137 AVG Test Loss:0.183\n",
            "Epoch:1539/3000 AVG Training Loss:0.166 AVG Test Loss:0.129\n",
            "Epoch:1540/3000 AVG Training Loss:0.135 AVG Test Loss:0.088\n",
            "Epoch:1541/3000 AVG Training Loss:0.167 AVG Test Loss:0.259\n",
            "Epoch:1542/3000 AVG Training Loss:0.213 AVG Test Loss:0.231\n",
            "Epoch:1543/3000 AVG Training Loss:0.188 AVG Test Loss:0.129\n",
            "Epoch:1544/3000 AVG Training Loss:0.230 AVG Test Loss:0.248\n",
            "Epoch:1545/3000 AVG Training Loss:0.213 AVG Test Loss:0.182\n",
            "Epoch:1546/3000 AVG Training Loss:0.176 AVG Test Loss:0.251\n",
            "Epoch:1547/3000 AVG Training Loss:0.210 AVG Test Loss:0.309\n",
            "Epoch:1548/3000 AVG Training Loss:0.185 AVG Test Loss:0.149\n",
            "Epoch:1549/3000 AVG Training Loss:0.185 AVG Test Loss:0.175\n",
            "Epoch:1550/3000 AVG Training Loss:0.116 AVG Test Loss:0.109\n",
            "Epoch:1551/3000 AVG Training Loss:0.199 AVG Test Loss:0.221\n",
            "Epoch:1552/3000 AVG Training Loss:0.124 AVG Test Loss:0.069\n",
            "Epoch:1553/3000 AVG Training Loss:0.171 AVG Test Loss:0.108\n",
            "Epoch:1554/3000 AVG Training Loss:0.169 AVG Test Loss:0.214\n",
            "Epoch:1555/3000 AVG Training Loss:0.096 AVG Test Loss:0.110\n",
            "Epoch:1556/3000 AVG Training Loss:0.216 AVG Test Loss:0.092\n",
            "Epoch:1557/3000 AVG Training Loss:0.141 AVG Test Loss:0.251\n",
            "Epoch:1558/3000 AVG Training Loss:0.176 AVG Test Loss:0.243\n",
            "Epoch:1559/3000 AVG Training Loss:0.219 AVG Test Loss:0.096\n",
            "Epoch:1560/3000 AVG Training Loss:0.078 AVG Test Loss:0.177\n",
            "Epoch:1561/3000 AVG Training Loss:0.257 AVG Test Loss:0.342\n",
            "Epoch:1562/3000 AVG Training Loss:0.097 AVG Test Loss:0.088\n",
            "Epoch:1563/3000 AVG Training Loss:0.142 AVG Test Loss:0.119\n",
            "Epoch:1564/3000 AVG Training Loss:0.149 AVG Test Loss:0.290\n",
            "Epoch:1565/3000 AVG Training Loss:0.144 AVG Test Loss:0.163\n",
            "Epoch:1566/3000 AVG Training Loss:0.191 AVG Test Loss:0.092\n",
            "Epoch:1567/3000 AVG Training Loss:0.153 AVG Test Loss:0.169\n",
            "Epoch:1568/3000 AVG Training Loss:0.235 AVG Test Loss:0.255\n",
            "Epoch:1569/3000 AVG Training Loss:0.120 AVG Test Loss:0.253\n",
            "Epoch:1570/3000 AVG Training Loss:0.109 AVG Test Loss:0.205\n",
            "Epoch:1571/3000 AVG Training Loss:0.092 AVG Test Loss:0.225\n",
            "Epoch:1572/3000 AVG Training Loss:0.126 AVG Test Loss:0.299\n",
            "Epoch:1573/3000 AVG Training Loss:0.201 AVG Test Loss:0.274\n",
            "Epoch:1574/3000 AVG Training Loss:0.141 AVG Test Loss:0.256\n",
            "Epoch:1575/3000 AVG Training Loss:0.152 AVG Test Loss:0.112\n",
            "Epoch:1576/3000 AVG Training Loss:0.146 AVG Test Loss:0.233\n",
            "Epoch:1577/3000 AVG Training Loss:0.119 AVG Test Loss:0.070\n",
            "Epoch:1578/3000 AVG Training Loss:0.167 AVG Test Loss:0.054\n",
            "Epoch:1579/3000 AVG Training Loss:0.102 AVG Test Loss:0.114\n",
            "Epoch:1580/3000 AVG Training Loss:0.229 AVG Test Loss:0.089\n",
            "Epoch:1581/3000 AVG Training Loss:0.235 AVG Test Loss:0.179\n",
            "Epoch:1582/3000 AVG Training Loss:0.167 AVG Test Loss:0.329\n",
            "Epoch:1583/3000 AVG Training Loss:0.135 AVG Test Loss:0.216\n",
            "Epoch:1584/3000 AVG Training Loss:0.179 AVG Test Loss:0.166\n",
            "Epoch:1585/3000 AVG Training Loss:0.168 AVG Test Loss:0.301\n",
            "Epoch:1586/3000 AVG Training Loss:0.218 AVG Test Loss:0.179\n",
            "Epoch:1587/3000 AVG Training Loss:0.110 AVG Test Loss:0.133\n",
            "Epoch:1588/3000 AVG Training Loss:0.130 AVG Test Loss:0.129\n",
            "Epoch:1589/3000 AVG Training Loss:0.138 AVG Test Loss:0.232\n",
            "Epoch:1590/3000 AVG Training Loss:0.094 AVG Test Loss:0.175\n",
            "Epoch:1591/3000 AVG Training Loss:0.247 AVG Test Loss:0.059\n",
            "Epoch:1592/3000 AVG Training Loss:0.186 AVG Test Loss:0.131\n",
            "Epoch:1593/3000 AVG Training Loss:0.166 AVG Test Loss:0.075\n",
            "Epoch:1594/3000 AVG Training Loss:0.135 AVG Test Loss:0.087\n",
            "Epoch:1595/3000 AVG Training Loss:0.136 AVG Test Loss:0.351\n",
            "Epoch:1596/3000 AVG Training Loss:0.193 AVG Test Loss:0.161\n",
            "Epoch:1597/3000 AVG Training Loss:0.121 AVG Test Loss:0.272\n",
            "Epoch:1598/3000 AVG Training Loss:0.211 AVG Test Loss:0.252\n",
            "Epoch:1599/3000 AVG Training Loss:0.151 AVG Test Loss:0.190\n",
            "Epoch:1600/3000 AVG Training Loss:0.157 AVG Test Loss:0.227\n",
            "Epoch:1601/3000 AVG Training Loss:0.304 AVG Test Loss:0.324\n",
            "Epoch:1602/3000 AVG Training Loss:0.207 AVG Test Loss:0.326\n",
            "Epoch:1603/3000 AVG Training Loss:0.203 AVG Test Loss:0.127\n",
            "Epoch:1604/3000 AVG Training Loss:0.163 AVG Test Loss:0.230\n",
            "Epoch:1605/3000 AVG Training Loss:0.113 AVG Test Loss:0.324\n",
            "Epoch:1606/3000 AVG Training Loss:0.185 AVG Test Loss:0.129\n",
            "Epoch:1607/3000 AVG Training Loss:0.213 AVG Test Loss:0.089\n",
            "Epoch:1608/3000 AVG Training Loss:0.132 AVG Test Loss:0.201\n",
            "Epoch:1609/3000 AVG Training Loss:0.201 AVG Test Loss:0.258\n",
            "Epoch:1610/3000 AVG Training Loss:0.214 AVG Test Loss:0.129\n",
            "Epoch:1611/3000 AVG Training Loss:0.269 AVG Test Loss:0.178\n",
            "Epoch:1612/3000 AVG Training Loss:0.107 AVG Test Loss:0.097\n",
            "Epoch:1613/3000 AVG Training Loss:0.118 AVG Test Loss:0.137\n",
            "Epoch:1614/3000 AVG Training Loss:0.125 AVG Test Loss:0.264\n",
            "Epoch:1615/3000 AVG Training Loss:0.113 AVG Test Loss:0.183\n",
            "Epoch:1616/3000 AVG Training Loss:0.160 AVG Test Loss:0.099\n",
            "Epoch:1617/3000 AVG Training Loss:0.132 AVG Test Loss:0.142\n",
            "Epoch:1618/3000 AVG Training Loss:0.176 AVG Test Loss:0.101\n",
            "Epoch:1619/3000 AVG Training Loss:0.183 AVG Test Loss:0.248\n",
            "Epoch:1620/3000 AVG Training Loss:0.292 AVG Test Loss:0.327\n",
            "Epoch:1621/3000 AVG Training Loss:0.152 AVG Test Loss:0.279\n",
            "Epoch:1622/3000 AVG Training Loss:0.156 AVG Test Loss:0.158\n",
            "Epoch:1623/3000 AVG Training Loss:0.230 AVG Test Loss:0.218\n",
            "Epoch:1624/3000 AVG Training Loss:0.155 AVG Test Loss:0.308\n",
            "Epoch:1625/3000 AVG Training Loss:0.064 AVG Test Loss:0.113\n",
            "Epoch:1626/3000 AVG Training Loss:0.259 AVG Test Loss:0.120\n",
            "Epoch:1627/3000 AVG Training Loss:0.086 AVG Test Loss:0.286\n",
            "Epoch:1628/3000 AVG Training Loss:0.137 AVG Test Loss:0.166\n",
            "Epoch:1629/3000 AVG Training Loss:0.102 AVG Test Loss:0.150\n",
            "Epoch:1630/3000 AVG Training Loss:0.098 AVG Test Loss:0.096\n",
            "Epoch:1631/3000 AVG Training Loss:0.181 AVG Test Loss:0.260\n",
            "Epoch:1632/3000 AVG Training Loss:0.131 AVG Test Loss:0.186\n",
            "Epoch:1633/3000 AVG Training Loss:0.098 AVG Test Loss:0.187\n",
            "Epoch:1634/3000 AVG Training Loss:0.159 AVG Test Loss:0.164\n",
            "Epoch:1635/3000 AVG Training Loss:0.151 AVG Test Loss:0.244\n",
            "Epoch:1636/3000 AVG Training Loss:0.110 AVG Test Loss:0.323\n",
            "Epoch:1637/3000 AVG Training Loss:0.105 AVG Test Loss:0.142\n",
            "Epoch:1638/3000 AVG Training Loss:0.144 AVG Test Loss:0.170\n",
            "Epoch:1639/3000 AVG Training Loss:0.160 AVG Test Loss:0.250\n",
            "Epoch:1640/3000 AVG Training Loss:0.199 AVG Test Loss:0.307\n",
            "Epoch:1641/3000 AVG Training Loss:0.086 AVG Test Loss:0.325\n",
            "Epoch:1642/3000 AVG Training Loss:0.152 AVG Test Loss:0.106\n",
            "Epoch:1643/3000 AVG Training Loss:0.179 AVG Test Loss:0.189\n",
            "Epoch:1644/3000 AVG Training Loss:0.118 AVG Test Loss:0.101\n",
            "Epoch:1645/3000 AVG Training Loss:0.130 AVG Test Loss:0.113\n",
            "Epoch:1646/3000 AVG Training Loss:0.142 AVG Test Loss:0.366\n",
            "Epoch:1647/3000 AVG Training Loss:0.203 AVG Test Loss:0.203\n",
            "Epoch:1648/3000 AVG Training Loss:0.124 AVG Test Loss:0.138\n",
            "Epoch:1649/3000 AVG Training Loss:0.164 AVG Test Loss:0.154\n",
            "Epoch:1650/3000 AVG Training Loss:0.133 AVG Test Loss:0.117\n",
            "Epoch:1651/3000 AVG Training Loss:0.098 AVG Test Loss:0.185\n",
            "Epoch:1652/3000 AVG Training Loss:0.124 AVG Test Loss:0.325\n",
            "Epoch:1653/3000 AVG Training Loss:0.125 AVG Test Loss:0.211\n",
            "Epoch:1654/3000 AVG Training Loss:0.207 AVG Test Loss:0.299\n",
            "Epoch:1655/3000 AVG Training Loss:0.097 AVG Test Loss:0.059\n",
            "Epoch:1656/3000 AVG Training Loss:0.089 AVG Test Loss:0.112\n",
            "Epoch:1657/3000 AVG Training Loss:0.172 AVG Test Loss:0.287\n",
            "Epoch:1658/3000 AVG Training Loss:0.180 AVG Test Loss:0.073\n",
            "Epoch:1659/3000 AVG Training Loss:0.253 AVG Test Loss:0.178\n",
            "Epoch:1660/3000 AVG Training Loss:0.168 AVG Test Loss:0.076\n",
            "Epoch:1661/3000 AVG Training Loss:0.105 AVG Test Loss:0.191\n",
            "Epoch:1662/3000 AVG Training Loss:0.203 AVG Test Loss:0.274\n",
            "Epoch:1663/3000 AVG Training Loss:0.113 AVG Test Loss:0.097\n",
            "Epoch:1664/3000 AVG Training Loss:0.122 AVG Test Loss:0.252\n",
            "Epoch:1665/3000 AVG Training Loss:0.218 AVG Test Loss:0.228\n",
            "Epoch:1666/3000 AVG Training Loss:0.177 AVG Test Loss:0.096\n",
            "Epoch:1667/3000 AVG Training Loss:0.192 AVG Test Loss:0.408\n",
            "Epoch:1668/3000 AVG Training Loss:0.230 AVG Test Loss:0.167\n",
            "Epoch:1669/3000 AVG Training Loss:0.099 AVG Test Loss:0.135\n",
            "Epoch:1670/3000 AVG Training Loss:0.214 AVG Test Loss:0.167\n",
            "Epoch:1671/3000 AVG Training Loss:0.167 AVG Test Loss:0.079\n",
            "Epoch:1672/3000 AVG Training Loss:0.131 AVG Test Loss:0.180\n",
            "Epoch:1673/3000 AVG Training Loss:0.211 AVG Test Loss:0.132\n",
            "Epoch:1674/3000 AVG Training Loss:0.311 AVG Test Loss:0.091\n",
            "Epoch:1675/3000 AVG Training Loss:0.276 AVG Test Loss:0.313\n",
            "Epoch:1676/3000 AVG Training Loss:0.142 AVG Test Loss:0.205\n",
            "Epoch:1677/3000 AVG Training Loss:0.231 AVG Test Loss:0.269\n",
            "Epoch:1678/3000 AVG Training Loss:0.103 AVG Test Loss:0.071\n",
            "Epoch:1679/3000 AVG Training Loss:0.100 AVG Test Loss:0.187\n",
            "Epoch:1680/3000 AVG Training Loss:0.124 AVG Test Loss:0.160\n",
            "Epoch:1681/3000 AVG Training Loss:0.160 AVG Test Loss:0.124\n",
            "Epoch:1682/3000 AVG Training Loss:0.159 AVG Test Loss:0.133\n",
            "Epoch:1683/3000 AVG Training Loss:0.109 AVG Test Loss:0.214\n",
            "Epoch:1684/3000 AVG Training Loss:0.113 AVG Test Loss:0.178\n",
            "Epoch:1685/3000 AVG Training Loss:0.182 AVG Test Loss:0.197\n",
            "Epoch:1686/3000 AVG Training Loss:0.142 AVG Test Loss:0.135\n",
            "Epoch:1687/3000 AVG Training Loss:0.116 AVG Test Loss:0.130\n",
            "Epoch:1688/3000 AVG Training Loss:0.225 AVG Test Loss:0.088\n",
            "Epoch:1689/3000 AVG Training Loss:0.219 AVG Test Loss:0.146\n",
            "Epoch:1690/3000 AVG Training Loss:0.202 AVG Test Loss:0.116\n",
            "Epoch:1691/3000 AVG Training Loss:0.244 AVG Test Loss:0.221\n",
            "Epoch:1692/3000 AVG Training Loss:0.161 AVG Test Loss:0.306\n",
            "Epoch:1693/3000 AVG Training Loss:0.167 AVG Test Loss:0.241\n",
            "Epoch:1694/3000 AVG Training Loss:0.139 AVG Test Loss:0.093\n",
            "Epoch:1695/3000 AVG Training Loss:0.137 AVG Test Loss:0.289\n",
            "Epoch:1696/3000 AVG Training Loss:0.119 AVG Test Loss:0.187\n",
            "Epoch:1697/3000 AVG Training Loss:0.207 AVG Test Loss:0.086\n",
            "Epoch:1698/3000 AVG Training Loss:0.202 AVG Test Loss:0.130\n",
            "Epoch:1699/3000 AVG Training Loss:0.213 AVG Test Loss:0.250\n",
            "Epoch:1700/3000 AVG Training Loss:0.070 AVG Test Loss:0.371\n",
            "Epoch:1701/3000 AVG Training Loss:0.194 AVG Test Loss:0.099\n",
            "Epoch:1702/3000 AVG Training Loss:0.108 AVG Test Loss:0.364\n",
            "Epoch:1703/3000 AVG Training Loss:0.203 AVG Test Loss:0.262\n",
            "Epoch:1704/3000 AVG Training Loss:0.207 AVG Test Loss:0.283\n",
            "Epoch:1705/3000 AVG Training Loss:0.142 AVG Test Loss:0.126\n",
            "Epoch:1706/3000 AVG Training Loss:0.168 AVG Test Loss:0.096\n",
            "Epoch:1707/3000 AVG Training Loss:0.118 AVG Test Loss:0.300\n",
            "Epoch:1708/3000 AVG Training Loss:0.160 AVG Test Loss:0.100\n",
            "Epoch:1709/3000 AVG Training Loss:0.119 AVG Test Loss:0.112\n",
            "Epoch:1710/3000 AVG Training Loss:0.124 AVG Test Loss:0.251\n",
            "Epoch:1711/3000 AVG Training Loss:0.129 AVG Test Loss:0.277\n",
            "Epoch:1712/3000 AVG Training Loss:0.107 AVG Test Loss:0.265\n",
            "Epoch:1713/3000 AVG Training Loss:0.176 AVG Test Loss:0.225\n",
            "Epoch:1714/3000 AVG Training Loss:0.086 AVG Test Loss:0.268\n",
            "Epoch:1715/3000 AVG Training Loss:0.147 AVG Test Loss:0.158\n",
            "Epoch:1716/3000 AVG Training Loss:0.176 AVG Test Loss:0.115\n",
            "Epoch:1717/3000 AVG Training Loss:0.116 AVG Test Loss:0.162\n",
            "Epoch:1718/3000 AVG Training Loss:0.129 AVG Test Loss:0.127\n",
            "Epoch:1719/3000 AVG Training Loss:0.136 AVG Test Loss:0.123\n",
            "Epoch:1720/3000 AVG Training Loss:0.111 AVG Test Loss:0.168\n",
            "Epoch:1721/3000 AVG Training Loss:0.176 AVG Test Loss:0.343\n",
            "Epoch:1722/3000 AVG Training Loss:0.230 AVG Test Loss:0.139\n",
            "Epoch:1723/3000 AVG Training Loss:0.110 AVG Test Loss:0.278\n",
            "Epoch:1724/3000 AVG Training Loss:0.088 AVG Test Loss:0.235\n",
            "Epoch:1725/3000 AVG Training Loss:0.158 AVG Test Loss:0.082\n",
            "Epoch:1726/3000 AVG Training Loss:0.205 AVG Test Loss:0.302\n",
            "Epoch:1727/3000 AVG Training Loss:0.113 AVG Test Loss:0.200\n",
            "Epoch:1728/3000 AVG Training Loss:0.180 AVG Test Loss:0.315\n",
            "Epoch:1729/3000 AVG Training Loss:0.187 AVG Test Loss:0.315\n",
            "Epoch:1730/3000 AVG Training Loss:0.207 AVG Test Loss:0.067\n",
            "Epoch:1731/3000 AVG Training Loss:0.107 AVG Test Loss:0.270\n",
            "Epoch:1732/3000 AVG Training Loss:0.136 AVG Test Loss:0.226\n",
            "Epoch:1733/3000 AVG Training Loss:0.188 AVG Test Loss:0.221\n",
            "Epoch:1734/3000 AVG Training Loss:0.207 AVG Test Loss:0.160\n",
            "Epoch:1735/3000 AVG Training Loss:0.140 AVG Test Loss:0.215\n",
            "Epoch:1736/3000 AVG Training Loss:0.182 AVG Test Loss:0.194\n",
            "Epoch:1737/3000 AVG Training Loss:0.165 AVG Test Loss:0.149\n",
            "Epoch:1738/3000 AVG Training Loss:0.209 AVG Test Loss:0.125\n",
            "Epoch:1739/3000 AVG Training Loss:0.156 AVG Test Loss:0.195\n",
            "Epoch:1740/3000 AVG Training Loss:0.095 AVG Test Loss:0.071\n",
            "Epoch:1741/3000 AVG Training Loss:0.147 AVG Test Loss:0.045\n",
            "Epoch:1742/3000 AVG Training Loss:0.240 AVG Test Loss:0.169\n",
            "Epoch:1743/3000 AVG Training Loss:0.135 AVG Test Loss:0.233\n",
            "Epoch:1744/3000 AVG Training Loss:0.225 AVG Test Loss:0.126\n",
            "Epoch:1745/3000 AVG Training Loss:0.194 AVG Test Loss:0.066\n",
            "Epoch:1746/3000 AVG Training Loss:0.183 AVG Test Loss:0.285\n",
            "Epoch:1747/3000 AVG Training Loss:0.149 AVG Test Loss:0.249\n",
            "Epoch:1748/3000 AVG Training Loss:0.161 AVG Test Loss:0.087\n",
            "Epoch:1749/3000 AVG Training Loss:0.204 AVG Test Loss:0.107\n",
            "Epoch:1750/3000 AVG Training Loss:0.180 AVG Test Loss:0.138\n",
            "Epoch:1751/3000 AVG Training Loss:0.137 AVG Test Loss:0.149\n",
            "Epoch:1752/3000 AVG Training Loss:0.205 AVG Test Loss:0.136\n",
            "Epoch:1753/3000 AVG Training Loss:0.169 AVG Test Loss:0.319\n",
            "Epoch:1754/3000 AVG Training Loss:0.160 AVG Test Loss:0.103\n",
            "Epoch:1755/3000 AVG Training Loss:0.156 AVG Test Loss:0.186\n",
            "Epoch:1756/3000 AVG Training Loss:0.169 AVG Test Loss:0.280\n",
            "Epoch:1757/3000 AVG Training Loss:0.175 AVG Test Loss:0.137\n",
            "Epoch:1758/3000 AVG Training Loss:0.134 AVG Test Loss:0.187\n",
            "Epoch:1759/3000 AVG Training Loss:0.165 AVG Test Loss:0.257\n",
            "Epoch:1760/3000 AVG Training Loss:0.215 AVG Test Loss:0.168\n",
            "Epoch:1761/3000 AVG Training Loss:0.126 AVG Test Loss:0.228\n",
            "Epoch:1762/3000 AVG Training Loss:0.160 AVG Test Loss:0.162\n",
            "Epoch:1763/3000 AVG Training Loss:0.094 AVG Test Loss:0.125\n",
            "Epoch:1764/3000 AVG Training Loss:0.165 AVG Test Loss:0.120\n",
            "Epoch:1765/3000 AVG Training Loss:0.171 AVG Test Loss:0.120\n",
            "Epoch:1766/3000 AVG Training Loss:0.170 AVG Test Loss:0.290\n",
            "Epoch:1767/3000 AVG Training Loss:0.130 AVG Test Loss:0.188\n",
            "Epoch:1768/3000 AVG Training Loss:0.197 AVG Test Loss:0.114\n",
            "Epoch:1769/3000 AVG Training Loss:0.126 AVG Test Loss:0.208\n",
            "Epoch:1770/3000 AVG Training Loss:0.131 AVG Test Loss:0.100\n",
            "Epoch:1771/3000 AVG Training Loss:0.198 AVG Test Loss:0.334\n",
            "Epoch:1772/3000 AVG Training Loss:0.105 AVG Test Loss:0.123\n",
            "Epoch:1773/3000 AVG Training Loss:0.121 AVG Test Loss:0.267\n",
            "Epoch:1774/3000 AVG Training Loss:0.141 AVG Test Loss:0.130\n",
            "Epoch:1775/3000 AVG Training Loss:0.162 AVG Test Loss:0.219\n",
            "Epoch:1776/3000 AVG Training Loss:0.186 AVG Test Loss:0.097\n",
            "Epoch:1777/3000 AVG Training Loss:0.154 AVG Test Loss:0.164\n",
            "Epoch:1778/3000 AVG Training Loss:0.233 AVG Test Loss:0.206\n",
            "Epoch:1779/3000 AVG Training Loss:0.125 AVG Test Loss:0.086\n",
            "Epoch:1780/3000 AVG Training Loss:0.164 AVG Test Loss:0.216\n",
            "Epoch:1781/3000 AVG Training Loss:0.144 AVG Test Loss:0.312\n",
            "Epoch:1782/3000 AVG Training Loss:0.181 AVG Test Loss:0.291\n",
            "Epoch:1783/3000 AVG Training Loss:0.281 AVG Test Loss:0.143\n",
            "Epoch:1784/3000 AVG Training Loss:0.119 AVG Test Loss:0.240\n",
            "Epoch:1785/3000 AVG Training Loss:0.221 AVG Test Loss:0.229\n",
            "Epoch:1786/3000 AVG Training Loss:0.194 AVG Test Loss:0.125\n",
            "Epoch:1787/3000 AVG Training Loss:0.077 AVG Test Loss:0.215\n",
            "Epoch:1788/3000 AVG Training Loss:0.204 AVG Test Loss:0.310\n",
            "Epoch:1789/3000 AVG Training Loss:0.164 AVG Test Loss:0.098\n",
            "Epoch:1790/3000 AVG Training Loss:0.203 AVG Test Loss:0.221\n",
            "Epoch:1791/3000 AVG Training Loss:0.114 AVG Test Loss:0.196\n",
            "Epoch:1792/3000 AVG Training Loss:0.229 AVG Test Loss:0.214\n",
            "Epoch:1793/3000 AVG Training Loss:0.137 AVG Test Loss:0.354\n",
            "Epoch:1794/3000 AVG Training Loss:0.183 AVG Test Loss:0.201\n",
            "Epoch:1795/3000 AVG Training Loss:0.109 AVG Test Loss:0.117\n",
            "Epoch:1796/3000 AVG Training Loss:0.109 AVG Test Loss:0.044\n",
            "Epoch:1797/3000 AVG Training Loss:0.134 AVG Test Loss:0.168\n",
            "Epoch:1798/3000 AVG Training Loss:0.095 AVG Test Loss:0.140\n",
            "Epoch:1799/3000 AVG Training Loss:0.106 AVG Test Loss:0.243\n",
            "Epoch:1800/3000 AVG Training Loss:0.165 AVG Test Loss:0.084\n",
            "Epoch:1801/3000 AVG Training Loss:0.086 AVG Test Loss:0.282\n",
            "Epoch:1802/3000 AVG Training Loss:0.103 AVG Test Loss:0.138\n",
            "Epoch:1803/3000 AVG Training Loss:0.130 AVG Test Loss:0.044\n",
            "Epoch:1804/3000 AVG Training Loss:0.186 AVG Test Loss:0.052\n",
            "Epoch:1805/3000 AVG Training Loss:0.186 AVG Test Loss:0.103\n",
            "Epoch:1806/3000 AVG Training Loss:0.148 AVG Test Loss:0.215\n",
            "Epoch:1807/3000 AVG Training Loss:0.143 AVG Test Loss:0.351\n",
            "Epoch:1808/3000 AVG Training Loss:0.087 AVG Test Loss:0.203\n",
            "Epoch:1809/3000 AVG Training Loss:0.122 AVG Test Loss:0.124\n",
            "Epoch:1810/3000 AVG Training Loss:0.176 AVG Test Loss:0.156\n",
            "Epoch:1811/3000 AVG Training Loss:0.130 AVG Test Loss:0.164\n",
            "Epoch:1812/3000 AVG Training Loss:0.220 AVG Test Loss:0.219\n",
            "Epoch:1813/3000 AVG Training Loss:0.072 AVG Test Loss:0.064\n",
            "Epoch:1814/3000 AVG Training Loss:0.168 AVG Test Loss:0.170\n",
            "Epoch:1815/3000 AVG Training Loss:0.253 AVG Test Loss:0.084\n",
            "Epoch:1816/3000 AVG Training Loss:0.145 AVG Test Loss:0.148\n",
            "Epoch:1817/3000 AVG Training Loss:0.250 AVG Test Loss:0.215\n",
            "Epoch:1818/3000 AVG Training Loss:0.278 AVG Test Loss:0.189\n",
            "Epoch:1819/3000 AVG Training Loss:0.061 AVG Test Loss:0.210\n",
            "Epoch:1820/3000 AVG Training Loss:0.096 AVG Test Loss:0.213\n",
            "Epoch:1821/3000 AVG Training Loss:0.212 AVG Test Loss:0.235\n",
            "Epoch:1822/3000 AVG Training Loss:0.109 AVG Test Loss:0.122\n",
            "Epoch:1823/3000 AVG Training Loss:0.220 AVG Test Loss:0.271\n",
            "Epoch:1824/3000 AVG Training Loss:0.214 AVG Test Loss:0.276\n",
            "Epoch:1825/3000 AVG Training Loss:0.141 AVG Test Loss:0.173\n",
            "Epoch:1826/3000 AVG Training Loss:0.186 AVG Test Loss:0.199\n",
            "Epoch:1827/3000 AVG Training Loss:0.156 AVG Test Loss:0.239\n",
            "Epoch:1828/3000 AVG Training Loss:0.189 AVG Test Loss:0.393\n",
            "Epoch:1829/3000 AVG Training Loss:0.120 AVG Test Loss:0.227\n",
            "Epoch:1830/3000 AVG Training Loss:0.193 AVG Test Loss:0.100\n",
            "Epoch:1831/3000 AVG Training Loss:0.151 AVG Test Loss:0.089\n",
            "Epoch:1832/3000 AVG Training Loss:0.164 AVG Test Loss:0.235\n",
            "Epoch:1833/3000 AVG Training Loss:0.250 AVG Test Loss:0.192\n",
            "Epoch:1834/3000 AVG Training Loss:0.143 AVG Test Loss:0.238\n",
            "Epoch:1835/3000 AVG Training Loss:0.137 AVG Test Loss:0.041\n",
            "Epoch:1836/3000 AVG Training Loss:0.162 AVG Test Loss:0.276\n",
            "Epoch:1837/3000 AVG Training Loss:0.155 AVG Test Loss:0.203\n",
            "Epoch:1838/3000 AVG Training Loss:0.249 AVG Test Loss:0.158\n",
            "Epoch:1839/3000 AVG Training Loss:0.120 AVG Test Loss:0.256\n",
            "Epoch:1840/3000 AVG Training Loss:0.169 AVG Test Loss:0.168\n",
            "Epoch:1841/3000 AVG Training Loss:0.120 AVG Test Loss:0.192\n",
            "Epoch:1842/3000 AVG Training Loss:0.079 AVG Test Loss:0.217\n",
            "Epoch:1843/3000 AVG Training Loss:0.131 AVG Test Loss:0.158\n",
            "Epoch:1844/3000 AVG Training Loss:0.292 AVG Test Loss:0.181\n",
            "Epoch:1845/3000 AVG Training Loss:0.140 AVG Test Loss:0.283\n",
            "Epoch:1846/3000 AVG Training Loss:0.143 AVG Test Loss:0.185\n",
            "Epoch:1847/3000 AVG Training Loss:0.137 AVG Test Loss:0.147\n",
            "Epoch:1848/3000 AVG Training Loss:0.075 AVG Test Loss:0.247\n",
            "Epoch:1849/3000 AVG Training Loss:0.053 AVG Test Loss:0.262\n",
            "Epoch:1850/3000 AVG Training Loss:0.213 AVG Test Loss:0.390\n",
            "Epoch:1851/3000 AVG Training Loss:0.076 AVG Test Loss:0.229\n",
            "Epoch:1852/3000 AVG Training Loss:0.113 AVG Test Loss:0.162\n",
            "Epoch:1853/3000 AVG Training Loss:0.224 AVG Test Loss:0.218\n",
            "Epoch:1854/3000 AVG Training Loss:0.153 AVG Test Loss:0.281\n",
            "Epoch:1855/3000 AVG Training Loss:0.184 AVG Test Loss:0.169\n",
            "Epoch:1856/3000 AVG Training Loss:0.114 AVG Test Loss:0.163\n",
            "Epoch:1857/3000 AVG Training Loss:0.110 AVG Test Loss:0.137\n",
            "Epoch:1858/3000 AVG Training Loss:0.180 AVG Test Loss:0.097\n",
            "Epoch:1859/3000 AVG Training Loss:0.108 AVG Test Loss:0.149\n",
            "Epoch:1860/3000 AVG Training Loss:0.127 AVG Test Loss:0.265\n",
            "Epoch:1861/3000 AVG Training Loss:0.132 AVG Test Loss:0.106\n",
            "Epoch:1862/3000 AVG Training Loss:0.144 AVG Test Loss:0.251\n",
            "Epoch:1863/3000 AVG Training Loss:0.169 AVG Test Loss:0.157\n",
            "Epoch:1864/3000 AVG Training Loss:0.194 AVG Test Loss:0.291\n",
            "Epoch:1865/3000 AVG Training Loss:0.110 AVG Test Loss:0.365\n",
            "Epoch:1866/3000 AVG Training Loss:0.306 AVG Test Loss:0.179\n",
            "Epoch:1867/3000 AVG Training Loss:0.092 AVG Test Loss:0.102\n",
            "Epoch:1868/3000 AVG Training Loss:0.166 AVG Test Loss:0.173\n",
            "Epoch:1869/3000 AVG Training Loss:0.329 AVG Test Loss:0.070\n",
            "Epoch:1870/3000 AVG Training Loss:0.160 AVG Test Loss:0.197\n",
            "Epoch:1871/3000 AVG Training Loss:0.151 AVG Test Loss:0.284\n",
            "Epoch:1872/3000 AVG Training Loss:0.179 AVG Test Loss:0.207\n",
            "Epoch:1873/3000 AVG Training Loss:0.098 AVG Test Loss:0.081\n",
            "Epoch:1874/3000 AVG Training Loss:0.115 AVG Test Loss:0.257\n",
            "Epoch:1875/3000 AVG Training Loss:0.138 AVG Test Loss:0.093\n",
            "Epoch:1876/3000 AVG Training Loss:0.172 AVG Test Loss:0.067\n",
            "Epoch:1877/3000 AVG Training Loss:0.267 AVG Test Loss:0.148\n",
            "Epoch:1878/3000 AVG Training Loss:0.108 AVG Test Loss:0.090\n",
            "Epoch:1879/3000 AVG Training Loss:0.137 AVG Test Loss:0.140\n",
            "Epoch:1880/3000 AVG Training Loss:0.129 AVG Test Loss:0.068\n",
            "Epoch:1881/3000 AVG Training Loss:0.057 AVG Test Loss:0.166\n",
            "Epoch:1882/3000 AVG Training Loss:0.151 AVG Test Loss:0.158\n",
            "Epoch:1883/3000 AVG Training Loss:0.292 AVG Test Loss:0.088\n",
            "Epoch:1884/3000 AVG Training Loss:0.241 AVG Test Loss:0.240\n",
            "Epoch:1885/3000 AVG Training Loss:0.182 AVG Test Loss:0.118\n",
            "Epoch:1886/3000 AVG Training Loss:0.147 AVG Test Loss:0.167\n",
            "Epoch:1887/3000 AVG Training Loss:0.162 AVG Test Loss:0.156\n",
            "Epoch:1888/3000 AVG Training Loss:0.148 AVG Test Loss:0.143\n",
            "Epoch:1889/3000 AVG Training Loss:0.131 AVG Test Loss:0.137\n",
            "Epoch:1890/3000 AVG Training Loss:0.147 AVG Test Loss:0.071\n",
            "Epoch:1891/3000 AVG Training Loss:0.171 AVG Test Loss:0.127\n",
            "Epoch:1892/3000 AVG Training Loss:0.198 AVG Test Loss:0.095\n",
            "Epoch:1893/3000 AVG Training Loss:0.267 AVG Test Loss:0.072\n",
            "Epoch:1894/3000 AVG Training Loss:0.107 AVG Test Loss:0.069\n",
            "Epoch:1895/3000 AVG Training Loss:0.200 AVG Test Loss:0.111\n",
            "Epoch:1896/3000 AVG Training Loss:0.189 AVG Test Loss:0.115\n",
            "Epoch:1897/3000 AVG Training Loss:0.139 AVG Test Loss:0.448\n",
            "Epoch:1898/3000 AVG Training Loss:0.069 AVG Test Loss:0.213\n",
            "Epoch:1899/3000 AVG Training Loss:0.196 AVG Test Loss:0.136\n",
            "Epoch:1900/3000 AVG Training Loss:0.115 AVG Test Loss:0.096\n",
            "Epoch:1901/3000 AVG Training Loss:0.209 AVG Test Loss:0.172\n",
            "Epoch:1902/3000 AVG Training Loss:0.153 AVG Test Loss:0.300\n",
            "Epoch:1903/3000 AVG Training Loss:0.196 AVG Test Loss:0.330\n",
            "Epoch:1904/3000 AVG Training Loss:0.144 AVG Test Loss:0.274\n",
            "Epoch:1905/3000 AVG Training Loss:0.099 AVG Test Loss:0.094\n",
            "Epoch:1906/3000 AVG Training Loss:0.085 AVG Test Loss:0.055\n",
            "Epoch:1907/3000 AVG Training Loss:0.110 AVG Test Loss:0.203\n",
            "Epoch:1908/3000 AVG Training Loss:0.181 AVG Test Loss:0.173\n",
            "Epoch:1909/3000 AVG Training Loss:0.087 AVG Test Loss:0.110\n",
            "Epoch:1910/3000 AVG Training Loss:0.081 AVG Test Loss:0.104\n",
            "Epoch:1911/3000 AVG Training Loss:0.214 AVG Test Loss:0.236\n",
            "Epoch:1912/3000 AVG Training Loss:0.086 AVG Test Loss:0.130\n",
            "Epoch:1913/3000 AVG Training Loss:0.180 AVG Test Loss:0.124\n",
            "Epoch:1914/3000 AVG Training Loss:0.188 AVG Test Loss:0.164\n",
            "Epoch:1915/3000 AVG Training Loss:0.090 AVG Test Loss:0.237\n",
            "Epoch:1916/3000 AVG Training Loss:0.178 AVG Test Loss:0.331\n",
            "Epoch:1917/3000 AVG Training Loss:0.186 AVG Test Loss:0.179\n",
            "Epoch:1918/3000 AVG Training Loss:0.070 AVG Test Loss:0.201\n",
            "Epoch:1919/3000 AVG Training Loss:0.143 AVG Test Loss:0.151\n",
            "Epoch:1920/3000 AVG Training Loss:0.157 AVG Test Loss:0.206\n",
            "Epoch:1921/3000 AVG Training Loss:0.188 AVG Test Loss:0.159\n",
            "Epoch:1922/3000 AVG Training Loss:0.180 AVG Test Loss:0.069\n",
            "Epoch:1923/3000 AVG Training Loss:0.120 AVG Test Loss:0.058\n",
            "Epoch:1924/3000 AVG Training Loss:0.131 AVG Test Loss:0.238\n",
            "Epoch:1925/3000 AVG Training Loss:0.139 AVG Test Loss:0.120\n",
            "Epoch:1926/3000 AVG Training Loss:0.180 AVG Test Loss:0.216\n",
            "Epoch:1927/3000 AVG Training Loss:0.157 AVG Test Loss:0.180\n",
            "Epoch:1928/3000 AVG Training Loss:0.177 AVG Test Loss:0.105\n",
            "Epoch:1929/3000 AVG Training Loss:0.101 AVG Test Loss:0.152\n",
            "Epoch:1930/3000 AVG Training Loss:0.146 AVG Test Loss:0.231\n",
            "Epoch:1931/3000 AVG Training Loss:0.177 AVG Test Loss:0.254\n",
            "Epoch:1932/3000 AVG Training Loss:0.190 AVG Test Loss:0.264\n",
            "Epoch:1933/3000 AVG Training Loss:0.190 AVG Test Loss:0.178\n",
            "Epoch:1934/3000 AVG Training Loss:0.195 AVG Test Loss:0.166\n",
            "Epoch:1935/3000 AVG Training Loss:0.094 AVG Test Loss:0.188\n",
            "Epoch:1936/3000 AVG Training Loss:0.089 AVG Test Loss:0.155\n",
            "Epoch:1937/3000 AVG Training Loss:0.167 AVG Test Loss:0.147\n",
            "Epoch:1938/3000 AVG Training Loss:0.227 AVG Test Loss:0.122\n",
            "Epoch:1939/3000 AVG Training Loss:0.243 AVG Test Loss:0.436\n",
            "Epoch:1940/3000 AVG Training Loss:0.140 AVG Test Loss:0.146\n",
            "Epoch:1941/3000 AVG Training Loss:0.167 AVG Test Loss:0.104\n",
            "Epoch:1942/3000 AVG Training Loss:0.069 AVG Test Loss:0.149\n",
            "Epoch:1943/3000 AVG Training Loss:0.131 AVG Test Loss:0.098\n",
            "Epoch:1944/3000 AVG Training Loss:0.118 AVG Test Loss:0.191\n",
            "Epoch:1945/3000 AVG Training Loss:0.113 AVG Test Loss:0.247\n",
            "Epoch:1946/3000 AVG Training Loss:0.121 AVG Test Loss:0.063\n",
            "Epoch:1947/3000 AVG Training Loss:0.188 AVG Test Loss:0.108\n",
            "Epoch:1948/3000 AVG Training Loss:0.107 AVG Test Loss:0.094\n",
            "Epoch:1949/3000 AVG Training Loss:0.187 AVG Test Loss:0.179\n",
            "Epoch:1950/3000 AVG Training Loss:0.182 AVG Test Loss:0.120\n",
            "Epoch:1951/3000 AVG Training Loss:0.143 AVG Test Loss:0.358\n",
            "Epoch:1952/3000 AVG Training Loss:0.235 AVG Test Loss:0.236\n",
            "Epoch:1953/3000 AVG Training Loss:0.158 AVG Test Loss:0.153\n",
            "Epoch:1954/3000 AVG Training Loss:0.123 AVG Test Loss:0.368\n",
            "Epoch:1955/3000 AVG Training Loss:0.209 AVG Test Loss:0.227\n",
            "Epoch:1956/3000 AVG Training Loss:0.145 AVG Test Loss:0.174\n",
            "Epoch:1957/3000 AVG Training Loss:0.191 AVG Test Loss:0.257\n",
            "Epoch:1958/3000 AVG Training Loss:0.098 AVG Test Loss:0.199\n",
            "Epoch:1959/3000 AVG Training Loss:0.143 AVG Test Loss:0.131\n",
            "Epoch:1960/3000 AVG Training Loss:0.245 AVG Test Loss:0.257\n",
            "Epoch:1961/3000 AVG Training Loss:0.225 AVG Test Loss:0.194\n",
            "Epoch:1962/3000 AVG Training Loss:0.212 AVG Test Loss:0.132\n",
            "Epoch:1963/3000 AVG Training Loss:0.103 AVG Test Loss:0.175\n",
            "Epoch:1964/3000 AVG Training Loss:0.217 AVG Test Loss:0.220\n",
            "Epoch:1965/3000 AVG Training Loss:0.126 AVG Test Loss:0.155\n",
            "Epoch:1966/3000 AVG Training Loss:0.171 AVG Test Loss:0.091\n",
            "Epoch:1967/3000 AVG Training Loss:0.088 AVG Test Loss:0.351\n",
            "Epoch:1968/3000 AVG Training Loss:0.130 AVG Test Loss:0.133\n",
            "Epoch:1969/3000 AVG Training Loss:0.107 AVG Test Loss:0.128\n",
            "Epoch:1970/3000 AVG Training Loss:0.154 AVG Test Loss:0.171\n",
            "Epoch:1971/3000 AVG Training Loss:0.122 AVG Test Loss:0.206\n",
            "Epoch:1972/3000 AVG Training Loss:0.257 AVG Test Loss:0.111\n",
            "Epoch:1973/3000 AVG Training Loss:0.182 AVG Test Loss:0.148\n",
            "Epoch:1974/3000 AVG Training Loss:0.167 AVG Test Loss:0.076\n",
            "Epoch:1975/3000 AVG Training Loss:0.119 AVG Test Loss:0.234\n",
            "Epoch:1976/3000 AVG Training Loss:0.164 AVG Test Loss:0.182\n",
            "Epoch:1977/3000 AVG Training Loss:0.113 AVG Test Loss:0.333\n",
            "Epoch:1978/3000 AVG Training Loss:0.145 AVG Test Loss:0.247\n",
            "Epoch:1979/3000 AVG Training Loss:0.108 AVG Test Loss:0.123\n",
            "Epoch:1980/3000 AVG Training Loss:0.119 AVG Test Loss:0.094\n",
            "Epoch:1981/3000 AVG Training Loss:0.129 AVG Test Loss:0.201\n",
            "Epoch:1982/3000 AVG Training Loss:0.103 AVG Test Loss:0.272\n",
            "Epoch:1983/3000 AVG Training Loss:0.084 AVG Test Loss:0.276\n",
            "Epoch:1984/3000 AVG Training Loss:0.158 AVG Test Loss:0.274\n",
            "Epoch:1985/3000 AVG Training Loss:0.191 AVG Test Loss:0.123\n",
            "Epoch:1986/3000 AVG Training Loss:0.169 AVG Test Loss:0.368\n",
            "Epoch:1987/3000 AVG Training Loss:0.125 AVG Test Loss:0.106\n",
            "Epoch:1988/3000 AVG Training Loss:0.134 AVG Test Loss:0.164\n",
            "Epoch:1989/3000 AVG Training Loss:0.144 AVG Test Loss:0.090\n",
            "Epoch:1990/3000 AVG Training Loss:0.135 AVG Test Loss:0.146\n",
            "Epoch:1991/3000 AVG Training Loss:0.152 AVG Test Loss:0.228\n",
            "Epoch:1992/3000 AVG Training Loss:0.149 AVG Test Loss:0.417\n",
            "Epoch:1993/3000 AVG Training Loss:0.073 AVG Test Loss:0.274\n",
            "Epoch:1994/3000 AVG Training Loss:0.130 AVG Test Loss:0.329\n",
            "Epoch:1995/3000 AVG Training Loss:0.239 AVG Test Loss:0.088\n",
            "Epoch:1996/3000 AVG Training Loss:0.115 AVG Test Loss:0.143\n",
            "Epoch:1997/3000 AVG Training Loss:0.123 AVG Test Loss:0.145\n",
            "Epoch:1998/3000 AVG Training Loss:0.137 AVG Test Loss:0.171\n",
            "Epoch:1999/3000 AVG Training Loss:0.135 AVG Test Loss:0.139\n",
            "Epoch:2000/3000 AVG Training Loss:0.230 AVG Test Loss:0.187\n",
            "Epoch:2001/3000 AVG Training Loss:0.168 AVG Test Loss:0.356\n",
            "Epoch:2002/3000 AVG Training Loss:0.117 AVG Test Loss:0.124\n",
            "Epoch:2003/3000 AVG Training Loss:0.109 AVG Test Loss:0.251\n",
            "Epoch:2004/3000 AVG Training Loss:0.114 AVG Test Loss:0.103\n",
            "Epoch:2005/3000 AVG Training Loss:0.099 AVG Test Loss:0.140\n",
            "Epoch:2006/3000 AVG Training Loss:0.122 AVG Test Loss:0.032\n",
            "Epoch:2007/3000 AVG Training Loss:0.079 AVG Test Loss:0.125\n",
            "Epoch:2008/3000 AVG Training Loss:0.131 AVG Test Loss:0.362\n",
            "Epoch:2009/3000 AVG Training Loss:0.103 AVG Test Loss:0.233\n",
            "Epoch:2010/3000 AVG Training Loss:0.117 AVG Test Loss:0.228\n",
            "Epoch:2011/3000 AVG Training Loss:0.068 AVG Test Loss:0.308\n",
            "Epoch:2012/3000 AVG Training Loss:0.163 AVG Test Loss:0.198\n",
            "Epoch:2013/3000 AVG Training Loss:0.145 AVG Test Loss:0.293\n",
            "Epoch:2014/3000 AVG Training Loss:0.130 AVG Test Loss:0.241\n",
            "Epoch:2015/3000 AVG Training Loss:0.087 AVG Test Loss:0.081\n",
            "Epoch:2016/3000 AVG Training Loss:0.069 AVG Test Loss:0.089\n",
            "Epoch:2017/3000 AVG Training Loss:0.216 AVG Test Loss:0.145\n",
            "Epoch:2018/3000 AVG Training Loss:0.341 AVG Test Loss:0.219\n",
            "Epoch:2019/3000 AVG Training Loss:0.173 AVG Test Loss:0.380\n",
            "Epoch:2020/3000 AVG Training Loss:0.145 AVG Test Loss:0.198\n",
            "Epoch:2021/3000 AVG Training Loss:0.095 AVG Test Loss:0.202\n",
            "Epoch:2022/3000 AVG Training Loss:0.067 AVG Test Loss:0.149\n",
            "Epoch:2023/3000 AVG Training Loss:0.121 AVG Test Loss:0.213\n",
            "Epoch:2024/3000 AVG Training Loss:0.146 AVG Test Loss:0.169\n",
            "Epoch:2025/3000 AVG Training Loss:0.084 AVG Test Loss:0.211\n",
            "Epoch:2026/3000 AVG Training Loss:0.176 AVG Test Loss:0.269\n",
            "Epoch:2027/3000 AVG Training Loss:0.149 AVG Test Loss:0.285\n",
            "Epoch:2028/3000 AVG Training Loss:0.139 AVG Test Loss:0.150\n",
            "Epoch:2029/3000 AVG Training Loss:0.080 AVG Test Loss:0.125\n",
            "Epoch:2030/3000 AVG Training Loss:0.089 AVG Test Loss:0.085\n",
            "Epoch:2031/3000 AVG Training Loss:0.190 AVG Test Loss:0.083\n",
            "Epoch:2032/3000 AVG Training Loss:0.227 AVG Test Loss:0.270\n",
            "Epoch:2033/3000 AVG Training Loss:0.128 AVG Test Loss:0.223\n",
            "Epoch:2034/3000 AVG Training Loss:0.160 AVG Test Loss:0.300\n",
            "Epoch:2035/3000 AVG Training Loss:0.083 AVG Test Loss:0.118\n",
            "Epoch:2036/3000 AVG Training Loss:0.123 AVG Test Loss:0.107\n",
            "Epoch:2037/3000 AVG Training Loss:0.093 AVG Test Loss:0.156\n",
            "Epoch:2038/3000 AVG Training Loss:0.150 AVG Test Loss:0.268\n",
            "Epoch:2039/3000 AVG Training Loss:0.149 AVG Test Loss:0.235\n",
            "Epoch:2040/3000 AVG Training Loss:0.076 AVG Test Loss:0.239\n",
            "Epoch:2041/3000 AVG Training Loss:0.140 AVG Test Loss:0.030\n",
            "Epoch:2042/3000 AVG Training Loss:0.097 AVG Test Loss:0.245\n",
            "Epoch:2043/3000 AVG Training Loss:0.185 AVG Test Loss:0.093\n",
            "Epoch:2044/3000 AVG Training Loss:0.101 AVG Test Loss:0.031\n",
            "Epoch:2045/3000 AVG Training Loss:0.108 AVG Test Loss:0.306\n",
            "Epoch:2046/3000 AVG Training Loss:0.179 AVG Test Loss:0.113\n",
            "Epoch:2047/3000 AVG Training Loss:0.113 AVG Test Loss:0.125\n",
            "Epoch:2048/3000 AVG Training Loss:0.088 AVG Test Loss:0.167\n",
            "Epoch:2049/3000 AVG Training Loss:0.277 AVG Test Loss:0.210\n",
            "Epoch:2050/3000 AVG Training Loss:0.235 AVG Test Loss:0.115\n",
            "Epoch:2051/3000 AVG Training Loss:0.093 AVG Test Loss:0.146\n",
            "Epoch:2052/3000 AVG Training Loss:0.152 AVG Test Loss:0.212\n",
            "Epoch:2053/3000 AVG Training Loss:0.111 AVG Test Loss:0.081\n",
            "Epoch:2054/3000 AVG Training Loss:0.137 AVG Test Loss:0.085\n",
            "Epoch:2055/3000 AVG Training Loss:0.119 AVG Test Loss:0.112\n",
            "Epoch:2056/3000 AVG Training Loss:0.087 AVG Test Loss:0.213\n",
            "Epoch:2057/3000 AVG Training Loss:0.158 AVG Test Loss:0.108\n",
            "Epoch:2058/3000 AVG Training Loss:0.110 AVG Test Loss:0.233\n",
            "Epoch:2059/3000 AVG Training Loss:0.123 AVG Test Loss:0.128\n",
            "Epoch:2060/3000 AVG Training Loss:0.239 AVG Test Loss:0.124\n",
            "Epoch:2061/3000 AVG Training Loss:0.161 AVG Test Loss:0.151\n",
            "Epoch:2062/3000 AVG Training Loss:0.102 AVG Test Loss:0.418\n",
            "Epoch:2063/3000 AVG Training Loss:0.146 AVG Test Loss:0.058\n",
            "Epoch:2064/3000 AVG Training Loss:0.100 AVG Test Loss:0.392\n",
            "Epoch:2065/3000 AVG Training Loss:0.154 AVG Test Loss:0.276\n",
            "Epoch:2066/3000 AVG Training Loss:0.104 AVG Test Loss:0.195\n",
            "Epoch:2067/3000 AVG Training Loss:0.149 AVG Test Loss:0.194\n",
            "Epoch:2068/3000 AVG Training Loss:0.099 AVG Test Loss:0.216\n",
            "Epoch:2069/3000 AVG Training Loss:0.083 AVG Test Loss:0.320\n",
            "Epoch:2070/3000 AVG Training Loss:0.106 AVG Test Loss:0.134\n",
            "Epoch:2071/3000 AVG Training Loss:0.126 AVG Test Loss:0.181\n",
            "Epoch:2072/3000 AVG Training Loss:0.186 AVG Test Loss:0.205\n",
            "Epoch:2073/3000 AVG Training Loss:0.227 AVG Test Loss:0.215\n",
            "Epoch:2074/3000 AVG Training Loss:0.128 AVG Test Loss:0.106\n",
            "Epoch:2075/3000 AVG Training Loss:0.074 AVG Test Loss:0.065\n",
            "Epoch:2076/3000 AVG Training Loss:0.179 AVG Test Loss:0.157\n",
            "Epoch:2077/3000 AVG Training Loss:0.100 AVG Test Loss:0.106\n",
            "Epoch:2078/3000 AVG Training Loss:0.083 AVG Test Loss:0.126\n",
            "Epoch:2079/3000 AVG Training Loss:0.117 AVG Test Loss:0.223\n",
            "Epoch:2080/3000 AVG Training Loss:0.171 AVG Test Loss:0.081\n",
            "Epoch:2081/3000 AVG Training Loss:0.105 AVG Test Loss:0.184\n",
            "Epoch:2082/3000 AVG Training Loss:0.126 AVG Test Loss:0.042\n",
            "Epoch:2083/3000 AVG Training Loss:0.099 AVG Test Loss:0.333\n",
            "Epoch:2084/3000 AVG Training Loss:0.134 AVG Test Loss:0.150\n",
            "Epoch:2085/3000 AVG Training Loss:0.082 AVG Test Loss:0.199\n",
            "Epoch:2086/3000 AVG Training Loss:0.118 AVG Test Loss:0.069\n",
            "Epoch:2087/3000 AVG Training Loss:0.167 AVG Test Loss:0.094\n",
            "Epoch:2088/3000 AVG Training Loss:0.137 AVG Test Loss:0.147\n",
            "Epoch:2089/3000 AVG Training Loss:0.120 AVG Test Loss:0.359\n",
            "Epoch:2090/3000 AVG Training Loss:0.297 AVG Test Loss:0.066\n",
            "Epoch:2091/3000 AVG Training Loss:0.097 AVG Test Loss:0.253\n",
            "Epoch:2092/3000 AVG Training Loss:0.197 AVG Test Loss:0.561\n",
            "Epoch:2093/3000 AVG Training Loss:0.227 AVG Test Loss:0.261\n",
            "Epoch:2094/3000 AVG Training Loss:0.171 AVG Test Loss:0.167\n",
            "Epoch:2095/3000 AVG Training Loss:0.115 AVG Test Loss:0.144\n",
            "Epoch:2096/3000 AVG Training Loss:0.143 AVG Test Loss:0.172\n",
            "Epoch:2097/3000 AVG Training Loss:0.197 AVG Test Loss:0.295\n",
            "Epoch:2098/3000 AVG Training Loss:0.104 AVG Test Loss:0.071\n",
            "Epoch:2099/3000 AVG Training Loss:0.150 AVG Test Loss:0.201\n",
            "Epoch:2100/3000 AVG Training Loss:0.116 AVG Test Loss:0.046\n",
            "Epoch:2101/3000 AVG Training Loss:0.099 AVG Test Loss:0.181\n",
            "Epoch:2102/3000 AVG Training Loss:0.106 AVG Test Loss:0.110\n",
            "Epoch:2103/3000 AVG Training Loss:0.149 AVG Test Loss:0.195\n",
            "Epoch:2104/3000 AVG Training Loss:0.147 AVG Test Loss:0.111\n",
            "Epoch:2105/3000 AVG Training Loss:0.092 AVG Test Loss:0.267\n",
            "Epoch:2106/3000 AVG Training Loss:0.064 AVG Test Loss:0.179\n",
            "Epoch:2107/3000 AVG Training Loss:0.160 AVG Test Loss:0.131\n",
            "Epoch:2108/3000 AVG Training Loss:0.175 AVG Test Loss:0.128\n",
            "Epoch:2109/3000 AVG Training Loss:0.101 AVG Test Loss:0.246\n",
            "Epoch:2110/3000 AVG Training Loss:0.125 AVG Test Loss:0.077\n",
            "Epoch:2111/3000 AVG Training Loss:0.134 AVG Test Loss:0.105\n",
            "Epoch:2112/3000 AVG Training Loss:0.124 AVG Test Loss:0.045\n",
            "Epoch:2113/3000 AVG Training Loss:0.162 AVG Test Loss:0.329\n",
            "Epoch:2114/3000 AVG Training Loss:0.173 AVG Test Loss:0.090\n",
            "Epoch:2115/3000 AVG Training Loss:0.131 AVG Test Loss:0.115\n",
            "Epoch:2116/3000 AVG Training Loss:0.128 AVG Test Loss:0.075\n",
            "Epoch:2117/3000 AVG Training Loss:0.165 AVG Test Loss:0.189\n",
            "Epoch:2118/3000 AVG Training Loss:0.083 AVG Test Loss:0.186\n",
            "Epoch:2119/3000 AVG Training Loss:0.144 AVG Test Loss:0.435\n",
            "Epoch:2120/3000 AVG Training Loss:0.143 AVG Test Loss:0.153\n",
            "Epoch:2121/3000 AVG Training Loss:0.142 AVG Test Loss:0.156\n",
            "Epoch:2122/3000 AVG Training Loss:0.083 AVG Test Loss:0.178\n",
            "Epoch:2123/3000 AVG Training Loss:0.238 AVG Test Loss:0.224\n",
            "Epoch:2124/3000 AVG Training Loss:0.130 AVG Test Loss:0.282\n",
            "Epoch:2125/3000 AVG Training Loss:0.149 AVG Test Loss:0.100\n",
            "Epoch:2126/3000 AVG Training Loss:0.098 AVG Test Loss:0.081\n",
            "Epoch:2127/3000 AVG Training Loss:0.176 AVG Test Loss:0.211\n",
            "Epoch:2128/3000 AVG Training Loss:0.142 AVG Test Loss:0.065\n",
            "Epoch:2129/3000 AVG Training Loss:0.085 AVG Test Loss:0.358\n",
            "Epoch:2130/3000 AVG Training Loss:0.149 AVG Test Loss:0.234\n",
            "Epoch:2131/3000 AVG Training Loss:0.103 AVG Test Loss:0.190\n",
            "Epoch:2132/3000 AVG Training Loss:0.259 AVG Test Loss:0.188\n",
            "Epoch:2133/3000 AVG Training Loss:0.207 AVG Test Loss:0.101\n",
            "Epoch:2134/3000 AVG Training Loss:0.115 AVG Test Loss:0.259\n",
            "Epoch:2135/3000 AVG Training Loss:0.220 AVG Test Loss:0.205\n",
            "Epoch:2136/3000 AVG Training Loss:0.114 AVG Test Loss:0.171\n",
            "Epoch:2137/3000 AVG Training Loss:0.113 AVG Test Loss:0.167\n",
            "Epoch:2138/3000 AVG Training Loss:0.093 AVG Test Loss:0.165\n",
            "Epoch:2139/3000 AVG Training Loss:0.116 AVG Test Loss:0.075\n",
            "Epoch:2140/3000 AVG Training Loss:0.211 AVG Test Loss:0.133\n",
            "Epoch:2141/3000 AVG Training Loss:0.220 AVG Test Loss:0.175\n",
            "Epoch:2142/3000 AVG Training Loss:0.218 AVG Test Loss:0.056\n",
            "Epoch:2143/3000 AVG Training Loss:0.136 AVG Test Loss:0.071\n",
            "Epoch:2144/3000 AVG Training Loss:0.093 AVG Test Loss:0.218\n",
            "Epoch:2145/3000 AVG Training Loss:0.150 AVG Test Loss:0.090\n",
            "Epoch:2146/3000 AVG Training Loss:0.166 AVG Test Loss:0.118\n",
            "Epoch:2147/3000 AVG Training Loss:0.089 AVG Test Loss:0.104\n",
            "Epoch:2148/3000 AVG Training Loss:0.134 AVG Test Loss:0.320\n",
            "Epoch:2149/3000 AVG Training Loss:0.177 AVG Test Loss:0.214\n",
            "Epoch:2150/3000 AVG Training Loss:0.104 AVG Test Loss:0.073\n",
            "Epoch:2151/3000 AVG Training Loss:0.091 AVG Test Loss:0.155\n",
            "Epoch:2152/3000 AVG Training Loss:0.113 AVG Test Loss:0.190\n",
            "Epoch:2153/3000 AVG Training Loss:0.128 AVG Test Loss:0.212\n",
            "Epoch:2154/3000 AVG Training Loss:0.209 AVG Test Loss:0.191\n",
            "Epoch:2155/3000 AVG Training Loss:0.103 AVG Test Loss:0.265\n",
            "Epoch:2156/3000 AVG Training Loss:0.102 AVG Test Loss:0.110\n",
            "Epoch:2157/3000 AVG Training Loss:0.076 AVG Test Loss:0.114\n",
            "Epoch:2158/3000 AVG Training Loss:0.100 AVG Test Loss:0.136\n",
            "Epoch:2159/3000 AVG Training Loss:0.086 AVG Test Loss:0.047\n",
            "Epoch:2160/3000 AVG Training Loss:0.164 AVG Test Loss:0.234\n",
            "Epoch:2161/3000 AVG Training Loss:0.092 AVG Test Loss:0.189\n",
            "Epoch:2162/3000 AVG Training Loss:0.163 AVG Test Loss:0.160\n",
            "Epoch:2163/3000 AVG Training Loss:0.245 AVG Test Loss:0.216\n",
            "Epoch:2164/3000 AVG Training Loss:0.143 AVG Test Loss:0.306\n",
            "Epoch:2165/3000 AVG Training Loss:0.148 AVG Test Loss:0.174\n",
            "Epoch:2166/3000 AVG Training Loss:0.083 AVG Test Loss:0.262\n",
            "Epoch:2167/3000 AVG Training Loss:0.106 AVG Test Loss:0.289\n",
            "Epoch:2168/3000 AVG Training Loss:0.130 AVG Test Loss:0.332\n",
            "Epoch:2169/3000 AVG Training Loss:0.124 AVG Test Loss:0.158\n",
            "Epoch:2170/3000 AVG Training Loss:0.133 AVG Test Loss:0.202\n",
            "Epoch:2171/3000 AVG Training Loss:0.211 AVG Test Loss:0.303\n",
            "Epoch:2172/3000 AVG Training Loss:0.134 AVG Test Loss:0.046\n",
            "Epoch:2173/3000 AVG Training Loss:0.196 AVG Test Loss:0.186\n",
            "Epoch:2174/3000 AVG Training Loss:0.105 AVG Test Loss:0.197\n",
            "Epoch:2175/3000 AVG Training Loss:0.108 AVG Test Loss:0.200\n",
            "Epoch:2176/3000 AVG Training Loss:0.243 AVG Test Loss:0.150\n",
            "Epoch:2177/3000 AVG Training Loss:0.200 AVG Test Loss:0.085\n",
            "Epoch:2178/3000 AVG Training Loss:0.087 AVG Test Loss:0.053\n",
            "Epoch:2179/3000 AVG Training Loss:0.117 AVG Test Loss:0.300\n",
            "Epoch:2180/3000 AVG Training Loss:0.103 AVG Test Loss:0.106\n",
            "Epoch:2181/3000 AVG Training Loss:0.232 AVG Test Loss:0.106\n",
            "Epoch:2182/3000 AVG Training Loss:0.102 AVG Test Loss:0.306\n",
            "Epoch:2183/3000 AVG Training Loss:0.098 AVG Test Loss:0.263\n",
            "Epoch:2184/3000 AVG Training Loss:0.105 AVG Test Loss:0.113\n",
            "Epoch:2185/3000 AVG Training Loss:0.100 AVG Test Loss:0.232\n",
            "Epoch:2186/3000 AVG Training Loss:0.164 AVG Test Loss:0.115\n",
            "Epoch:2187/3000 AVG Training Loss:0.117 AVG Test Loss:0.245\n",
            "Epoch:2188/3000 AVG Training Loss:0.202 AVG Test Loss:0.211\n",
            "Epoch:2189/3000 AVG Training Loss:0.120 AVG Test Loss:0.153\n",
            "Epoch:2190/3000 AVG Training Loss:0.117 AVG Test Loss:0.364\n",
            "Epoch:2191/3000 AVG Training Loss:0.113 AVG Test Loss:0.149\n",
            "Epoch:2192/3000 AVG Training Loss:0.224 AVG Test Loss:0.171\n",
            "Epoch:2193/3000 AVG Training Loss:0.125 AVG Test Loss:0.345\n",
            "Epoch:2194/3000 AVG Training Loss:0.208 AVG Test Loss:0.202\n",
            "Epoch:2195/3000 AVG Training Loss:0.112 AVG Test Loss:0.066\n",
            "Epoch:2196/3000 AVG Training Loss:0.072 AVG Test Loss:0.137\n",
            "Epoch:2197/3000 AVG Training Loss:0.118 AVG Test Loss:0.154\n",
            "Epoch:2198/3000 AVG Training Loss:0.137 AVG Test Loss:0.091\n",
            "Epoch:2199/3000 AVG Training Loss:0.198 AVG Test Loss:0.207\n",
            "Epoch:2200/3000 AVG Training Loss:0.079 AVG Test Loss:0.053\n",
            "Epoch:2201/3000 AVG Training Loss:0.121 AVG Test Loss:0.259\n",
            "Epoch:2202/3000 AVG Training Loss:0.140 AVG Test Loss:0.204\n",
            "Epoch:2203/3000 AVG Training Loss:0.163 AVG Test Loss:0.157\n",
            "Epoch:2204/3000 AVG Training Loss:0.131 AVG Test Loss:0.166\n",
            "Epoch:2205/3000 AVG Training Loss:0.166 AVG Test Loss:0.212\n",
            "Epoch:2206/3000 AVG Training Loss:0.069 AVG Test Loss:0.149\n",
            "Epoch:2207/3000 AVG Training Loss:0.096 AVG Test Loss:0.221\n",
            "Epoch:2208/3000 AVG Training Loss:0.153 AVG Test Loss:0.191\n",
            "Epoch:2209/3000 AVG Training Loss:0.206 AVG Test Loss:0.213\n",
            "Epoch:2210/3000 AVG Training Loss:0.258 AVG Test Loss:0.479\n",
            "Epoch:2211/3000 AVG Training Loss:0.188 AVG Test Loss:0.158\n",
            "Epoch:2212/3000 AVG Training Loss:0.073 AVG Test Loss:0.434\n",
            "Epoch:2213/3000 AVG Training Loss:0.156 AVG Test Loss:0.088\n",
            "Epoch:2214/3000 AVG Training Loss:0.168 AVG Test Loss:0.275\n",
            "Epoch:2215/3000 AVG Training Loss:0.119 AVG Test Loss:0.355\n",
            "Epoch:2216/3000 AVG Training Loss:0.102 AVG Test Loss:0.070\n",
            "Epoch:2217/3000 AVG Training Loss:0.117 AVG Test Loss:0.125\n",
            "Epoch:2218/3000 AVG Training Loss:0.174 AVG Test Loss:0.278\n",
            "Epoch:2219/3000 AVG Training Loss:0.170 AVG Test Loss:0.111\n",
            "Epoch:2220/3000 AVG Training Loss:0.140 AVG Test Loss:0.066\n",
            "Epoch:2221/3000 AVG Training Loss:0.137 AVG Test Loss:0.171\n",
            "Epoch:2222/3000 AVG Training Loss:0.258 AVG Test Loss:0.039\n",
            "Epoch:2223/3000 AVG Training Loss:0.138 AVG Test Loss:0.135\n",
            "Epoch:2224/3000 AVG Training Loss:0.118 AVG Test Loss:0.267\n",
            "Epoch:2225/3000 AVG Training Loss:0.188 AVG Test Loss:0.079\n",
            "Epoch:2226/3000 AVG Training Loss:0.106 AVG Test Loss:0.089\n",
            "Epoch:2227/3000 AVG Training Loss:0.152 AVG Test Loss:0.102\n",
            "Epoch:2228/3000 AVG Training Loss:0.072 AVG Test Loss:0.158\n",
            "Epoch:2229/3000 AVG Training Loss:0.107 AVG Test Loss:0.141\n",
            "Epoch:2230/3000 AVG Training Loss:0.149 AVG Test Loss:0.172\n",
            "Epoch:2231/3000 AVG Training Loss:0.176 AVG Test Loss:0.277\n",
            "Epoch:2232/3000 AVG Training Loss:0.168 AVG Test Loss:0.153\n",
            "Epoch:2233/3000 AVG Training Loss:0.092 AVG Test Loss:0.073\n",
            "Epoch:2234/3000 AVG Training Loss:0.073 AVG Test Loss:0.188\n",
            "Epoch:2235/3000 AVG Training Loss:0.164 AVG Test Loss:0.120\n",
            "Epoch:2236/3000 AVG Training Loss:0.150 AVG Test Loss:0.396\n",
            "Epoch:2237/3000 AVG Training Loss:0.098 AVG Test Loss:0.163\n",
            "Epoch:2238/3000 AVG Training Loss:0.154 AVG Test Loss:0.158\n",
            "Epoch:2239/3000 AVG Training Loss:0.156 AVG Test Loss:0.194\n",
            "Epoch:2240/3000 AVG Training Loss:0.109 AVG Test Loss:0.229\n",
            "Epoch:2241/3000 AVG Training Loss:0.090 AVG Test Loss:0.121\n",
            "Epoch:2242/3000 AVG Training Loss:0.167 AVG Test Loss:0.212\n",
            "Epoch:2243/3000 AVG Training Loss:0.107 AVG Test Loss:0.198\n",
            "Epoch:2244/3000 AVG Training Loss:0.185 AVG Test Loss:0.054\n",
            "Epoch:2245/3000 AVG Training Loss:0.174 AVG Test Loss:0.107\n",
            "Epoch:2246/3000 AVG Training Loss:0.065 AVG Test Loss:0.183\n",
            "Epoch:2247/3000 AVG Training Loss:0.147 AVG Test Loss:0.115\n",
            "Epoch:2248/3000 AVG Training Loss:0.097 AVG Test Loss:0.145\n",
            "Epoch:2249/3000 AVG Training Loss:0.144 AVG Test Loss:0.190\n",
            "Epoch:2250/3000 AVG Training Loss:0.126 AVG Test Loss:0.084\n",
            "Epoch:2251/3000 AVG Training Loss:0.160 AVG Test Loss:0.111\n",
            "Epoch:2252/3000 AVG Training Loss:0.203 AVG Test Loss:0.079\n",
            "Epoch:2253/3000 AVG Training Loss:0.084 AVG Test Loss:0.229\n",
            "Epoch:2254/3000 AVG Training Loss:0.120 AVG Test Loss:0.151\n",
            "Epoch:2255/3000 AVG Training Loss:0.103 AVG Test Loss:0.117\n",
            "Epoch:2256/3000 AVG Training Loss:0.148 AVG Test Loss:0.173\n",
            "Epoch:2257/3000 AVG Training Loss:0.114 AVG Test Loss:0.126\n",
            "Epoch:2258/3000 AVG Training Loss:0.146 AVG Test Loss:0.102\n",
            "Epoch:2259/3000 AVG Training Loss:0.104 AVG Test Loss:0.106\n",
            "Epoch:2260/3000 AVG Training Loss:0.139 AVG Test Loss:0.165\n",
            "Epoch:2261/3000 AVG Training Loss:0.155 AVG Test Loss:0.104\n",
            "Epoch:2262/3000 AVG Training Loss:0.089 AVG Test Loss:0.218\n",
            "Epoch:2263/3000 AVG Training Loss:0.170 AVG Test Loss:0.114\n",
            "Epoch:2264/3000 AVG Training Loss:0.089 AVG Test Loss:0.098\n",
            "Epoch:2265/3000 AVG Training Loss:0.181 AVG Test Loss:0.274\n",
            "Epoch:2266/3000 AVG Training Loss:0.196 AVG Test Loss:0.122\n",
            "Epoch:2267/3000 AVG Training Loss:0.124 AVG Test Loss:0.170\n",
            "Epoch:2268/3000 AVG Training Loss:0.141 AVG Test Loss:0.076\n",
            "Epoch:2269/3000 AVG Training Loss:0.120 AVG Test Loss:0.195\n",
            "Epoch:2270/3000 AVG Training Loss:0.135 AVG Test Loss:0.118\n",
            "Epoch:2271/3000 AVG Training Loss:0.067 AVG Test Loss:0.115\n",
            "Epoch:2272/3000 AVG Training Loss:0.151 AVG Test Loss:0.088\n",
            "Epoch:2273/3000 AVG Training Loss:0.078 AVG Test Loss:0.225\n",
            "Epoch:2274/3000 AVG Training Loss:0.159 AVG Test Loss:0.227\n",
            "Epoch:2275/3000 AVG Training Loss:0.132 AVG Test Loss:0.098\n",
            "Epoch:2276/3000 AVG Training Loss:0.197 AVG Test Loss:0.128\n",
            "Epoch:2277/3000 AVG Training Loss:0.115 AVG Test Loss:0.236\n",
            "Epoch:2278/3000 AVG Training Loss:0.142 AVG Test Loss:0.243\n",
            "Epoch:2279/3000 AVG Training Loss:0.175 AVG Test Loss:0.132\n",
            "Epoch:2280/3000 AVG Training Loss:0.107 AVG Test Loss:0.377\n",
            "Epoch:2281/3000 AVG Training Loss:0.122 AVG Test Loss:0.256\n",
            "Epoch:2282/3000 AVG Training Loss:0.150 AVG Test Loss:0.176\n",
            "Epoch:2283/3000 AVG Training Loss:0.119 AVG Test Loss:0.145\n",
            "Epoch:2284/3000 AVG Training Loss:0.081 AVG Test Loss:0.244\n",
            "Epoch:2285/3000 AVG Training Loss:0.139 AVG Test Loss:0.330\n",
            "Epoch:2286/3000 AVG Training Loss:0.090 AVG Test Loss:0.219\n",
            "Epoch:2287/3000 AVG Training Loss:0.075 AVG Test Loss:0.134\n",
            "Epoch:2288/3000 AVG Training Loss:0.121 AVG Test Loss:0.209\n",
            "Epoch:2289/3000 AVG Training Loss:0.116 AVG Test Loss:0.300\n",
            "Epoch:2290/3000 AVG Training Loss:0.189 AVG Test Loss:0.171\n",
            "Epoch:2291/3000 AVG Training Loss:0.188 AVG Test Loss:0.316\n",
            "Epoch:2292/3000 AVG Training Loss:0.130 AVG Test Loss:0.188\n",
            "Epoch:2293/3000 AVG Training Loss:0.138 AVG Test Loss:0.131\n",
            "Epoch:2294/3000 AVG Training Loss:0.111 AVG Test Loss:0.255\n",
            "Epoch:2295/3000 AVG Training Loss:0.119 AVG Test Loss:0.343\n",
            "Epoch:2296/3000 AVG Training Loss:0.151 AVG Test Loss:0.150\n",
            "Epoch:2297/3000 AVG Training Loss:0.158 AVG Test Loss:0.183\n",
            "Epoch:2298/3000 AVG Training Loss:0.136 AVG Test Loss:0.160\n",
            "Epoch:2299/3000 AVG Training Loss:0.150 AVG Test Loss:0.290\n",
            "Epoch:2300/3000 AVG Training Loss:0.129 AVG Test Loss:0.160\n",
            "Epoch:2301/3000 AVG Training Loss:0.137 AVG Test Loss:0.155\n",
            "Epoch:2302/3000 AVG Training Loss:0.099 AVG Test Loss:0.202\n",
            "Epoch:2303/3000 AVG Training Loss:0.064 AVG Test Loss:0.135\n",
            "Epoch:2304/3000 AVG Training Loss:0.103 AVG Test Loss:0.373\n",
            "Epoch:2305/3000 AVG Training Loss:0.151 AVG Test Loss:0.169\n",
            "Epoch:2306/3000 AVG Training Loss:0.131 AVG Test Loss:0.351\n",
            "Epoch:2307/3000 AVG Training Loss:0.168 AVG Test Loss:0.220\n",
            "Epoch:2308/3000 AVG Training Loss:0.114 AVG Test Loss:0.043\n",
            "Epoch:2309/3000 AVG Training Loss:0.155 AVG Test Loss:0.051\n",
            "Epoch:2310/3000 AVG Training Loss:0.073 AVG Test Loss:0.241\n",
            "Epoch:2311/3000 AVG Training Loss:0.113 AVG Test Loss:0.401\n",
            "Epoch:2312/3000 AVG Training Loss:0.117 AVG Test Loss:0.254\n",
            "Epoch:2313/3000 AVG Training Loss:0.077 AVG Test Loss:0.107\n",
            "Epoch:2314/3000 AVG Training Loss:0.167 AVG Test Loss:0.155\n",
            "Epoch:2315/3000 AVG Training Loss:0.127 AVG Test Loss:0.160\n",
            "Epoch:2316/3000 AVG Training Loss:0.184 AVG Test Loss:0.239\n",
            "Epoch:2317/3000 AVG Training Loss:0.081 AVG Test Loss:0.159\n",
            "Epoch:2318/3000 AVG Training Loss:0.144 AVG Test Loss:0.143\n",
            "Epoch:2319/3000 AVG Training Loss:0.105 AVG Test Loss:0.098\n",
            "Epoch:2320/3000 AVG Training Loss:0.092 AVG Test Loss:0.296\n",
            "Epoch:2321/3000 AVG Training Loss:0.063 AVG Test Loss:0.185\n",
            "Epoch:2322/3000 AVG Training Loss:0.051 AVG Test Loss:0.143\n",
            "Epoch:2323/3000 AVG Training Loss:0.168 AVG Test Loss:0.181\n",
            "Epoch:2324/3000 AVG Training Loss:0.187 AVG Test Loss:0.276\n",
            "Epoch:2325/3000 AVG Training Loss:0.168 AVG Test Loss:0.101\n",
            "Epoch:2326/3000 AVG Training Loss:0.160 AVG Test Loss:0.253\n",
            "Epoch:2327/3000 AVG Training Loss:0.086 AVG Test Loss:0.215\n",
            "Epoch:2328/3000 AVG Training Loss:0.185 AVG Test Loss:0.287\n",
            "Epoch:2329/3000 AVG Training Loss:0.157 AVG Test Loss:0.144\n",
            "Epoch:2330/3000 AVG Training Loss:0.074 AVG Test Loss:0.217\n",
            "Epoch:2331/3000 AVG Training Loss:0.108 AVG Test Loss:0.148\n",
            "Epoch:2332/3000 AVG Training Loss:0.260 AVG Test Loss:0.149\n",
            "Epoch:2333/3000 AVG Training Loss:0.134 AVG Test Loss:0.088\n",
            "Epoch:2334/3000 AVG Training Loss:0.153 AVG Test Loss:0.145\n",
            "Epoch:2335/3000 AVG Training Loss:0.146 AVG Test Loss:0.162\n",
            "Epoch:2336/3000 AVG Training Loss:0.115 AVG Test Loss:0.300\n",
            "Epoch:2337/3000 AVG Training Loss:0.110 AVG Test Loss:0.191\n",
            "Epoch:2338/3000 AVG Training Loss:0.096 AVG Test Loss:0.299\n",
            "Epoch:2339/3000 AVG Training Loss:0.050 AVG Test Loss:0.205\n",
            "Epoch:2340/3000 AVG Training Loss:0.146 AVG Test Loss:0.110\n",
            "Epoch:2341/3000 AVG Training Loss:0.111 AVG Test Loss:0.301\n",
            "Epoch:2342/3000 AVG Training Loss:0.100 AVG Test Loss:0.250\n",
            "Epoch:2343/3000 AVG Training Loss:0.041 AVG Test Loss:0.131\n",
            "Epoch:2344/3000 AVG Training Loss:0.155 AVG Test Loss:0.157\n",
            "Epoch:2345/3000 AVG Training Loss:0.050 AVG Test Loss:0.307\n",
            "Epoch:2346/3000 AVG Training Loss:0.120 AVG Test Loss:0.177\n",
            "Epoch:2347/3000 AVG Training Loss:0.180 AVG Test Loss:0.083\n",
            "Epoch:2348/3000 AVG Training Loss:0.187 AVG Test Loss:0.114\n",
            "Epoch:2349/3000 AVG Training Loss:0.122 AVG Test Loss:0.105\n",
            "Epoch:2350/3000 AVG Training Loss:0.045 AVG Test Loss:0.041\n",
            "Epoch:2351/3000 AVG Training Loss:0.068 AVG Test Loss:0.182\n",
            "Epoch:2352/3000 AVG Training Loss:0.053 AVG Test Loss:0.174\n",
            "Epoch:2353/3000 AVG Training Loss:0.173 AVG Test Loss:0.055\n",
            "Epoch:2354/3000 AVG Training Loss:0.118 AVG Test Loss:0.165\n",
            "Epoch:2355/3000 AVG Training Loss:0.126 AVG Test Loss:0.092\n",
            "Epoch:2356/3000 AVG Training Loss:0.230 AVG Test Loss:0.188\n",
            "Epoch:2357/3000 AVG Training Loss:0.191 AVG Test Loss:0.070\n",
            "Epoch:2358/3000 AVG Training Loss:0.111 AVG Test Loss:0.143\n",
            "Epoch:2359/3000 AVG Training Loss:0.129 AVG Test Loss:0.339\n",
            "Epoch:2360/3000 AVG Training Loss:0.232 AVG Test Loss:0.256\n",
            "Epoch:2361/3000 AVG Training Loss:0.146 AVG Test Loss:0.155\n",
            "Epoch:2362/3000 AVG Training Loss:0.169 AVG Test Loss:0.110\n",
            "Epoch:2363/3000 AVG Training Loss:0.068 AVG Test Loss:0.159\n",
            "Epoch:2364/3000 AVG Training Loss:0.100 AVG Test Loss:0.322\n",
            "Epoch:2365/3000 AVG Training Loss:0.166 AVG Test Loss:0.102\n",
            "Epoch:2366/3000 AVG Training Loss:0.193 AVG Test Loss:0.205\n",
            "Epoch:2367/3000 AVG Training Loss:0.140 AVG Test Loss:0.126\n",
            "Epoch:2368/3000 AVG Training Loss:0.099 AVG Test Loss:0.153\n",
            "Epoch:2369/3000 AVG Training Loss:0.051 AVG Test Loss:0.074\n",
            "Epoch:2370/3000 AVG Training Loss:0.136 AVG Test Loss:0.175\n",
            "Epoch:2371/3000 AVG Training Loss:0.129 AVG Test Loss:0.077\n",
            "Epoch:2372/3000 AVG Training Loss:0.119 AVG Test Loss:0.014\n",
            "Epoch:2373/3000 AVG Training Loss:0.085 AVG Test Loss:0.313\n",
            "Epoch:2374/3000 AVG Training Loss:0.146 AVG Test Loss:0.096\n",
            "Epoch:2375/3000 AVG Training Loss:0.275 AVG Test Loss:0.237\n",
            "Epoch:2376/3000 AVG Training Loss:0.163 AVG Test Loss:0.090\n",
            "Epoch:2377/3000 AVG Training Loss:0.098 AVG Test Loss:0.301\n",
            "Epoch:2378/3000 AVG Training Loss:0.134 AVG Test Loss:0.116\n",
            "Epoch:2379/3000 AVG Training Loss:0.127 AVG Test Loss:0.068\n",
            "Epoch:2380/3000 AVG Training Loss:0.111 AVG Test Loss:0.187\n",
            "Epoch:2381/3000 AVG Training Loss:0.219 AVG Test Loss:0.391\n",
            "Epoch:2382/3000 AVG Training Loss:0.205 AVG Test Loss:0.114\n",
            "Epoch:2383/3000 AVG Training Loss:0.088 AVG Test Loss:0.104\n",
            "Epoch:2384/3000 AVG Training Loss:0.128 AVG Test Loss:0.080\n",
            "Epoch:2385/3000 AVG Training Loss:0.125 AVG Test Loss:0.068\n",
            "Epoch:2386/3000 AVG Training Loss:0.112 AVG Test Loss:0.208\n",
            "Epoch:2387/3000 AVG Training Loss:0.168 AVG Test Loss:0.123\n",
            "Epoch:2388/3000 AVG Training Loss:0.073 AVG Test Loss:0.149\n",
            "Epoch:2389/3000 AVG Training Loss:0.109 AVG Test Loss:0.128\n",
            "Epoch:2390/3000 AVG Training Loss:0.128 AVG Test Loss:0.154\n",
            "Epoch:2391/3000 AVG Training Loss:0.111 AVG Test Loss:0.204\n",
            "Epoch:2392/3000 AVG Training Loss:0.115 AVG Test Loss:0.239\n",
            "Epoch:2393/3000 AVG Training Loss:0.096 AVG Test Loss:0.182\n",
            "Epoch:2394/3000 AVG Training Loss:0.131 AVG Test Loss:0.315\n",
            "Epoch:2395/3000 AVG Training Loss:0.126 AVG Test Loss:0.167\n",
            "Epoch:2396/3000 AVG Training Loss:0.106 AVG Test Loss:0.134\n",
            "Epoch:2397/3000 AVG Training Loss:0.127 AVG Test Loss:0.106\n",
            "Epoch:2398/3000 AVG Training Loss:0.060 AVG Test Loss:0.161\n",
            "Epoch:2399/3000 AVG Training Loss:0.121 AVG Test Loss:0.090\n",
            "Epoch:2400/3000 AVG Training Loss:0.091 AVG Test Loss:0.297\n",
            "Epoch:2401/3000 AVG Training Loss:0.135 AVG Test Loss:0.343\n",
            "Epoch:2402/3000 AVG Training Loss:0.162 AVG Test Loss:0.096\n",
            "Epoch:2403/3000 AVG Training Loss:0.062 AVG Test Loss:0.380\n",
            "Epoch:2404/3000 AVG Training Loss:0.168 AVG Test Loss:0.242\n",
            "Epoch:2405/3000 AVG Training Loss:0.108 AVG Test Loss:0.162\n",
            "Epoch:2406/3000 AVG Training Loss:0.157 AVG Test Loss:0.132\n",
            "Epoch:2407/3000 AVG Training Loss:0.075 AVG Test Loss:0.121\n",
            "Epoch:2408/3000 AVG Training Loss:0.145 AVG Test Loss:0.161\n",
            "Epoch:2409/3000 AVG Training Loss:0.248 AVG Test Loss:0.312\n",
            "Epoch:2410/3000 AVG Training Loss:0.204 AVG Test Loss:0.125\n",
            "Epoch:2411/3000 AVG Training Loss:0.124 AVG Test Loss:0.069\n",
            "Epoch:2412/3000 AVG Training Loss:0.094 AVG Test Loss:0.189\n",
            "Epoch:2413/3000 AVG Training Loss:0.118 AVG Test Loss:0.058\n",
            "Epoch:2414/3000 AVG Training Loss:0.125 AVG Test Loss:0.124\n",
            "Epoch:2415/3000 AVG Training Loss:0.120 AVG Test Loss:0.074\n",
            "Epoch:2416/3000 AVG Training Loss:0.161 AVG Test Loss:0.126\n",
            "Epoch:2417/3000 AVG Training Loss:0.130 AVG Test Loss:0.144\n",
            "Epoch:2418/3000 AVG Training Loss:0.080 AVG Test Loss:0.064\n",
            "Epoch:2419/3000 AVG Training Loss:0.214 AVG Test Loss:0.190\n",
            "Epoch:2420/3000 AVG Training Loss:0.281 AVG Test Loss:0.185\n",
            "Epoch:2421/3000 AVG Training Loss:0.179 AVG Test Loss:0.156\n",
            "Epoch:2422/3000 AVG Training Loss:0.085 AVG Test Loss:0.133\n",
            "Epoch:2423/3000 AVG Training Loss:0.147 AVG Test Loss:0.333\n",
            "Epoch:2424/3000 AVG Training Loss:0.169 AVG Test Loss:0.157\n",
            "Epoch:2425/3000 AVG Training Loss:0.094 AVG Test Loss:0.117\n",
            "Epoch:2426/3000 AVG Training Loss:0.155 AVG Test Loss:0.108\n",
            "Epoch:2427/3000 AVG Training Loss:0.187 AVG Test Loss:0.042\n",
            "Epoch:2428/3000 AVG Training Loss:0.081 AVG Test Loss:0.093\n",
            "Epoch:2429/3000 AVG Training Loss:0.090 AVG Test Loss:0.136\n",
            "Epoch:2430/3000 AVG Training Loss:0.147 AVG Test Loss:0.379\n",
            "Epoch:2431/3000 AVG Training Loss:0.108 AVG Test Loss:0.343\n",
            "Epoch:2432/3000 AVG Training Loss:0.159 AVG Test Loss:0.089\n",
            "Epoch:2433/3000 AVG Training Loss:0.111 AVG Test Loss:0.081\n",
            "Epoch:2434/3000 AVG Training Loss:0.085 AVG Test Loss:0.176\n",
            "Epoch:2435/3000 AVG Training Loss:0.205 AVG Test Loss:0.318\n",
            "Epoch:2436/3000 AVG Training Loss:0.149 AVG Test Loss:0.147\n",
            "Epoch:2437/3000 AVG Training Loss:0.140 AVG Test Loss:0.233\n",
            "Epoch:2438/3000 AVG Training Loss:0.127 AVG Test Loss:0.237\n",
            "Epoch:2439/3000 AVG Training Loss:0.088 AVG Test Loss:0.194\n",
            "Epoch:2440/3000 AVG Training Loss:0.144 AVG Test Loss:0.069\n",
            "Epoch:2441/3000 AVG Training Loss:0.124 AVG Test Loss:0.322\n",
            "Epoch:2442/3000 AVG Training Loss:0.118 AVG Test Loss:0.162\n",
            "Epoch:2443/3000 AVG Training Loss:0.198 AVG Test Loss:0.102\n",
            "Epoch:2444/3000 AVG Training Loss:0.097 AVG Test Loss:0.203\n",
            "Epoch:2445/3000 AVG Training Loss:0.106 AVG Test Loss:0.112\n",
            "Epoch:2446/3000 AVG Training Loss:0.066 AVG Test Loss:0.089\n",
            "Epoch:2447/3000 AVG Training Loss:0.108 AVG Test Loss:0.252\n",
            "Epoch:2448/3000 AVG Training Loss:0.121 AVG Test Loss:0.064\n",
            "Epoch:2449/3000 AVG Training Loss:0.085 AVG Test Loss:0.098\n",
            "Epoch:2450/3000 AVG Training Loss:0.170 AVG Test Loss:0.196\n",
            "Epoch:2451/3000 AVG Training Loss:0.155 AVG Test Loss:0.074\n",
            "Epoch:2452/3000 AVG Training Loss:0.080 AVG Test Loss:0.374\n",
            "Epoch:2453/3000 AVG Training Loss:0.152 AVG Test Loss:0.155\n",
            "Epoch:2454/3000 AVG Training Loss:0.103 AVG Test Loss:0.286\n",
            "Epoch:2455/3000 AVG Training Loss:0.200 AVG Test Loss:0.142\n",
            "Epoch:2456/3000 AVG Training Loss:0.112 AVG Test Loss:0.211\n",
            "Epoch:2457/3000 AVG Training Loss:0.115 AVG Test Loss:0.119\n",
            "Epoch:2458/3000 AVG Training Loss:0.067 AVG Test Loss:0.070\n",
            "Epoch:2459/3000 AVG Training Loss:0.159 AVG Test Loss:0.112\n",
            "Epoch:2460/3000 AVG Training Loss:0.078 AVG Test Loss:0.082\n",
            "Epoch:2461/3000 AVG Training Loss:0.085 AVG Test Loss:0.138\n",
            "Epoch:2462/3000 AVG Training Loss:0.130 AVG Test Loss:0.018\n",
            "Epoch:2463/3000 AVG Training Loss:0.089 AVG Test Loss:0.165\n",
            "Epoch:2464/3000 AVG Training Loss:0.199 AVG Test Loss:0.197\n",
            "Epoch:2465/3000 AVG Training Loss:0.185 AVG Test Loss:0.308\n",
            "Epoch:2466/3000 AVG Training Loss:0.068 AVG Test Loss:0.095\n",
            "Epoch:2467/3000 AVG Training Loss:0.121 AVG Test Loss:0.058\n",
            "Epoch:2468/3000 AVG Training Loss:0.089 AVG Test Loss:0.081\n",
            "Epoch:2469/3000 AVG Training Loss:0.088 AVG Test Loss:0.124\n",
            "Epoch:2470/3000 AVG Training Loss:0.168 AVG Test Loss:0.066\n",
            "Epoch:2471/3000 AVG Training Loss:0.124 AVG Test Loss:0.249\n",
            "Epoch:2472/3000 AVG Training Loss:0.129 AVG Test Loss:0.196\n",
            "Epoch:2473/3000 AVG Training Loss:0.135 AVG Test Loss:0.128\n",
            "Epoch:2474/3000 AVG Training Loss:0.059 AVG Test Loss:0.033\n",
            "Epoch:2475/3000 AVG Training Loss:0.101 AVG Test Loss:0.214\n",
            "Epoch:2476/3000 AVG Training Loss:0.177 AVG Test Loss:0.302\n",
            "Epoch:2477/3000 AVG Training Loss:0.049 AVG Test Loss:0.169\n",
            "Epoch:2478/3000 AVG Training Loss:0.130 AVG Test Loss:0.340\n",
            "Epoch:2479/3000 AVG Training Loss:0.135 AVG Test Loss:0.128\n",
            "Epoch:2480/3000 AVG Training Loss:0.130 AVG Test Loss:0.348\n",
            "Epoch:2481/3000 AVG Training Loss:0.198 AVG Test Loss:0.185\n",
            "Epoch:2482/3000 AVG Training Loss:0.104 AVG Test Loss:0.138\n",
            "Epoch:2483/3000 AVG Training Loss:0.140 AVG Test Loss:0.133\n",
            "Epoch:2484/3000 AVG Training Loss:0.171 AVG Test Loss:0.256\n",
            "Epoch:2485/3000 AVG Training Loss:0.107 AVG Test Loss:0.255\n",
            "Epoch:2486/3000 AVG Training Loss:0.120 AVG Test Loss:0.246\n",
            "Epoch:2487/3000 AVG Training Loss:0.073 AVG Test Loss:0.063\n",
            "Epoch:2488/3000 AVG Training Loss:0.069 AVG Test Loss:0.051\n",
            "Epoch:2489/3000 AVG Training Loss:0.218 AVG Test Loss:0.088\n",
            "Epoch:2490/3000 AVG Training Loss:0.042 AVG Test Loss:0.408\n",
            "Epoch:2491/3000 AVG Training Loss:0.162 AVG Test Loss:0.263\n",
            "Epoch:2492/3000 AVG Training Loss:0.090 AVG Test Loss:0.341\n",
            "Epoch:2493/3000 AVG Training Loss:0.189 AVG Test Loss:0.306\n",
            "Epoch:2494/3000 AVG Training Loss:0.134 AVG Test Loss:0.139\n",
            "Epoch:2495/3000 AVG Training Loss:0.130 AVG Test Loss:0.321\n",
            "Epoch:2496/3000 AVG Training Loss:0.093 AVG Test Loss:0.186\n",
            "Epoch:2497/3000 AVG Training Loss:0.115 AVG Test Loss:0.211\n",
            "Epoch:2498/3000 AVG Training Loss:0.096 AVG Test Loss:0.135\n",
            "Epoch:2499/3000 AVG Training Loss:0.128 AVG Test Loss:0.046\n",
            "Epoch:2500/3000 AVG Training Loss:0.179 AVG Test Loss:0.149\n",
            "Epoch:2501/3000 AVG Training Loss:0.140 AVG Test Loss:0.090\n",
            "Epoch:2502/3000 AVG Training Loss:0.093 AVG Test Loss:0.106\n",
            "Epoch:2503/3000 AVG Training Loss:0.162 AVG Test Loss:0.114\n",
            "Epoch:2504/3000 AVG Training Loss:0.062 AVG Test Loss:0.100\n",
            "Epoch:2505/3000 AVG Training Loss:0.169 AVG Test Loss:0.025\n",
            "Epoch:2506/3000 AVG Training Loss:0.065 AVG Test Loss:0.085\n",
            "Epoch:2507/3000 AVG Training Loss:0.174 AVG Test Loss:0.095\n",
            "Epoch:2508/3000 AVG Training Loss:0.126 AVG Test Loss:0.137\n",
            "Epoch:2509/3000 AVG Training Loss:0.243 AVG Test Loss:0.157\n",
            "Epoch:2510/3000 AVG Training Loss:0.113 AVG Test Loss:0.105\n",
            "Epoch:2511/3000 AVG Training Loss:0.104 AVG Test Loss:0.143\n",
            "Epoch:2512/3000 AVG Training Loss:0.159 AVG Test Loss:0.201\n",
            "Epoch:2513/3000 AVG Training Loss:0.102 AVG Test Loss:0.145\n",
            "Epoch:2514/3000 AVG Training Loss:0.090 AVG Test Loss:0.151\n",
            "Epoch:2515/3000 AVG Training Loss:0.127 AVG Test Loss:0.093\n",
            "Epoch:2516/3000 AVG Training Loss:0.174 AVG Test Loss:0.260\n",
            "Epoch:2517/3000 AVG Training Loss:0.210 AVG Test Loss:0.267\n",
            "Epoch:2518/3000 AVG Training Loss:0.168 AVG Test Loss:0.037\n",
            "Epoch:2519/3000 AVG Training Loss:0.119 AVG Test Loss:0.120\n",
            "Epoch:2520/3000 AVG Training Loss:0.064 AVG Test Loss:0.086\n",
            "Epoch:2521/3000 AVG Training Loss:0.073 AVG Test Loss:0.179\n",
            "Epoch:2522/3000 AVG Training Loss:0.054 AVG Test Loss:0.337\n",
            "Epoch:2523/3000 AVG Training Loss:0.086 AVG Test Loss:0.136\n",
            "Epoch:2524/3000 AVG Training Loss:0.088 AVG Test Loss:0.208\n",
            "Epoch:2525/3000 AVG Training Loss:0.114 AVG Test Loss:0.316\n",
            "Epoch:2526/3000 AVG Training Loss:0.099 AVG Test Loss:0.420\n",
            "Epoch:2527/3000 AVG Training Loss:0.089 AVG Test Loss:0.305\n",
            "Epoch:2528/3000 AVG Training Loss:0.116 AVG Test Loss:0.073\n",
            "Epoch:2529/3000 AVG Training Loss:0.103 AVG Test Loss:0.165\n",
            "Epoch:2530/3000 AVG Training Loss:0.145 AVG Test Loss:0.136\n",
            "Epoch:2531/3000 AVG Training Loss:0.116 AVG Test Loss:0.275\n",
            "Epoch:2532/3000 AVG Training Loss:0.103 AVG Test Loss:0.196\n",
            "Epoch:2533/3000 AVG Training Loss:0.084 AVG Test Loss:0.173\n",
            "Epoch:2534/3000 AVG Training Loss:0.141 AVG Test Loss:0.069\n",
            "Epoch:2535/3000 AVG Training Loss:0.182 AVG Test Loss:0.274\n",
            "Epoch:2536/3000 AVG Training Loss:0.082 AVG Test Loss:0.160\n",
            "Epoch:2537/3000 AVG Training Loss:0.185 AVG Test Loss:0.129\n",
            "Epoch:2538/3000 AVG Training Loss:0.107 AVG Test Loss:0.340\n",
            "Epoch:2539/3000 AVG Training Loss:0.086 AVG Test Loss:0.037\n",
            "Epoch:2540/3000 AVG Training Loss:0.160 AVG Test Loss:0.207\n",
            "Epoch:2541/3000 AVG Training Loss:0.170 AVG Test Loss:0.159\n",
            "Epoch:2542/3000 AVG Training Loss:0.095 AVG Test Loss:0.243\n",
            "Epoch:2543/3000 AVG Training Loss:0.094 AVG Test Loss:0.084\n",
            "Epoch:2544/3000 AVG Training Loss:0.127 AVG Test Loss:0.171\n",
            "Epoch:2545/3000 AVG Training Loss:0.146 AVG Test Loss:0.084\n",
            "Epoch:2546/3000 AVG Training Loss:0.094 AVG Test Loss:0.192\n",
            "Epoch:2547/3000 AVG Training Loss:0.146 AVG Test Loss:0.101\n",
            "Epoch:2548/3000 AVG Training Loss:0.232 AVG Test Loss:0.066\n",
            "Epoch:2549/3000 AVG Training Loss:0.126 AVG Test Loss:0.171\n",
            "Epoch:2550/3000 AVG Training Loss:0.078 AVG Test Loss:0.261\n",
            "Epoch:2551/3000 AVG Training Loss:0.150 AVG Test Loss:0.236\n",
            "Epoch:2552/3000 AVG Training Loss:0.161 AVG Test Loss:0.046\n",
            "Epoch:2553/3000 AVG Training Loss:0.248 AVG Test Loss:0.137\n",
            "Epoch:2554/3000 AVG Training Loss:0.170 AVG Test Loss:0.122\n",
            "Epoch:2555/3000 AVG Training Loss:0.124 AVG Test Loss:0.142\n",
            "Epoch:2556/3000 AVG Training Loss:0.155 AVG Test Loss:0.092\n",
            "Epoch:2557/3000 AVG Training Loss:0.096 AVG Test Loss:0.155\n",
            "Epoch:2558/3000 AVG Training Loss:0.129 AVG Test Loss:0.105\n",
            "Epoch:2559/3000 AVG Training Loss:0.243 AVG Test Loss:0.110\n",
            "Epoch:2560/3000 AVG Training Loss:0.122 AVG Test Loss:0.144\n",
            "Epoch:2561/3000 AVG Training Loss:0.186 AVG Test Loss:0.218\n",
            "Epoch:2562/3000 AVG Training Loss:0.097 AVG Test Loss:0.040\n",
            "Epoch:2563/3000 AVG Training Loss:0.088 AVG Test Loss:0.030\n",
            "Epoch:2564/3000 AVG Training Loss:0.105 AVG Test Loss:0.248\n",
            "Epoch:2565/3000 AVG Training Loss:0.256 AVG Test Loss:0.040\n",
            "Epoch:2566/3000 AVG Training Loss:0.079 AVG Test Loss:0.262\n",
            "Epoch:2567/3000 AVG Training Loss:0.073 AVG Test Loss:0.207\n",
            "Epoch:2568/3000 AVG Training Loss:0.154 AVG Test Loss:0.041\n",
            "Epoch:2569/3000 AVG Training Loss:0.182 AVG Test Loss:0.202\n",
            "Epoch:2570/3000 AVG Training Loss:0.094 AVG Test Loss:0.420\n",
            "Epoch:2571/3000 AVG Training Loss:0.063 AVG Test Loss:0.154\n",
            "Epoch:2572/3000 AVG Training Loss:0.166 AVG Test Loss:0.041\n",
            "Epoch:2573/3000 AVG Training Loss:0.117 AVG Test Loss:0.075\n",
            "Epoch:2574/3000 AVG Training Loss:0.140 AVG Test Loss:0.177\n",
            "Epoch:2575/3000 AVG Training Loss:0.168 AVG Test Loss:0.151\n",
            "Epoch:2576/3000 AVG Training Loss:0.161 AVG Test Loss:0.126\n",
            "Epoch:2577/3000 AVG Training Loss:0.087 AVG Test Loss:0.145\n",
            "Epoch:2578/3000 AVG Training Loss:0.086 AVG Test Loss:0.228\n",
            "Epoch:2579/3000 AVG Training Loss:0.163 AVG Test Loss:0.165\n",
            "Epoch:2580/3000 AVG Training Loss:0.173 AVG Test Loss:0.053\n",
            "Epoch:2581/3000 AVG Training Loss:0.177 AVG Test Loss:0.288\n",
            "Epoch:2582/3000 AVG Training Loss:0.092 AVG Test Loss:0.142\n",
            "Epoch:2583/3000 AVG Training Loss:0.094 AVG Test Loss:0.203\n",
            "Epoch:2584/3000 AVG Training Loss:0.215 AVG Test Loss:0.070\n",
            "Epoch:2585/3000 AVG Training Loss:0.071 AVG Test Loss:0.181\n",
            "Epoch:2586/3000 AVG Training Loss:0.123 AVG Test Loss:0.154\n",
            "Epoch:2587/3000 AVG Training Loss:0.118 AVG Test Loss:0.094\n",
            "Epoch:2588/3000 AVG Training Loss:0.104 AVG Test Loss:0.143\n",
            "Epoch:2589/3000 AVG Training Loss:0.112 AVG Test Loss:0.216\n",
            "Epoch:2590/3000 AVG Training Loss:0.195 AVG Test Loss:0.103\n",
            "Epoch:2591/3000 AVG Training Loss:0.150 AVG Test Loss:0.278\n",
            "Epoch:2592/3000 AVG Training Loss:0.139 AVG Test Loss:0.217\n",
            "Epoch:2593/3000 AVG Training Loss:0.082 AVG Test Loss:0.214\n",
            "Epoch:2594/3000 AVG Training Loss:0.141 AVG Test Loss:0.251\n",
            "Epoch:2595/3000 AVG Training Loss:0.082 AVG Test Loss:0.062\n",
            "Epoch:2596/3000 AVG Training Loss:0.128 AVG Test Loss:0.225\n",
            "Epoch:2597/3000 AVG Training Loss:0.094 AVG Test Loss:0.046\n",
            "Epoch:2598/3000 AVG Training Loss:0.089 AVG Test Loss:0.350\n",
            "Epoch:2599/3000 AVG Training Loss:0.091 AVG Test Loss:0.048\n",
            "Epoch:2600/3000 AVG Training Loss:0.097 AVG Test Loss:0.161\n",
            "Epoch:2601/3000 AVG Training Loss:0.114 AVG Test Loss:0.095\n",
            "Epoch:2602/3000 AVG Training Loss:0.097 AVG Test Loss:0.275\n",
            "Epoch:2603/3000 AVG Training Loss:0.143 AVG Test Loss:0.108\n",
            "Epoch:2604/3000 AVG Training Loss:0.096 AVG Test Loss:0.083\n",
            "Epoch:2605/3000 AVG Training Loss:0.128 AVG Test Loss:0.335\n",
            "Epoch:2606/3000 AVG Training Loss:0.115 AVG Test Loss:0.094\n",
            "Epoch:2607/3000 AVG Training Loss:0.127 AVG Test Loss:0.217\n",
            "Epoch:2608/3000 AVG Training Loss:0.083 AVG Test Loss:0.340\n",
            "Epoch:2609/3000 AVG Training Loss:0.082 AVG Test Loss:0.115\n",
            "Epoch:2610/3000 AVG Training Loss:0.090 AVG Test Loss:0.057\n",
            "Epoch:2611/3000 AVG Training Loss:0.093 AVG Test Loss:0.140\n",
            "Epoch:2612/3000 AVG Training Loss:0.162 AVG Test Loss:0.193\n",
            "Epoch:2613/3000 AVG Training Loss:0.134 AVG Test Loss:0.055\n",
            "Epoch:2614/3000 AVG Training Loss:0.086 AVG Test Loss:0.233\n",
            "Epoch:2615/3000 AVG Training Loss:0.055 AVG Test Loss:0.160\n",
            "Epoch:2616/3000 AVG Training Loss:0.164 AVG Test Loss:0.214\n",
            "Epoch:2617/3000 AVG Training Loss:0.198 AVG Test Loss:0.169\n",
            "Epoch:2618/3000 AVG Training Loss:0.108 AVG Test Loss:0.135\n",
            "Epoch:2619/3000 AVG Training Loss:0.137 AVG Test Loss:0.259\n",
            "Epoch:2620/3000 AVG Training Loss:0.147 AVG Test Loss:0.124\n",
            "Epoch:2621/3000 AVG Training Loss:0.129 AVG Test Loss:0.228\n",
            "Epoch:2622/3000 AVG Training Loss:0.085 AVG Test Loss:0.034\n",
            "Epoch:2623/3000 AVG Training Loss:0.115 AVG Test Loss:0.122\n",
            "Epoch:2624/3000 AVG Training Loss:0.063 AVG Test Loss:0.037\n",
            "Epoch:2625/3000 AVG Training Loss:0.127 AVG Test Loss:0.133\n",
            "Epoch:2626/3000 AVG Training Loss:0.201 AVG Test Loss:0.227\n",
            "Epoch:2627/3000 AVG Training Loss:0.150 AVG Test Loss:0.112\n",
            "Epoch:2628/3000 AVG Training Loss:0.243 AVG Test Loss:0.127\n",
            "Epoch:2629/3000 AVG Training Loss:0.157 AVG Test Loss:0.115\n",
            "Epoch:2630/3000 AVG Training Loss:0.159 AVG Test Loss:0.089\n",
            "Epoch:2631/3000 AVG Training Loss:0.120 AVG Test Loss:0.147\n",
            "Epoch:2632/3000 AVG Training Loss:0.213 AVG Test Loss:0.244\n",
            "Epoch:2633/3000 AVG Training Loss:0.219 AVG Test Loss:0.137\n",
            "Epoch:2634/3000 AVG Training Loss:0.097 AVG Test Loss:0.213\n",
            "Epoch:2635/3000 AVG Training Loss:0.157 AVG Test Loss:0.064\n",
            "Epoch:2636/3000 AVG Training Loss:0.114 AVG Test Loss:0.093\n",
            "Epoch:2637/3000 AVG Training Loss:0.197 AVG Test Loss:0.096\n",
            "Epoch:2638/3000 AVG Training Loss:0.091 AVG Test Loss:0.052\n",
            "Epoch:2639/3000 AVG Training Loss:0.163 AVG Test Loss:0.246\n",
            "Epoch:2640/3000 AVG Training Loss:0.132 AVG Test Loss:0.199\n",
            "Epoch:2641/3000 AVG Training Loss:0.114 AVG Test Loss:0.066\n",
            "Epoch:2642/3000 AVG Training Loss:0.151 AVG Test Loss:0.269\n",
            "Epoch:2643/3000 AVG Training Loss:0.146 AVG Test Loss:0.085\n",
            "Epoch:2644/3000 AVG Training Loss:0.067 AVG Test Loss:0.138\n",
            "Epoch:2645/3000 AVG Training Loss:0.221 AVG Test Loss:0.257\n",
            "Epoch:2646/3000 AVG Training Loss:0.230 AVG Test Loss:0.379\n",
            "Epoch:2647/3000 AVG Training Loss:0.088 AVG Test Loss:0.059\n",
            "Epoch:2648/3000 AVG Training Loss:0.145 AVG Test Loss:0.135\n",
            "Epoch:2649/3000 AVG Training Loss:0.107 AVG Test Loss:0.406\n",
            "Epoch:2650/3000 AVG Training Loss:0.074 AVG Test Loss:0.201\n",
            "Epoch:2651/3000 AVG Training Loss:0.074 AVG Test Loss:0.151\n",
            "Epoch:2652/3000 AVG Training Loss:0.164 AVG Test Loss:0.361\n",
            "Epoch:2653/3000 AVG Training Loss:0.139 AVG Test Loss:0.069\n",
            "Epoch:2654/3000 AVG Training Loss:0.153 AVG Test Loss:0.195\n",
            "Epoch:2655/3000 AVG Training Loss:0.208 AVG Test Loss:0.098\n",
            "Epoch:2656/3000 AVG Training Loss:0.106 AVG Test Loss:0.105\n",
            "Epoch:2657/3000 AVG Training Loss:0.072 AVG Test Loss:0.194\n",
            "Epoch:2658/3000 AVG Training Loss:0.064 AVG Test Loss:0.211\n",
            "Epoch:2659/3000 AVG Training Loss:0.162 AVG Test Loss:0.165\n",
            "Epoch:2660/3000 AVG Training Loss:0.089 AVG Test Loss:0.338\n",
            "Epoch:2661/3000 AVG Training Loss:0.137 AVG Test Loss:0.220\n",
            "Epoch:2662/3000 AVG Training Loss:0.109 AVG Test Loss:0.100\n",
            "Epoch:2663/3000 AVG Training Loss:0.115 AVG Test Loss:0.199\n",
            "Epoch:2664/3000 AVG Training Loss:0.121 AVG Test Loss:0.130\n",
            "Epoch:2665/3000 AVG Training Loss:0.079 AVG Test Loss:0.266\n",
            "Epoch:2666/3000 AVG Training Loss:0.067 AVG Test Loss:0.232\n",
            "Epoch:2667/3000 AVG Training Loss:0.306 AVG Test Loss:0.168\n",
            "Epoch:2668/3000 AVG Training Loss:0.106 AVG Test Loss:0.131\n",
            "Epoch:2669/3000 AVG Training Loss:0.140 AVG Test Loss:0.255\n",
            "Epoch:2670/3000 AVG Training Loss:0.052 AVG Test Loss:0.281\n",
            "Epoch:2671/3000 AVG Training Loss:0.119 AVG Test Loss:0.056\n",
            "Epoch:2672/3000 AVG Training Loss:0.145 AVG Test Loss:0.190\n",
            "Epoch:2673/3000 AVG Training Loss:0.052 AVG Test Loss:0.061\n",
            "Epoch:2674/3000 AVG Training Loss:0.079 AVG Test Loss:0.137\n",
            "Epoch:2675/3000 AVG Training Loss:0.148 AVG Test Loss:0.118\n",
            "Epoch:2676/3000 AVG Training Loss:0.077 AVG Test Loss:0.118\n",
            "Epoch:2677/3000 AVG Training Loss:0.069 AVG Test Loss:0.073\n",
            "Epoch:2678/3000 AVG Training Loss:0.070 AVG Test Loss:0.253\n",
            "Epoch:2679/3000 AVG Training Loss:0.098 AVG Test Loss:0.046\n",
            "Epoch:2680/3000 AVG Training Loss:0.102 AVG Test Loss:0.204\n",
            "Epoch:2681/3000 AVG Training Loss:0.140 AVG Test Loss:0.105\n",
            "Epoch:2682/3000 AVG Training Loss:0.155 AVG Test Loss:0.093\n",
            "Epoch:2683/3000 AVG Training Loss:0.194 AVG Test Loss:0.100\n",
            "Epoch:2684/3000 AVG Training Loss:0.124 AVG Test Loss:0.149\n",
            "Epoch:2685/3000 AVG Training Loss:0.075 AVG Test Loss:0.047\n",
            "Epoch:2686/3000 AVG Training Loss:0.226 AVG Test Loss:0.142\n",
            "Epoch:2687/3000 AVG Training Loss:0.191 AVG Test Loss:0.145\n",
            "Epoch:2688/3000 AVG Training Loss:0.069 AVG Test Loss:0.226\n",
            "Epoch:2689/3000 AVG Training Loss:0.067 AVG Test Loss:0.151\n",
            "Epoch:2690/3000 AVG Training Loss:0.096 AVG Test Loss:0.179\n",
            "Epoch:2691/3000 AVG Training Loss:0.099 AVG Test Loss:0.358\n",
            "Epoch:2692/3000 AVG Training Loss:0.110 AVG Test Loss:0.247\n",
            "Epoch:2693/3000 AVG Training Loss:0.120 AVG Test Loss:0.247\n",
            "Epoch:2694/3000 AVG Training Loss:0.150 AVG Test Loss:0.136\n",
            "Epoch:2695/3000 AVG Training Loss:0.162 AVG Test Loss:0.142\n",
            "Epoch:2696/3000 AVG Training Loss:0.111 AVG Test Loss:0.173\n",
            "Epoch:2697/3000 AVG Training Loss:0.106 AVG Test Loss:0.178\n",
            "Epoch:2698/3000 AVG Training Loss:0.122 AVG Test Loss:0.084\n",
            "Epoch:2699/3000 AVG Training Loss:0.110 AVG Test Loss:0.123\n",
            "Epoch:2700/3000 AVG Training Loss:0.155 AVG Test Loss:0.139\n",
            "Epoch:2701/3000 AVG Training Loss:0.119 AVG Test Loss:0.056\n",
            "Epoch:2702/3000 AVG Training Loss:0.130 AVG Test Loss:0.130\n",
            "Epoch:2703/3000 AVG Training Loss:0.141 AVG Test Loss:0.155\n",
            "Epoch:2704/3000 AVG Training Loss:0.143 AVG Test Loss:0.083\n",
            "Epoch:2705/3000 AVG Training Loss:0.089 AVG Test Loss:0.058\n",
            "Epoch:2706/3000 AVG Training Loss:0.089 AVG Test Loss:0.182\n",
            "Epoch:2707/3000 AVG Training Loss:0.094 AVG Test Loss:0.100\n",
            "Epoch:2708/3000 AVG Training Loss:0.096 AVG Test Loss:0.205\n",
            "Epoch:2709/3000 AVG Training Loss:0.094 AVG Test Loss:0.129\n",
            "Epoch:2710/3000 AVG Training Loss:0.096 AVG Test Loss:0.123\n",
            "Epoch:2711/3000 AVG Training Loss:0.131 AVG Test Loss:0.125\n",
            "Epoch:2712/3000 AVG Training Loss:0.084 AVG Test Loss:0.067\n",
            "Epoch:2713/3000 AVG Training Loss:0.080 AVG Test Loss:0.205\n",
            "Epoch:2714/3000 AVG Training Loss:0.094 AVG Test Loss:0.105\n",
            "Epoch:2715/3000 AVG Training Loss:0.068 AVG Test Loss:0.166\n",
            "Epoch:2716/3000 AVG Training Loss:0.117 AVG Test Loss:0.110\n",
            "Epoch:2717/3000 AVG Training Loss:0.138 AVG Test Loss:0.193\n",
            "Epoch:2718/3000 AVG Training Loss:0.197 AVG Test Loss:0.284\n",
            "Epoch:2719/3000 AVG Training Loss:0.146 AVG Test Loss:0.082\n",
            "Epoch:2720/3000 AVG Training Loss:0.096 AVG Test Loss:0.040\n",
            "Epoch:2721/3000 AVG Training Loss:0.076 AVG Test Loss:0.112\n",
            "Epoch:2722/3000 AVG Training Loss:0.075 AVG Test Loss:0.059\n",
            "Epoch:2723/3000 AVG Training Loss:0.112 AVG Test Loss:0.119\n",
            "Epoch:2724/3000 AVG Training Loss:0.162 AVG Test Loss:0.079\n",
            "Epoch:2725/3000 AVG Training Loss:0.162 AVG Test Loss:0.130\n",
            "Epoch:2726/3000 AVG Training Loss:0.149 AVG Test Loss:0.148\n",
            "Epoch:2727/3000 AVG Training Loss:0.055 AVG Test Loss:0.089\n",
            "Epoch:2728/3000 AVG Training Loss:0.194 AVG Test Loss:0.109\n",
            "Epoch:2729/3000 AVG Training Loss:0.078 AVG Test Loss:0.190\n",
            "Epoch:2730/3000 AVG Training Loss:0.152 AVG Test Loss:0.083\n",
            "Epoch:2731/3000 AVG Training Loss:0.100 AVG Test Loss:0.242\n",
            "Epoch:2732/3000 AVG Training Loss:0.063 AVG Test Loss:0.175\n",
            "Epoch:2733/3000 AVG Training Loss:0.211 AVG Test Loss:0.074\n",
            "Epoch:2734/3000 AVG Training Loss:0.118 AVG Test Loss:0.082\n",
            "Epoch:2735/3000 AVG Training Loss:0.092 AVG Test Loss:0.329\n",
            "Epoch:2736/3000 AVG Training Loss:0.085 AVG Test Loss:0.168\n",
            "Epoch:2737/3000 AVG Training Loss:0.158 AVG Test Loss:0.083\n",
            "Epoch:2738/3000 AVG Training Loss:0.109 AVG Test Loss:0.148\n",
            "Epoch:2739/3000 AVG Training Loss:0.117 AVG Test Loss:0.142\n",
            "Epoch:2740/3000 AVG Training Loss:0.104 AVG Test Loss:0.130\n",
            "Epoch:2741/3000 AVG Training Loss:0.173 AVG Test Loss:0.128\n",
            "Epoch:2742/3000 AVG Training Loss:0.098 AVG Test Loss:0.148\n",
            "Epoch:2743/3000 AVG Training Loss:0.083 AVG Test Loss:0.133\n",
            "Epoch:2744/3000 AVG Training Loss:0.066 AVG Test Loss:0.097\n",
            "Epoch:2745/3000 AVG Training Loss:0.207 AVG Test Loss:0.226\n",
            "Epoch:2746/3000 AVG Training Loss:0.115 AVG Test Loss:0.053\n",
            "Epoch:2747/3000 AVG Training Loss:0.158 AVG Test Loss:0.130\n",
            "Epoch:2748/3000 AVG Training Loss:0.130 AVG Test Loss:0.089\n",
            "Epoch:2749/3000 AVG Training Loss:0.130 AVG Test Loss:0.099\n",
            "Epoch:2750/3000 AVG Training Loss:0.059 AVG Test Loss:0.161\n",
            "Epoch:2751/3000 AVG Training Loss:0.129 AVG Test Loss:0.190\n",
            "Epoch:2752/3000 AVG Training Loss:0.089 AVG Test Loss:0.224\n",
            "Epoch:2753/3000 AVG Training Loss:0.076 AVG Test Loss:0.106\n",
            "Epoch:2754/3000 AVG Training Loss:0.071 AVG Test Loss:0.261\n",
            "Epoch:2755/3000 AVG Training Loss:0.077 AVG Test Loss:0.100\n",
            "Epoch:2756/3000 AVG Training Loss:0.167 AVG Test Loss:0.104\n",
            "Epoch:2757/3000 AVG Training Loss:0.218 AVG Test Loss:0.118\n",
            "Epoch:2758/3000 AVG Training Loss:0.069 AVG Test Loss:0.153\n",
            "Epoch:2759/3000 AVG Training Loss:0.188 AVG Test Loss:0.203\n",
            "Epoch:2760/3000 AVG Training Loss:0.208 AVG Test Loss:0.335\n",
            "Epoch:2761/3000 AVG Training Loss:0.091 AVG Test Loss:0.172\n",
            "Epoch:2762/3000 AVG Training Loss:0.070 AVG Test Loss:0.070\n",
            "Epoch:2763/3000 AVG Training Loss:0.177 AVG Test Loss:0.193\n",
            "Epoch:2764/3000 AVG Training Loss:0.086 AVG Test Loss:0.105\n",
            "Epoch:2765/3000 AVG Training Loss:0.151 AVG Test Loss:0.167\n",
            "Epoch:2766/3000 AVG Training Loss:0.147 AVG Test Loss:0.331\n",
            "Epoch:2767/3000 AVG Training Loss:0.106 AVG Test Loss:0.234\n",
            "Epoch:2768/3000 AVG Training Loss:0.084 AVG Test Loss:0.181\n",
            "Epoch:2769/3000 AVG Training Loss:0.151 AVG Test Loss:0.217\n",
            "Epoch:2770/3000 AVG Training Loss:0.074 AVG Test Loss:0.187\n",
            "Epoch:2771/3000 AVG Training Loss:0.132 AVG Test Loss:0.130\n",
            "Epoch:2772/3000 AVG Training Loss:0.168 AVG Test Loss:0.266\n",
            "Epoch:2773/3000 AVG Training Loss:0.119 AVG Test Loss:0.184\n",
            "Epoch:2774/3000 AVG Training Loss:0.145 AVG Test Loss:0.165\n",
            "Epoch:2775/3000 AVG Training Loss:0.065 AVG Test Loss:0.152\n",
            "Epoch:2776/3000 AVG Training Loss:0.165 AVG Test Loss:0.231\n",
            "Epoch:2777/3000 AVG Training Loss:0.085 AVG Test Loss:0.078\n",
            "Epoch:2778/3000 AVG Training Loss:0.078 AVG Test Loss:0.127\n",
            "Epoch:2779/3000 AVG Training Loss:0.084 AVG Test Loss:0.338\n",
            "Epoch:2780/3000 AVG Training Loss:0.096 AVG Test Loss:0.175\n",
            "Epoch:2781/3000 AVG Training Loss:0.105 AVG Test Loss:0.070\n",
            "Epoch:2782/3000 AVG Training Loss:0.107 AVG Test Loss:0.137\n",
            "Epoch:2783/3000 AVG Training Loss:0.105 AVG Test Loss:0.181\n",
            "Epoch:2784/3000 AVG Training Loss:0.135 AVG Test Loss:0.136\n",
            "Epoch:2785/3000 AVG Training Loss:0.134 AVG Test Loss:0.129\n",
            "Epoch:2786/3000 AVG Training Loss:0.071 AVG Test Loss:0.256\n",
            "Epoch:2787/3000 AVG Training Loss:0.097 AVG Test Loss:0.201\n",
            "Epoch:2788/3000 AVG Training Loss:0.097 AVG Test Loss:0.185\n",
            "Epoch:2789/3000 AVG Training Loss:0.071 AVG Test Loss:0.236\n",
            "Epoch:2790/3000 AVG Training Loss:0.104 AVG Test Loss:0.034\n",
            "Epoch:2791/3000 AVG Training Loss:0.102 AVG Test Loss:0.064\n",
            "Epoch:2792/3000 AVG Training Loss:0.061 AVG Test Loss:0.089\n",
            "Epoch:2793/3000 AVG Training Loss:0.112 AVG Test Loss:0.141\n",
            "Epoch:2794/3000 AVG Training Loss:0.099 AVG Test Loss:0.150\n",
            "Epoch:2795/3000 AVG Training Loss:0.151 AVG Test Loss:0.017\n",
            "Epoch:2796/3000 AVG Training Loss:0.150 AVG Test Loss:0.208\n",
            "Epoch:2797/3000 AVG Training Loss:0.108 AVG Test Loss:0.127\n",
            "Epoch:2798/3000 AVG Training Loss:0.110 AVG Test Loss:0.182\n",
            "Epoch:2799/3000 AVG Training Loss:0.119 AVG Test Loss:0.194\n",
            "Epoch:2800/3000 AVG Training Loss:0.220 AVG Test Loss:0.193\n",
            "Epoch:2801/3000 AVG Training Loss:0.139 AVG Test Loss:0.074\n",
            "Epoch:2802/3000 AVG Training Loss:0.094 AVG Test Loss:0.492\n",
            "Epoch:2803/3000 AVG Training Loss:0.167 AVG Test Loss:0.108\n",
            "Epoch:2804/3000 AVG Training Loss:0.086 AVG Test Loss:0.304\n",
            "Epoch:2805/3000 AVG Training Loss:0.115 AVG Test Loss:0.111\n",
            "Epoch:2806/3000 AVG Training Loss:0.082 AVG Test Loss:0.382\n",
            "Epoch:2807/3000 AVG Training Loss:0.143 AVG Test Loss:0.293\n",
            "Epoch:2808/3000 AVG Training Loss:0.060 AVG Test Loss:0.059\n",
            "Epoch:2809/3000 AVG Training Loss:0.135 AVG Test Loss:0.070\n",
            "Epoch:2810/3000 AVG Training Loss:0.101 AVG Test Loss:0.237\n",
            "Epoch:2811/3000 AVG Training Loss:0.170 AVG Test Loss:0.096\n",
            "Epoch:2812/3000 AVG Training Loss:0.086 AVG Test Loss:0.137\n",
            "Epoch:2813/3000 AVG Training Loss:0.159 AVG Test Loss:0.182\n",
            "Epoch:2814/3000 AVG Training Loss:0.138 AVG Test Loss:0.036\n",
            "Epoch:2815/3000 AVG Training Loss:0.118 AVG Test Loss:0.145\n",
            "Epoch:2816/3000 AVG Training Loss:0.095 AVG Test Loss:0.331\n",
            "Epoch:2817/3000 AVG Training Loss:0.154 AVG Test Loss:0.104\n",
            "Epoch:2818/3000 AVG Training Loss:0.212 AVG Test Loss:0.262\n",
            "Epoch:2819/3000 AVG Training Loss:0.071 AVG Test Loss:0.102\n",
            "Epoch:2820/3000 AVG Training Loss:0.180 AVG Test Loss:0.098\n",
            "Epoch:2821/3000 AVG Training Loss:0.084 AVG Test Loss:0.281\n",
            "Epoch:2822/3000 AVG Training Loss:0.117 AVG Test Loss:0.118\n",
            "Epoch:2823/3000 AVG Training Loss:0.129 AVG Test Loss:0.060\n",
            "Epoch:2824/3000 AVG Training Loss:0.188 AVG Test Loss:0.098\n",
            "Epoch:2825/3000 AVG Training Loss:0.133 AVG Test Loss:0.101\n",
            "Epoch:2826/3000 AVG Training Loss:0.066 AVG Test Loss:0.228\n",
            "Epoch:2827/3000 AVG Training Loss:0.141 AVG Test Loss:0.118\n",
            "Epoch:2828/3000 AVG Training Loss:0.183 AVG Test Loss:0.176\n",
            "Epoch:2829/3000 AVG Training Loss:0.065 AVG Test Loss:0.452\n",
            "Epoch:2830/3000 AVG Training Loss:0.223 AVG Test Loss:0.158\n",
            "Epoch:2831/3000 AVG Training Loss:0.119 AVG Test Loss:0.072\n",
            "Epoch:2832/3000 AVG Training Loss:0.117 AVG Test Loss:0.153\n",
            "Epoch:2833/3000 AVG Training Loss:0.060 AVG Test Loss:0.203\n",
            "Epoch:2834/3000 AVG Training Loss:0.123 AVG Test Loss:0.128\n",
            "Epoch:2835/3000 AVG Training Loss:0.091 AVG Test Loss:0.051\n",
            "Epoch:2836/3000 AVG Training Loss:0.145 AVG Test Loss:0.060\n",
            "Epoch:2837/3000 AVG Training Loss:0.063 AVG Test Loss:0.170\n",
            "Epoch:2838/3000 AVG Training Loss:0.198 AVG Test Loss:0.172\n",
            "Epoch:2839/3000 AVG Training Loss:0.166 AVG Test Loss:0.098\n",
            "Epoch:2840/3000 AVG Training Loss:0.263 AVG Test Loss:0.243\n",
            "Epoch:2841/3000 AVG Training Loss:0.223 AVG Test Loss:0.149\n",
            "Epoch:2842/3000 AVG Training Loss:0.170 AVG Test Loss:0.320\n",
            "Epoch:2843/3000 AVG Training Loss:0.139 AVG Test Loss:0.102\n",
            "Epoch:2844/3000 AVG Training Loss:0.102 AVG Test Loss:0.215\n",
            "Epoch:2845/3000 AVG Training Loss:0.080 AVG Test Loss:0.183\n",
            "Epoch:2846/3000 AVG Training Loss:0.093 AVG Test Loss:0.147\n",
            "Epoch:2847/3000 AVG Training Loss:0.105 AVG Test Loss:0.185\n",
            "Epoch:2848/3000 AVG Training Loss:0.113 AVG Test Loss:0.147\n",
            "Epoch:2849/3000 AVG Training Loss:0.141 AVG Test Loss:0.126\n",
            "Epoch:2850/3000 AVG Training Loss:0.135 AVG Test Loss:0.180\n",
            "Epoch:2851/3000 AVG Training Loss:0.190 AVG Test Loss:0.275\n",
            "Epoch:2852/3000 AVG Training Loss:0.138 AVG Test Loss:0.106\n",
            "Epoch:2853/3000 AVG Training Loss:0.158 AVG Test Loss:0.262\n",
            "Epoch:2854/3000 AVG Training Loss:0.132 AVG Test Loss:0.166\n",
            "Epoch:2855/3000 AVG Training Loss:0.083 AVG Test Loss:0.073\n",
            "Epoch:2856/3000 AVG Training Loss:0.083 AVG Test Loss:0.206\n",
            "Epoch:2857/3000 AVG Training Loss:0.131 AVG Test Loss:0.128\n",
            "Epoch:2858/3000 AVG Training Loss:0.108 AVG Test Loss:0.144\n",
            "Epoch:2859/3000 AVG Training Loss:0.117 AVG Test Loss:0.211\n",
            "Epoch:2860/3000 AVG Training Loss:0.158 AVG Test Loss:0.168\n",
            "Epoch:2861/3000 AVG Training Loss:0.158 AVG Test Loss:0.070\n",
            "Epoch:2862/3000 AVG Training Loss:0.196 AVG Test Loss:0.165\n",
            "Epoch:2863/3000 AVG Training Loss:0.069 AVG Test Loss:0.212\n",
            "Epoch:2864/3000 AVG Training Loss:0.162 AVG Test Loss:0.029\n",
            "Epoch:2865/3000 AVG Training Loss:0.121 AVG Test Loss:0.107\n",
            "Epoch:2866/3000 AVG Training Loss:0.143 AVG Test Loss:0.073\n",
            "Epoch:2867/3000 AVG Training Loss:0.147 AVG Test Loss:0.423\n",
            "Epoch:2868/3000 AVG Training Loss:0.232 AVG Test Loss:0.269\n",
            "Epoch:2869/3000 AVG Training Loss:0.125 AVG Test Loss:0.126\n",
            "Epoch:2870/3000 AVG Training Loss:0.087 AVG Test Loss:0.293\n",
            "Epoch:2871/3000 AVG Training Loss:0.074 AVG Test Loss:0.100\n",
            "Epoch:2872/3000 AVG Training Loss:0.068 AVG Test Loss:0.106\n",
            "Epoch:2873/3000 AVG Training Loss:0.057 AVG Test Loss:0.214\n",
            "Epoch:2874/3000 AVG Training Loss:0.115 AVG Test Loss:0.112\n",
            "Epoch:2875/3000 AVG Training Loss:0.078 AVG Test Loss:0.290\n",
            "Epoch:2876/3000 AVG Training Loss:0.113 AVG Test Loss:0.072\n",
            "Epoch:2877/3000 AVG Training Loss:0.124 AVG Test Loss:0.176\n",
            "Epoch:2878/3000 AVG Training Loss:0.071 AVG Test Loss:0.173\n",
            "Epoch:2879/3000 AVG Training Loss:0.077 AVG Test Loss:0.054\n",
            "Epoch:2880/3000 AVG Training Loss:0.087 AVG Test Loss:0.267\n",
            "Epoch:2881/3000 AVG Training Loss:0.146 AVG Test Loss:0.082\n",
            "Epoch:2882/3000 AVG Training Loss:0.213 AVG Test Loss:0.059\n",
            "Epoch:2883/3000 AVG Training Loss:0.081 AVG Test Loss:0.332\n",
            "Epoch:2884/3000 AVG Training Loss:0.138 AVG Test Loss:0.025\n",
            "Epoch:2885/3000 AVG Training Loss:0.157 AVG Test Loss:0.112\n",
            "Epoch:2886/3000 AVG Training Loss:0.085 AVG Test Loss:0.055\n",
            "Epoch:2887/3000 AVG Training Loss:0.125 AVG Test Loss:0.097\n",
            "Epoch:2888/3000 AVG Training Loss:0.097 AVG Test Loss:0.093\n",
            "Epoch:2889/3000 AVG Training Loss:0.067 AVG Test Loss:0.067\n",
            "Epoch:2890/3000 AVG Training Loss:0.190 AVG Test Loss:0.173\n",
            "Epoch:2891/3000 AVG Training Loss:0.106 AVG Test Loss:0.229\n",
            "Epoch:2892/3000 AVG Training Loss:0.150 AVG Test Loss:0.197\n",
            "Epoch:2893/3000 AVG Training Loss:0.129 AVG Test Loss:0.278\n",
            "Epoch:2894/3000 AVG Training Loss:0.110 AVG Test Loss:0.238\n",
            "Epoch:2895/3000 AVG Training Loss:0.110 AVG Test Loss:0.220\n",
            "Epoch:2896/3000 AVG Training Loss:0.136 AVG Test Loss:0.132\n",
            "Epoch:2897/3000 AVG Training Loss:0.108 AVG Test Loss:0.210\n",
            "Epoch:2898/3000 AVG Training Loss:0.152 AVG Test Loss:0.138\n",
            "Epoch:2899/3000 AVG Training Loss:0.143 AVG Test Loss:0.115\n",
            "Epoch:2900/3000 AVG Training Loss:0.081 AVG Test Loss:0.221\n",
            "Epoch:2901/3000 AVG Training Loss:0.104 AVG Test Loss:0.146\n",
            "Epoch:2902/3000 AVG Training Loss:0.107 AVG Test Loss:0.270\n",
            "Epoch:2903/3000 AVG Training Loss:0.180 AVG Test Loss:0.210\n",
            "Epoch:2904/3000 AVG Training Loss:0.120 AVG Test Loss:0.062\n",
            "Epoch:2905/3000 AVG Training Loss:0.175 AVG Test Loss:0.081\n",
            "Epoch:2906/3000 AVG Training Loss:0.274 AVG Test Loss:0.235\n",
            "Epoch:2907/3000 AVG Training Loss:0.129 AVG Test Loss:0.093\n",
            "Epoch:2908/3000 AVG Training Loss:0.131 AVG Test Loss:0.078\n",
            "Epoch:2909/3000 AVG Training Loss:0.075 AVG Test Loss:0.048\n",
            "Epoch:2910/3000 AVG Training Loss:0.112 AVG Test Loss:0.176\n",
            "Epoch:2911/3000 AVG Training Loss:0.189 AVG Test Loss:0.094\n",
            "Epoch:2912/3000 AVG Training Loss:0.136 AVG Test Loss:0.054\n",
            "Epoch:2913/3000 AVG Training Loss:0.197 AVG Test Loss:0.220\n",
            "Epoch:2914/3000 AVG Training Loss:0.177 AVG Test Loss:0.059\n",
            "Epoch:2915/3000 AVG Training Loss:0.167 AVG Test Loss:0.229\n",
            "Epoch:2916/3000 AVG Training Loss:0.087 AVG Test Loss:0.228\n",
            "Epoch:2917/3000 AVG Training Loss:0.091 AVG Test Loss:0.267\n",
            "Epoch:2918/3000 AVG Training Loss:0.133 AVG Test Loss:0.075\n",
            "Epoch:2919/3000 AVG Training Loss:0.072 AVG Test Loss:0.379\n",
            "Epoch:2920/3000 AVG Training Loss:0.183 AVG Test Loss:0.191\n",
            "Epoch:2921/3000 AVG Training Loss:0.220 AVG Test Loss:0.152\n",
            "Epoch:2922/3000 AVG Training Loss:0.140 AVG Test Loss:0.196\n",
            "Epoch:2923/3000 AVG Training Loss:0.132 AVG Test Loss:0.082\n",
            "Epoch:2924/3000 AVG Training Loss:0.125 AVG Test Loss:0.034\n",
            "Epoch:2925/3000 AVG Training Loss:0.209 AVG Test Loss:0.108\n",
            "Epoch:2926/3000 AVG Training Loss:0.086 AVG Test Loss:0.139\n",
            "Epoch:2927/3000 AVG Training Loss:0.171 AVG Test Loss:0.067\n",
            "Epoch:2928/3000 AVG Training Loss:0.109 AVG Test Loss:0.241\n",
            "Epoch:2929/3000 AVG Training Loss:0.198 AVG Test Loss:0.138\n",
            "Epoch:2930/3000 AVG Training Loss:0.121 AVG Test Loss:0.241\n",
            "Epoch:2931/3000 AVG Training Loss:0.052 AVG Test Loss:0.069\n",
            "Epoch:2932/3000 AVG Training Loss:0.123 AVG Test Loss:0.094\n",
            "Epoch:2933/3000 AVG Training Loss:0.055 AVG Test Loss:0.124\n",
            "Epoch:2934/3000 AVG Training Loss:0.099 AVG Test Loss:0.019\n",
            "Epoch:2935/3000 AVG Training Loss:0.052 AVG Test Loss:0.086\n",
            "Epoch:2936/3000 AVG Training Loss:0.102 AVG Test Loss:0.340\n",
            "Epoch:2937/3000 AVG Training Loss:0.284 AVG Test Loss:0.099\n",
            "Epoch:2938/3000 AVG Training Loss:0.157 AVG Test Loss:0.292\n",
            "Epoch:2939/3000 AVG Training Loss:0.121 AVG Test Loss:0.253\n",
            "Epoch:2940/3000 AVG Training Loss:0.092 AVG Test Loss:0.192\n",
            "Epoch:2941/3000 AVG Training Loss:0.099 AVG Test Loss:0.094\n",
            "Epoch:2942/3000 AVG Training Loss:0.089 AVG Test Loss:0.154\n",
            "Epoch:2943/3000 AVG Training Loss:0.091 AVG Test Loss:0.181\n",
            "Epoch:2944/3000 AVG Training Loss:0.165 AVG Test Loss:0.114\n",
            "Epoch:2945/3000 AVG Training Loss:0.116 AVG Test Loss:0.054\n",
            "Epoch:2946/3000 AVG Training Loss:0.092 AVG Test Loss:0.101\n",
            "Epoch:2947/3000 AVG Training Loss:0.053 AVG Test Loss:0.104\n",
            "Epoch:2948/3000 AVG Training Loss:0.164 AVG Test Loss:0.055\n",
            "Epoch:2949/3000 AVG Training Loss:0.062 AVG Test Loss:0.205\n",
            "Epoch:2950/3000 AVG Training Loss:0.088 AVG Test Loss:0.188\n",
            "Epoch:2951/3000 AVG Training Loss:0.094 AVG Test Loss:0.111\n",
            "Epoch:2952/3000 AVG Training Loss:0.090 AVG Test Loss:0.074\n",
            "Epoch:2953/3000 AVG Training Loss:0.150 AVG Test Loss:0.146\n",
            "Epoch:2954/3000 AVG Training Loss:0.072 AVG Test Loss:0.232\n",
            "Epoch:2955/3000 AVG Training Loss:0.105 AVG Test Loss:0.256\n",
            "Epoch:2956/3000 AVG Training Loss:0.103 AVG Test Loss:0.122\n",
            "Epoch:2957/3000 AVG Training Loss:0.084 AVG Test Loss:0.070\n",
            "Epoch:2958/3000 AVG Training Loss:0.156 AVG Test Loss:0.174\n",
            "Epoch:2959/3000 AVG Training Loss:0.109 AVG Test Loss:0.213\n",
            "Epoch:2960/3000 AVG Training Loss:0.134 AVG Test Loss:0.149\n",
            "Epoch:2961/3000 AVG Training Loss:0.102 AVG Test Loss:0.048\n",
            "Epoch:2962/3000 AVG Training Loss:0.154 AVG Test Loss:0.082\n",
            "Epoch:2963/3000 AVG Training Loss:0.125 AVG Test Loss:0.317\n",
            "Epoch:2964/3000 AVG Training Loss:0.143 AVG Test Loss:0.223\n",
            "Epoch:2965/3000 AVG Training Loss:0.159 AVG Test Loss:0.188\n",
            "Epoch:2966/3000 AVG Training Loss:0.102 AVG Test Loss:0.124\n",
            "Epoch:2967/3000 AVG Training Loss:0.051 AVG Test Loss:0.216\n",
            "Epoch:2968/3000 AVG Training Loss:0.108 AVG Test Loss:0.358\n",
            "Epoch:2969/3000 AVG Training Loss:0.097 AVG Test Loss:0.091\n",
            "Epoch:2970/3000 AVG Training Loss:0.078 AVG Test Loss:0.056\n",
            "Epoch:2971/3000 AVG Training Loss:0.206 AVG Test Loss:0.111\n",
            "Epoch:2972/3000 AVG Training Loss:0.132 AVG Test Loss:0.157\n",
            "Epoch:2973/3000 AVG Training Loss:0.157 AVG Test Loss:0.088\n",
            "Epoch:2974/3000 AVG Training Loss:0.130 AVG Test Loss:0.150\n",
            "Epoch:2975/3000 AVG Training Loss:0.121 AVG Test Loss:0.207\n",
            "Epoch:2976/3000 AVG Training Loss:0.066 AVG Test Loss:0.205\n",
            "Epoch:2977/3000 AVG Training Loss:0.072 AVG Test Loss:0.097\n",
            "Epoch:2978/3000 AVG Training Loss:0.150 AVG Test Loss:0.199\n",
            "Epoch:2979/3000 AVG Training Loss:0.158 AVG Test Loss:0.045\n",
            "Epoch:2980/3000 AVG Training Loss:0.192 AVG Test Loss:0.179\n",
            "Epoch:2981/3000 AVG Training Loss:0.112 AVG Test Loss:0.167\n",
            "Epoch:2982/3000 AVG Training Loss:0.066 AVG Test Loss:0.273\n",
            "Epoch:2983/3000 AVG Training Loss:0.121 AVG Test Loss:0.142\n",
            "Epoch:2984/3000 AVG Training Loss:0.120 AVG Test Loss:0.014\n",
            "Epoch:2985/3000 AVG Training Loss:0.041 AVG Test Loss:0.105\n",
            "Epoch:2986/3000 AVG Training Loss:0.121 AVG Test Loss:0.153\n",
            "Epoch:2987/3000 AVG Training Loss:0.110 AVG Test Loss:0.248\n",
            "Epoch:2988/3000 AVG Training Loss:0.077 AVG Test Loss:0.119\n",
            "Epoch:2989/3000 AVG Training Loss:0.113 AVG Test Loss:0.186\n",
            "Epoch:2990/3000 AVG Training Loss:0.137 AVG Test Loss:0.293\n",
            "Epoch:2991/3000 AVG Training Loss:0.156 AVG Test Loss:0.314\n",
            "Epoch:2992/3000 AVG Training Loss:0.125 AVG Test Loss:0.141\n",
            "Epoch:2993/3000 AVG Training Loss:0.048 AVG Test Loss:0.226\n",
            "Epoch:2994/3000 AVG Training Loss:0.239 AVG Test Loss:0.021\n",
            "Epoch:2995/3000 AVG Training Loss:0.167 AVG Test Loss:0.214\n",
            "Epoch:2996/3000 AVG Training Loss:0.100 AVG Test Loss:0.044\n",
            "Epoch:2997/3000 AVG Training Loss:0.055 AVG Test Loss:0.084\n",
            "Epoch:2998/3000 AVG Training Loss:0.120 AVG Test Loss:0.139\n",
            "Epoch:2999/3000 AVG Training Loss:0.091 AVG Test Loss:0.089\n",
            "Epoch:3000/3000 AVG Training Loss:0.108 AVG Test Loss:0.098\n",
            "Fold 5\n",
            "Epoch:1/3000 AVG Training Loss:6.303 AVG Test Loss:2.516\n",
            "Epoch:2/3000 AVG Training Loss:7.299 AVG Test Loss:0.650\n",
            "Epoch:3/3000 AVG Training Loss:4.601 AVG Test Loss:2.435\n",
            "Epoch:4/3000 AVG Training Loss:3.323 AVG Test Loss:1.988\n",
            "Epoch:5/3000 AVG Training Loss:2.483 AVG Test Loss:1.601\n",
            "Epoch:6/3000 AVG Training Loss:3.289 AVG Test Loss:1.792\n",
            "Epoch:7/3000 AVG Training Loss:3.394 AVG Test Loss:2.968\n",
            "Epoch:8/3000 AVG Training Loss:2.372 AVG Test Loss:1.772\n",
            "Epoch:9/3000 AVG Training Loss:3.250 AVG Test Loss:2.003\n",
            "Epoch:10/3000 AVG Training Loss:3.330 AVG Test Loss:2.830\n",
            "Epoch:11/3000 AVG Training Loss:2.891 AVG Test Loss:2.829\n",
            "Epoch:12/3000 AVG Training Loss:2.428 AVG Test Loss:2.669\n",
            "Epoch:13/3000 AVG Training Loss:3.259 AVG Test Loss:2.123\n",
            "Epoch:14/3000 AVG Training Loss:1.844 AVG Test Loss:2.019\n",
            "Epoch:15/3000 AVG Training Loss:4.054 AVG Test Loss:2.071\n",
            "Epoch:16/3000 AVG Training Loss:2.644 AVG Test Loss:1.279\n",
            "Epoch:17/3000 AVG Training Loss:2.539 AVG Test Loss:1.377\n",
            "Epoch:18/3000 AVG Training Loss:3.417 AVG Test Loss:2.739\n",
            "Epoch:19/3000 AVG Training Loss:2.945 AVG Test Loss:0.983\n",
            "Epoch:20/3000 AVG Training Loss:2.261 AVG Test Loss:1.802\n",
            "Epoch:21/3000 AVG Training Loss:3.422 AVG Test Loss:2.309\n",
            "Epoch:22/3000 AVG Training Loss:2.043 AVG Test Loss:2.620\n",
            "Epoch:23/3000 AVG Training Loss:2.364 AVG Test Loss:1.803\n",
            "Epoch:24/3000 AVG Training Loss:2.039 AVG Test Loss:3.161\n",
            "Epoch:25/3000 AVG Training Loss:2.824 AVG Test Loss:1.498\n",
            "Epoch:26/3000 AVG Training Loss:2.236 AVG Test Loss:1.532\n",
            "Epoch:27/3000 AVG Training Loss:3.084 AVG Test Loss:2.918\n",
            "Epoch:28/3000 AVG Training Loss:3.205 AVG Test Loss:1.819\n",
            "Epoch:29/3000 AVG Training Loss:1.930 AVG Test Loss:2.068\n",
            "Epoch:30/3000 AVG Training Loss:2.763 AVG Test Loss:2.150\n",
            "Epoch:31/3000 AVG Training Loss:1.926 AVG Test Loss:1.404\n",
            "Epoch:32/3000 AVG Training Loss:2.289 AVG Test Loss:1.877\n",
            "Epoch:33/3000 AVG Training Loss:1.981 AVG Test Loss:2.026\n",
            "Epoch:34/3000 AVG Training Loss:2.710 AVG Test Loss:2.114\n",
            "Epoch:35/3000 AVG Training Loss:2.282 AVG Test Loss:2.686\n",
            "Epoch:36/3000 AVG Training Loss:1.846 AVG Test Loss:1.975\n",
            "Epoch:37/3000 AVG Training Loss:1.882 AVG Test Loss:0.976\n",
            "Epoch:38/3000 AVG Training Loss:2.989 AVG Test Loss:0.998\n",
            "Epoch:39/3000 AVG Training Loss:2.545 AVG Test Loss:2.090\n",
            "Epoch:40/3000 AVG Training Loss:3.057 AVG Test Loss:1.785\n",
            "Epoch:41/3000 AVG Training Loss:2.772 AVG Test Loss:2.144\n",
            "Epoch:42/3000 AVG Training Loss:3.713 AVG Test Loss:1.833\n",
            "Epoch:43/3000 AVG Training Loss:2.522 AVG Test Loss:1.729\n",
            "Epoch:44/3000 AVG Training Loss:2.395 AVG Test Loss:1.535\n",
            "Epoch:45/3000 AVG Training Loss:2.506 AVG Test Loss:2.841\n",
            "Epoch:46/3000 AVG Training Loss:2.000 AVG Test Loss:2.109\n",
            "Epoch:47/3000 AVG Training Loss:2.505 AVG Test Loss:0.798\n",
            "Epoch:48/3000 AVG Training Loss:2.686 AVG Test Loss:1.860\n",
            "Epoch:49/3000 AVG Training Loss:2.344 AVG Test Loss:0.663\n",
            "Epoch:50/3000 AVG Training Loss:1.812 AVG Test Loss:1.719\n",
            "Epoch:51/3000 AVG Training Loss:3.102 AVG Test Loss:1.671\n",
            "Epoch:52/3000 AVG Training Loss:2.051 AVG Test Loss:1.448\n",
            "Epoch:53/3000 AVG Training Loss:1.881 AVG Test Loss:1.529\n",
            "Epoch:54/3000 AVG Training Loss:1.254 AVG Test Loss:0.868\n",
            "Epoch:55/3000 AVG Training Loss:2.241 AVG Test Loss:1.212\n",
            "Epoch:56/3000 AVG Training Loss:2.126 AVG Test Loss:1.013\n",
            "Epoch:57/3000 AVG Training Loss:2.273 AVG Test Loss:0.350\n",
            "Epoch:58/3000 AVG Training Loss:2.096 AVG Test Loss:1.952\n",
            "Epoch:59/3000 AVG Training Loss:1.070 AVG Test Loss:1.051\n",
            "Epoch:60/3000 AVG Training Loss:1.617 AVG Test Loss:1.687\n",
            "Epoch:61/3000 AVG Training Loss:1.727 AVG Test Loss:2.107\n",
            "Epoch:62/3000 AVG Training Loss:1.445 AVG Test Loss:0.547\n",
            "Epoch:63/3000 AVG Training Loss:1.127 AVG Test Loss:0.931\n",
            "Epoch:64/3000 AVG Training Loss:1.681 AVG Test Loss:1.537\n",
            "Epoch:65/3000 AVG Training Loss:1.809 AVG Test Loss:1.403\n",
            "Epoch:66/3000 AVG Training Loss:1.936 AVG Test Loss:1.553\n",
            "Epoch:67/3000 AVG Training Loss:1.508 AVG Test Loss:1.594\n",
            "Epoch:68/3000 AVG Training Loss:1.715 AVG Test Loss:0.596\n",
            "Epoch:69/3000 AVG Training Loss:1.173 AVG Test Loss:0.649\n",
            "Epoch:70/3000 AVG Training Loss:0.982 AVG Test Loss:0.933\n",
            "Epoch:71/3000 AVG Training Loss:1.122 AVG Test Loss:0.188\n",
            "Epoch:72/3000 AVG Training Loss:1.384 AVG Test Loss:0.721\n",
            "Epoch:73/3000 AVG Training Loss:1.307 AVG Test Loss:1.186\n",
            "Epoch:74/3000 AVG Training Loss:1.266 AVG Test Loss:1.420\n",
            "Epoch:75/3000 AVG Training Loss:0.947 AVG Test Loss:1.771\n",
            "Epoch:76/3000 AVG Training Loss:1.219 AVG Test Loss:0.774\n",
            "Epoch:77/3000 AVG Training Loss:1.309 AVG Test Loss:0.738\n",
            "Epoch:78/3000 AVG Training Loss:1.443 AVG Test Loss:0.314\n",
            "Epoch:79/3000 AVG Training Loss:1.109 AVG Test Loss:0.925\n",
            "Epoch:80/3000 AVG Training Loss:1.131 AVG Test Loss:1.213\n",
            "Epoch:81/3000 AVG Training Loss:1.358 AVG Test Loss:0.427\n",
            "Epoch:82/3000 AVG Training Loss:0.764 AVG Test Loss:0.578\n",
            "Epoch:83/3000 AVG Training Loss:1.985 AVG Test Loss:0.260\n",
            "Epoch:84/3000 AVG Training Loss:0.959 AVG Test Loss:0.993\n",
            "Epoch:85/3000 AVG Training Loss:1.046 AVG Test Loss:0.992\n",
            "Epoch:86/3000 AVG Training Loss:1.109 AVG Test Loss:1.618\n",
            "Epoch:87/3000 AVG Training Loss:0.831 AVG Test Loss:0.854\n",
            "Epoch:88/3000 AVG Training Loss:1.252 AVG Test Loss:0.522\n",
            "Epoch:89/3000 AVG Training Loss:1.048 AVG Test Loss:0.878\n",
            "Epoch:90/3000 AVG Training Loss:0.985 AVG Test Loss:0.974\n",
            "Epoch:91/3000 AVG Training Loss:1.285 AVG Test Loss:0.531\n",
            "Epoch:92/3000 AVG Training Loss:1.131 AVG Test Loss:0.892\n",
            "Epoch:93/3000 AVG Training Loss:0.895 AVG Test Loss:0.672\n",
            "Epoch:94/3000 AVG Training Loss:0.945 AVG Test Loss:0.810\n",
            "Epoch:95/3000 AVG Training Loss:0.973 AVG Test Loss:0.291\n",
            "Epoch:96/3000 AVG Training Loss:0.789 AVG Test Loss:0.838\n",
            "Epoch:97/3000 AVG Training Loss:1.330 AVG Test Loss:0.847\n",
            "Epoch:98/3000 AVG Training Loss:1.012 AVG Test Loss:0.338\n",
            "Epoch:99/3000 AVG Training Loss:0.999 AVG Test Loss:0.926\n",
            "Epoch:100/3000 AVG Training Loss:0.838 AVG Test Loss:0.622\n",
            "Epoch:101/3000 AVG Training Loss:0.694 AVG Test Loss:0.858\n",
            "Epoch:102/3000 AVG Training Loss:1.000 AVG Test Loss:0.794\n",
            "Epoch:103/3000 AVG Training Loss:1.017 AVG Test Loss:0.882\n",
            "Epoch:104/3000 AVG Training Loss:0.800 AVG Test Loss:0.597\n",
            "Epoch:105/3000 AVG Training Loss:0.797 AVG Test Loss:1.152\n",
            "Epoch:106/3000 AVG Training Loss:1.026 AVG Test Loss:0.938\n",
            "Epoch:107/3000 AVG Training Loss:0.786 AVG Test Loss:0.419\n",
            "Epoch:108/3000 AVG Training Loss:0.810 AVG Test Loss:0.898\n",
            "Epoch:109/3000 AVG Training Loss:0.570 AVG Test Loss:0.379\n",
            "Epoch:110/3000 AVG Training Loss:1.602 AVG Test Loss:0.619\n",
            "Epoch:111/3000 AVG Training Loss:1.089 AVG Test Loss:0.637\n",
            "Epoch:112/3000 AVG Training Loss:0.915 AVG Test Loss:0.623\n",
            "Epoch:113/3000 AVG Training Loss:0.688 AVG Test Loss:0.487\n",
            "Epoch:114/3000 AVG Training Loss:0.806 AVG Test Loss:1.116\n",
            "Epoch:115/3000 AVG Training Loss:1.069 AVG Test Loss:0.447\n",
            "Epoch:116/3000 AVG Training Loss:0.937 AVG Test Loss:0.896\n",
            "Epoch:117/3000 AVG Training Loss:0.703 AVG Test Loss:0.255\n",
            "Epoch:118/3000 AVG Training Loss:1.181 AVG Test Loss:1.304\n",
            "Epoch:119/3000 AVG Training Loss:1.077 AVG Test Loss:0.857\n",
            "Epoch:120/3000 AVG Training Loss:1.200 AVG Test Loss:0.642\n",
            "Epoch:121/3000 AVG Training Loss:0.545 AVG Test Loss:0.257\n",
            "Epoch:122/3000 AVG Training Loss:0.906 AVG Test Loss:0.713\n",
            "Epoch:123/3000 AVG Training Loss:0.980 AVG Test Loss:0.436\n",
            "Epoch:124/3000 AVG Training Loss:1.262 AVG Test Loss:0.631\n",
            "Epoch:125/3000 AVG Training Loss:1.154 AVG Test Loss:0.453\n",
            "Epoch:126/3000 AVG Training Loss:0.921 AVG Test Loss:0.841\n",
            "Epoch:127/3000 AVG Training Loss:0.772 AVG Test Loss:0.332\n",
            "Epoch:128/3000 AVG Training Loss:1.097 AVG Test Loss:1.038\n",
            "Epoch:129/3000 AVG Training Loss:1.509 AVG Test Loss:0.879\n",
            "Epoch:130/3000 AVG Training Loss:0.949 AVG Test Loss:0.532\n",
            "Epoch:131/3000 AVG Training Loss:0.747 AVG Test Loss:0.197\n",
            "Epoch:132/3000 AVG Training Loss:1.289 AVG Test Loss:0.833\n",
            "Epoch:133/3000 AVG Training Loss:1.274 AVG Test Loss:0.866\n",
            "Epoch:134/3000 AVG Training Loss:0.816 AVG Test Loss:0.444\n",
            "Epoch:135/3000 AVG Training Loss:0.621 AVG Test Loss:0.696\n",
            "Epoch:136/3000 AVG Training Loss:0.776 AVG Test Loss:0.419\n",
            "Epoch:137/3000 AVG Training Loss:0.825 AVG Test Loss:0.449\n",
            "Epoch:138/3000 AVG Training Loss:0.689 AVG Test Loss:0.589\n",
            "Epoch:139/3000 AVG Training Loss:0.672 AVG Test Loss:0.211\n",
            "Epoch:140/3000 AVG Training Loss:0.511 AVG Test Loss:0.466\n",
            "Epoch:141/3000 AVG Training Loss:0.993 AVG Test Loss:0.414\n",
            "Epoch:142/3000 AVG Training Loss:0.865 AVG Test Loss:0.333\n",
            "Epoch:143/3000 AVG Training Loss:0.652 AVG Test Loss:0.439\n",
            "Epoch:144/3000 AVG Training Loss:0.621 AVG Test Loss:0.637\n",
            "Epoch:145/3000 AVG Training Loss:0.676 AVG Test Loss:1.308\n",
            "Epoch:146/3000 AVG Training Loss:0.533 AVG Test Loss:0.402\n",
            "Epoch:147/3000 AVG Training Loss:0.781 AVG Test Loss:0.745\n",
            "Epoch:148/3000 AVG Training Loss:1.308 AVG Test Loss:0.461\n",
            "Epoch:149/3000 AVG Training Loss:0.900 AVG Test Loss:0.305\n",
            "Epoch:150/3000 AVG Training Loss:0.745 AVG Test Loss:0.405\n",
            "Epoch:151/3000 AVG Training Loss:1.259 AVG Test Loss:0.271\n",
            "Epoch:152/3000 AVG Training Loss:0.908 AVG Test Loss:0.742\n",
            "Epoch:153/3000 AVG Training Loss:0.900 AVG Test Loss:1.264\n",
            "Epoch:154/3000 AVG Training Loss:0.461 AVG Test Loss:0.504\n",
            "Epoch:155/3000 AVG Training Loss:0.574 AVG Test Loss:0.155\n",
            "Epoch:156/3000 AVG Training Loss:0.463 AVG Test Loss:0.514\n",
            "Epoch:157/3000 AVG Training Loss:0.579 AVG Test Loss:0.330\n",
            "Epoch:158/3000 AVG Training Loss:0.777 AVG Test Loss:0.988\n",
            "Epoch:159/3000 AVG Training Loss:0.640 AVG Test Loss:0.808\n",
            "Epoch:160/3000 AVG Training Loss:0.586 AVG Test Loss:0.588\n",
            "Epoch:161/3000 AVG Training Loss:0.831 AVG Test Loss:0.582\n",
            "Epoch:162/3000 AVG Training Loss:0.661 AVG Test Loss:0.203\n",
            "Epoch:163/3000 AVG Training Loss:0.602 AVG Test Loss:0.448\n",
            "Epoch:164/3000 AVG Training Loss:0.648 AVG Test Loss:0.410\n",
            "Epoch:165/3000 AVG Training Loss:1.149 AVG Test Loss:0.873\n",
            "Epoch:166/3000 AVG Training Loss:0.553 AVG Test Loss:0.521\n",
            "Epoch:167/3000 AVG Training Loss:0.618 AVG Test Loss:1.270\n",
            "Epoch:168/3000 AVG Training Loss:0.902 AVG Test Loss:0.591\n",
            "Epoch:169/3000 AVG Training Loss:0.661 AVG Test Loss:0.794\n",
            "Epoch:170/3000 AVG Training Loss:0.546 AVG Test Loss:0.568\n",
            "Epoch:171/3000 AVG Training Loss:0.793 AVG Test Loss:0.660\n",
            "Epoch:172/3000 AVG Training Loss:0.470 AVG Test Loss:0.708\n",
            "Epoch:173/3000 AVG Training Loss:0.872 AVG Test Loss:0.235\n",
            "Epoch:174/3000 AVG Training Loss:0.675 AVG Test Loss:0.993\n",
            "Epoch:175/3000 AVG Training Loss:0.687 AVG Test Loss:0.791\n",
            "Epoch:176/3000 AVG Training Loss:0.520 AVG Test Loss:0.452\n",
            "Epoch:177/3000 AVG Training Loss:0.757 AVG Test Loss:0.592\n",
            "Epoch:178/3000 AVG Training Loss:1.009 AVG Test Loss:0.822\n",
            "Epoch:179/3000 AVG Training Loss:0.736 AVG Test Loss:0.769\n",
            "Epoch:180/3000 AVG Training Loss:0.554 AVG Test Loss:0.633\n",
            "Epoch:181/3000 AVG Training Loss:0.595 AVG Test Loss:0.940\n",
            "Epoch:182/3000 AVG Training Loss:0.840 AVG Test Loss:0.052\n",
            "Epoch:183/3000 AVG Training Loss:0.509 AVG Test Loss:0.385\n",
            "Epoch:184/3000 AVG Training Loss:0.684 AVG Test Loss:0.396\n",
            "Epoch:185/3000 AVG Training Loss:0.535 AVG Test Loss:0.192\n",
            "Epoch:186/3000 AVG Training Loss:0.955 AVG Test Loss:0.694\n",
            "Epoch:187/3000 AVG Training Loss:0.654 AVG Test Loss:0.403\n",
            "Epoch:188/3000 AVG Training Loss:0.689 AVG Test Loss:0.921\n",
            "Epoch:189/3000 AVG Training Loss:0.614 AVG Test Loss:0.411\n",
            "Epoch:190/3000 AVG Training Loss:0.465 AVG Test Loss:0.924\n",
            "Epoch:191/3000 AVG Training Loss:0.633 AVG Test Loss:0.813\n",
            "Epoch:192/3000 AVG Training Loss:0.978 AVG Test Loss:0.613\n",
            "Epoch:193/3000 AVG Training Loss:0.766 AVG Test Loss:0.686\n",
            "Epoch:194/3000 AVG Training Loss:0.754 AVG Test Loss:0.173\n",
            "Epoch:195/3000 AVG Training Loss:1.041 AVG Test Loss:0.468\n",
            "Epoch:196/3000 AVG Training Loss:0.777 AVG Test Loss:0.519\n",
            "Epoch:197/3000 AVG Training Loss:0.741 AVG Test Loss:0.525\n",
            "Epoch:198/3000 AVG Training Loss:0.835 AVG Test Loss:0.473\n",
            "Epoch:199/3000 AVG Training Loss:0.641 AVG Test Loss:0.219\n",
            "Epoch:200/3000 AVG Training Loss:0.660 AVG Test Loss:0.334\n",
            "Epoch:201/3000 AVG Training Loss:0.643 AVG Test Loss:0.069\n",
            "Epoch:202/3000 AVG Training Loss:0.666 AVG Test Loss:0.568\n",
            "Epoch:203/3000 AVG Training Loss:0.814 AVG Test Loss:0.429\n",
            "Epoch:204/3000 AVG Training Loss:0.637 AVG Test Loss:0.841\n",
            "Epoch:205/3000 AVG Training Loss:0.527 AVG Test Loss:0.429\n",
            "Epoch:206/3000 AVG Training Loss:0.468 AVG Test Loss:0.585\n",
            "Epoch:207/3000 AVG Training Loss:0.740 AVG Test Loss:0.197\n",
            "Epoch:208/3000 AVG Training Loss:0.484 AVG Test Loss:0.314\n",
            "Epoch:209/3000 AVG Training Loss:0.794 AVG Test Loss:0.248\n",
            "Epoch:210/3000 AVG Training Loss:1.001 AVG Test Loss:0.291\n",
            "Epoch:211/3000 AVG Training Loss:0.485 AVG Test Loss:0.145\n",
            "Epoch:212/3000 AVG Training Loss:0.803 AVG Test Loss:0.872\n",
            "Epoch:213/3000 AVG Training Loss:0.894 AVG Test Loss:0.954\n",
            "Epoch:214/3000 AVG Training Loss:0.813 AVG Test Loss:0.406\n",
            "Epoch:215/3000 AVG Training Loss:0.520 AVG Test Loss:0.232\n",
            "Epoch:216/3000 AVG Training Loss:0.556 AVG Test Loss:0.635\n",
            "Epoch:217/3000 AVG Training Loss:0.611 AVG Test Loss:0.796\n",
            "Epoch:218/3000 AVG Training Loss:0.723 AVG Test Loss:0.417\n",
            "Epoch:219/3000 AVG Training Loss:0.651 AVG Test Loss:0.524\n",
            "Epoch:220/3000 AVG Training Loss:0.524 AVG Test Loss:0.786\n",
            "Epoch:221/3000 AVG Training Loss:0.684 AVG Test Loss:0.882\n",
            "Epoch:222/3000 AVG Training Loss:0.585 AVG Test Loss:0.387\n",
            "Epoch:223/3000 AVG Training Loss:0.327 AVG Test Loss:0.793\n",
            "Epoch:224/3000 AVG Training Loss:0.792 AVG Test Loss:0.593\n",
            "Epoch:225/3000 AVG Training Loss:0.716 AVG Test Loss:0.177\n",
            "Epoch:226/3000 AVG Training Loss:0.387 AVG Test Loss:0.381\n",
            "Epoch:227/3000 AVG Training Loss:0.551 AVG Test Loss:0.367\n",
            "Epoch:228/3000 AVG Training Loss:0.520 AVG Test Loss:0.446\n",
            "Epoch:229/3000 AVG Training Loss:0.553 AVG Test Loss:0.699\n",
            "Epoch:230/3000 AVG Training Loss:0.945 AVG Test Loss:0.910\n",
            "Epoch:231/3000 AVG Training Loss:0.591 AVG Test Loss:1.067\n",
            "Epoch:232/3000 AVG Training Loss:0.567 AVG Test Loss:0.476\n",
            "Epoch:233/3000 AVG Training Loss:0.771 AVG Test Loss:0.279\n",
            "Epoch:234/3000 AVG Training Loss:0.713 AVG Test Loss:1.041\n",
            "Epoch:235/3000 AVG Training Loss:0.516 AVG Test Loss:0.403\n",
            "Epoch:236/3000 AVG Training Loss:0.636 AVG Test Loss:0.331\n",
            "Epoch:237/3000 AVG Training Loss:0.720 AVG Test Loss:0.230\n",
            "Epoch:238/3000 AVG Training Loss:0.726 AVG Test Loss:0.383\n",
            "Epoch:239/3000 AVG Training Loss:0.414 AVG Test Loss:0.464\n",
            "Epoch:240/3000 AVG Training Loss:0.489 AVG Test Loss:1.048\n",
            "Epoch:241/3000 AVG Training Loss:0.865 AVG Test Loss:0.878\n",
            "Epoch:242/3000 AVG Training Loss:0.575 AVG Test Loss:0.885\n",
            "Epoch:243/3000 AVG Training Loss:0.623 AVG Test Loss:0.284\n",
            "Epoch:244/3000 AVG Training Loss:0.438 AVG Test Loss:0.127\n",
            "Epoch:245/3000 AVG Training Loss:0.714 AVG Test Loss:0.613\n",
            "Epoch:246/3000 AVG Training Loss:0.762 AVG Test Loss:0.269\n",
            "Epoch:247/3000 AVG Training Loss:0.680 AVG Test Loss:0.758\n",
            "Epoch:248/3000 AVG Training Loss:0.946 AVG Test Loss:0.342\n",
            "Epoch:249/3000 AVG Training Loss:0.606 AVG Test Loss:0.683\n",
            "Epoch:250/3000 AVG Training Loss:0.598 AVG Test Loss:0.945\n",
            "Epoch:251/3000 AVG Training Loss:0.439 AVG Test Loss:0.489\n",
            "Epoch:252/3000 AVG Training Loss:0.899 AVG Test Loss:0.662\n",
            "Epoch:253/3000 AVG Training Loss:0.644 AVG Test Loss:0.767\n",
            "Epoch:254/3000 AVG Training Loss:0.826 AVG Test Loss:0.427\n",
            "Epoch:255/3000 AVG Training Loss:0.653 AVG Test Loss:0.701\n",
            "Epoch:256/3000 AVG Training Loss:0.626 AVG Test Loss:0.593\n",
            "Epoch:257/3000 AVG Training Loss:0.490 AVG Test Loss:0.916\n",
            "Epoch:258/3000 AVG Training Loss:0.815 AVG Test Loss:0.418\n",
            "Epoch:259/3000 AVG Training Loss:0.736 AVG Test Loss:0.377\n",
            "Epoch:260/3000 AVG Training Loss:0.791 AVG Test Loss:0.921\n",
            "Epoch:261/3000 AVG Training Loss:0.589 AVG Test Loss:0.726\n",
            "Epoch:262/3000 AVG Training Loss:0.756 AVG Test Loss:0.385\n",
            "Epoch:263/3000 AVG Training Loss:0.677 AVG Test Loss:1.061\n",
            "Epoch:264/3000 AVG Training Loss:0.553 AVG Test Loss:0.307\n",
            "Epoch:265/3000 AVG Training Loss:0.515 AVG Test Loss:0.671\n",
            "Epoch:266/3000 AVG Training Loss:0.731 AVG Test Loss:0.234\n",
            "Epoch:267/3000 AVG Training Loss:0.455 AVG Test Loss:0.521\n",
            "Epoch:268/3000 AVG Training Loss:0.605 AVG Test Loss:0.686\n",
            "Epoch:269/3000 AVG Training Loss:0.454 AVG Test Loss:0.407\n",
            "Epoch:270/3000 AVG Training Loss:0.667 AVG Test Loss:0.708\n",
            "Epoch:271/3000 AVG Training Loss:0.589 AVG Test Loss:0.419\n",
            "Epoch:272/3000 AVG Training Loss:0.481 AVG Test Loss:0.599\n",
            "Epoch:273/3000 AVG Training Loss:0.591 AVG Test Loss:0.243\n",
            "Epoch:274/3000 AVG Training Loss:0.659 AVG Test Loss:0.913\n",
            "Epoch:275/3000 AVG Training Loss:0.673 AVG Test Loss:0.860\n",
            "Epoch:276/3000 AVG Training Loss:0.377 AVG Test Loss:0.430\n",
            "Epoch:277/3000 AVG Training Loss:0.624 AVG Test Loss:0.794\n",
            "Epoch:278/3000 AVG Training Loss:0.719 AVG Test Loss:0.194\n",
            "Epoch:279/3000 AVG Training Loss:0.549 AVG Test Loss:0.231\n",
            "Epoch:280/3000 AVG Training Loss:0.450 AVG Test Loss:0.616\n",
            "Epoch:281/3000 AVG Training Loss:0.615 AVG Test Loss:1.138\n",
            "Epoch:282/3000 AVG Training Loss:0.489 AVG Test Loss:0.509\n",
            "Epoch:283/3000 AVG Training Loss:0.453 AVG Test Loss:0.525\n",
            "Epoch:284/3000 AVG Training Loss:0.218 AVG Test Loss:0.437\n",
            "Epoch:285/3000 AVG Training Loss:0.495 AVG Test Loss:0.697\n",
            "Epoch:286/3000 AVG Training Loss:0.359 AVG Test Loss:0.382\n",
            "Epoch:287/3000 AVG Training Loss:0.530 AVG Test Loss:0.598\n",
            "Epoch:288/3000 AVG Training Loss:0.334 AVG Test Loss:0.496\n",
            "Epoch:289/3000 AVG Training Loss:0.843 AVG Test Loss:0.325\n",
            "Epoch:290/3000 AVG Training Loss:0.589 AVG Test Loss:0.930\n",
            "Epoch:291/3000 AVG Training Loss:0.405 AVG Test Loss:0.635\n",
            "Epoch:292/3000 AVG Training Loss:0.692 AVG Test Loss:0.661\n",
            "Epoch:293/3000 AVG Training Loss:0.376 AVG Test Loss:0.400\n",
            "Epoch:294/3000 AVG Training Loss:0.696 AVG Test Loss:0.479\n",
            "Epoch:295/3000 AVG Training Loss:0.538 AVG Test Loss:0.276\n",
            "Epoch:296/3000 AVG Training Loss:0.618 AVG Test Loss:0.221\n",
            "Epoch:297/3000 AVG Training Loss:0.701 AVG Test Loss:0.291\n",
            "Epoch:298/3000 AVG Training Loss:0.699 AVG Test Loss:0.393\n",
            "Epoch:299/3000 AVG Training Loss:0.523 AVG Test Loss:0.286\n",
            "Epoch:300/3000 AVG Training Loss:0.762 AVG Test Loss:0.248\n",
            "Epoch:301/3000 AVG Training Loss:0.535 AVG Test Loss:1.003\n",
            "Epoch:302/3000 AVG Training Loss:0.610 AVG Test Loss:0.149\n",
            "Epoch:303/3000 AVG Training Loss:0.498 AVG Test Loss:1.091\n",
            "Epoch:304/3000 AVG Training Loss:0.511 AVG Test Loss:0.395\n",
            "Epoch:305/3000 AVG Training Loss:0.900 AVG Test Loss:0.669\n",
            "Epoch:306/3000 AVG Training Loss:0.608 AVG Test Loss:0.442\n",
            "Epoch:307/3000 AVG Training Loss:0.732 AVG Test Loss:0.835\n",
            "Epoch:308/3000 AVG Training Loss:0.407 AVG Test Loss:0.507\n",
            "Epoch:309/3000 AVG Training Loss:0.193 AVG Test Loss:0.260\n",
            "Epoch:310/3000 AVG Training Loss:0.441 AVG Test Loss:0.294\n",
            "Epoch:311/3000 AVG Training Loss:0.462 AVG Test Loss:0.484\n",
            "Epoch:312/3000 AVG Training Loss:0.576 AVG Test Loss:0.597\n",
            "Epoch:313/3000 AVG Training Loss:0.615 AVG Test Loss:0.031\n",
            "Epoch:314/3000 AVG Training Loss:0.358 AVG Test Loss:0.768\n",
            "Epoch:315/3000 AVG Training Loss:0.430 AVG Test Loss:0.765\n",
            "Epoch:316/3000 AVG Training Loss:0.541 AVG Test Loss:0.525\n",
            "Epoch:317/3000 AVG Training Loss:0.537 AVG Test Loss:0.096\n",
            "Epoch:318/3000 AVG Training Loss:0.517 AVG Test Loss:0.317\n",
            "Epoch:319/3000 AVG Training Loss:0.592 AVG Test Loss:0.152\n",
            "Epoch:320/3000 AVG Training Loss:0.598 AVG Test Loss:0.501\n",
            "Epoch:321/3000 AVG Training Loss:0.659 AVG Test Loss:0.074\n",
            "Epoch:322/3000 AVG Training Loss:0.357 AVG Test Loss:0.456\n",
            "Epoch:323/3000 AVG Training Loss:0.379 AVG Test Loss:0.549\n",
            "Epoch:324/3000 AVG Training Loss:0.275 AVG Test Loss:0.796\n",
            "Epoch:325/3000 AVG Training Loss:0.790 AVG Test Loss:0.261\n",
            "Epoch:326/3000 AVG Training Loss:0.632 AVG Test Loss:0.222\n",
            "Epoch:327/3000 AVG Training Loss:0.398 AVG Test Loss:0.094\n",
            "Epoch:328/3000 AVG Training Loss:0.731 AVG Test Loss:0.383\n",
            "Epoch:329/3000 AVG Training Loss:0.777 AVG Test Loss:0.634\n",
            "Epoch:330/3000 AVG Training Loss:0.629 AVG Test Loss:0.576\n",
            "Epoch:331/3000 AVG Training Loss:0.396 AVG Test Loss:0.382\n",
            "Epoch:332/3000 AVG Training Loss:0.404 AVG Test Loss:0.355\n",
            "Epoch:333/3000 AVG Training Loss:0.573 AVG Test Loss:0.314\n",
            "Epoch:334/3000 AVG Training Loss:0.403 AVG Test Loss:0.176\n",
            "Epoch:335/3000 AVG Training Loss:0.482 AVG Test Loss:0.126\n",
            "Epoch:336/3000 AVG Training Loss:0.448 AVG Test Loss:0.291\n",
            "Epoch:337/3000 AVG Training Loss:0.618 AVG Test Loss:0.191\n",
            "Epoch:338/3000 AVG Training Loss:0.667 AVG Test Loss:0.621\n",
            "Epoch:339/3000 AVG Training Loss:0.542 AVG Test Loss:0.320\n",
            "Epoch:340/3000 AVG Training Loss:0.486 AVG Test Loss:0.690\n",
            "Epoch:341/3000 AVG Training Loss:0.634 AVG Test Loss:0.547\n",
            "Epoch:342/3000 AVG Training Loss:0.555 AVG Test Loss:0.675\n",
            "Epoch:343/3000 AVG Training Loss:0.518 AVG Test Loss:0.293\n",
            "Epoch:344/3000 AVG Training Loss:0.507 AVG Test Loss:0.548\n",
            "Epoch:345/3000 AVG Training Loss:0.653 AVG Test Loss:0.257\n",
            "Epoch:346/3000 AVG Training Loss:0.394 AVG Test Loss:0.442\n",
            "Epoch:347/3000 AVG Training Loss:0.551 AVG Test Loss:0.397\n",
            "Epoch:348/3000 AVG Training Loss:0.604 AVG Test Loss:0.220\n",
            "Epoch:349/3000 AVG Training Loss:0.565 AVG Test Loss:0.364\n",
            "Epoch:350/3000 AVG Training Loss:0.613 AVG Test Loss:0.298\n",
            "Epoch:351/3000 AVG Training Loss:0.721 AVG Test Loss:0.436\n",
            "Epoch:352/3000 AVG Training Loss:0.729 AVG Test Loss:1.026\n",
            "Epoch:353/3000 AVG Training Loss:0.586 AVG Test Loss:0.496\n",
            "Epoch:354/3000 AVG Training Loss:0.450 AVG Test Loss:0.397\n",
            "Epoch:355/3000 AVG Training Loss:0.596 AVG Test Loss:0.240\n",
            "Epoch:356/3000 AVG Training Loss:0.540 AVG Test Loss:0.345\n",
            "Epoch:357/3000 AVG Training Loss:0.923 AVG Test Loss:0.300\n",
            "Epoch:358/3000 AVG Training Loss:0.311 AVG Test Loss:0.534\n",
            "Epoch:359/3000 AVG Training Loss:0.740 AVG Test Loss:0.257\n",
            "Epoch:360/3000 AVG Training Loss:0.456 AVG Test Loss:0.688\n",
            "Epoch:361/3000 AVG Training Loss:0.376 AVG Test Loss:0.483\n",
            "Epoch:362/3000 AVG Training Loss:0.519 AVG Test Loss:0.261\n",
            "Epoch:363/3000 AVG Training Loss:0.617 AVG Test Loss:0.409\n",
            "Epoch:364/3000 AVG Training Loss:0.826 AVG Test Loss:1.027\n",
            "Epoch:365/3000 AVG Training Loss:0.946 AVG Test Loss:0.324\n",
            "Epoch:366/3000 AVG Training Loss:0.336 AVG Test Loss:0.459\n",
            "Epoch:367/3000 AVG Training Loss:0.317 AVG Test Loss:0.589\n",
            "Epoch:368/3000 AVG Training Loss:0.342 AVG Test Loss:0.589\n",
            "Epoch:369/3000 AVG Training Loss:0.749 AVG Test Loss:0.227\n",
            "Epoch:370/3000 AVG Training Loss:0.506 AVG Test Loss:0.225\n",
            "Epoch:371/3000 AVG Training Loss:0.367 AVG Test Loss:0.467\n",
            "Epoch:372/3000 AVG Training Loss:0.467 AVG Test Loss:0.235\n",
            "Epoch:373/3000 AVG Training Loss:0.549 AVG Test Loss:0.477\n",
            "Epoch:374/3000 AVG Training Loss:0.613 AVG Test Loss:0.382\n",
            "Epoch:375/3000 AVG Training Loss:0.639 AVG Test Loss:0.375\n",
            "Epoch:376/3000 AVG Training Loss:0.685 AVG Test Loss:0.602\n",
            "Epoch:377/3000 AVG Training Loss:0.350 AVG Test Loss:0.448\n",
            "Epoch:378/3000 AVG Training Loss:0.786 AVG Test Loss:0.963\n",
            "Epoch:379/3000 AVG Training Loss:0.687 AVG Test Loss:0.214\n",
            "Epoch:380/3000 AVG Training Loss:0.526 AVG Test Loss:0.295\n",
            "Epoch:381/3000 AVG Training Loss:0.397 AVG Test Loss:0.179\n",
            "Epoch:382/3000 AVG Training Loss:0.889 AVG Test Loss:0.552\n",
            "Epoch:383/3000 AVG Training Loss:0.621 AVG Test Loss:0.242\n",
            "Epoch:384/3000 AVG Training Loss:0.596 AVG Test Loss:0.441\n",
            "Epoch:385/3000 AVG Training Loss:0.930 AVG Test Loss:0.682\n",
            "Epoch:386/3000 AVG Training Loss:0.487 AVG Test Loss:0.208\n",
            "Epoch:387/3000 AVG Training Loss:0.389 AVG Test Loss:0.454\n",
            "Epoch:388/3000 AVG Training Loss:0.625 AVG Test Loss:0.159\n",
            "Epoch:389/3000 AVG Training Loss:0.613 AVG Test Loss:0.745\n",
            "Epoch:390/3000 AVG Training Loss:0.540 AVG Test Loss:0.597\n",
            "Epoch:391/3000 AVG Training Loss:0.510 AVG Test Loss:0.506\n",
            "Epoch:392/3000 AVG Training Loss:0.852 AVG Test Loss:0.651\n",
            "Epoch:393/3000 AVG Training Loss:0.474 AVG Test Loss:0.058\n",
            "Epoch:394/3000 AVG Training Loss:0.392 AVG Test Loss:0.575\n",
            "Epoch:395/3000 AVG Training Loss:0.325 AVG Test Loss:0.469\n",
            "Epoch:396/3000 AVG Training Loss:0.567 AVG Test Loss:0.171\n",
            "Epoch:397/3000 AVG Training Loss:0.439 AVG Test Loss:0.270\n",
            "Epoch:398/3000 AVG Training Loss:0.681 AVG Test Loss:1.157\n",
            "Epoch:399/3000 AVG Training Loss:0.498 AVG Test Loss:0.266\n",
            "Epoch:400/3000 AVG Training Loss:0.553 AVG Test Loss:0.361\n",
            "Epoch:401/3000 AVG Training Loss:0.320 AVG Test Loss:0.372\n",
            "Epoch:402/3000 AVG Training Loss:0.414 AVG Test Loss:0.376\n",
            "Epoch:403/3000 AVG Training Loss:0.654 AVG Test Loss:0.424\n",
            "Epoch:404/3000 AVG Training Loss:0.613 AVG Test Loss:0.374\n",
            "Epoch:405/3000 AVG Training Loss:0.592 AVG Test Loss:0.249\n",
            "Epoch:406/3000 AVG Training Loss:0.528 AVG Test Loss:0.258\n",
            "Epoch:407/3000 AVG Training Loss:0.324 AVG Test Loss:0.202\n",
            "Epoch:408/3000 AVG Training Loss:0.650 AVG Test Loss:0.381\n",
            "Epoch:409/3000 AVG Training Loss:0.554 AVG Test Loss:0.367\n",
            "Epoch:410/3000 AVG Training Loss:0.525 AVG Test Loss:0.310\n",
            "Epoch:411/3000 AVG Training Loss:0.425 AVG Test Loss:0.191\n",
            "Epoch:412/3000 AVG Training Loss:0.522 AVG Test Loss:0.446\n",
            "Epoch:413/3000 AVG Training Loss:0.448 AVG Test Loss:0.441\n",
            "Epoch:414/3000 AVG Training Loss:0.456 AVG Test Loss:0.400\n",
            "Epoch:415/3000 AVG Training Loss:0.399 AVG Test Loss:0.359\n",
            "Epoch:416/3000 AVG Training Loss:0.562 AVG Test Loss:0.545\n",
            "Epoch:417/3000 AVG Training Loss:0.439 AVG Test Loss:0.368\n",
            "Epoch:418/3000 AVG Training Loss:0.542 AVG Test Loss:0.280\n",
            "Epoch:419/3000 AVG Training Loss:0.355 AVG Test Loss:0.435\n",
            "Epoch:420/3000 AVG Training Loss:0.305 AVG Test Loss:0.279\n",
            "Epoch:421/3000 AVG Training Loss:0.356 AVG Test Loss:0.736\n",
            "Epoch:422/3000 AVG Training Loss:0.686 AVG Test Loss:0.370\n",
            "Epoch:423/3000 AVG Training Loss:0.519 AVG Test Loss:0.139\n",
            "Epoch:424/3000 AVG Training Loss:0.587 AVG Test Loss:0.141\n",
            "Epoch:425/3000 AVG Training Loss:0.605 AVG Test Loss:0.717\n",
            "Epoch:426/3000 AVG Training Loss:0.500 AVG Test Loss:0.742\n",
            "Epoch:427/3000 AVG Training Loss:0.369 AVG Test Loss:0.441\n",
            "Epoch:428/3000 AVG Training Loss:0.272 AVG Test Loss:0.777\n",
            "Epoch:429/3000 AVG Training Loss:0.549 AVG Test Loss:0.268\n",
            "Epoch:430/3000 AVG Training Loss:0.590 AVG Test Loss:0.236\n",
            "Epoch:431/3000 AVG Training Loss:0.553 AVG Test Loss:0.342\n",
            "Epoch:432/3000 AVG Training Loss:0.453 AVG Test Loss:0.079\n",
            "Epoch:433/3000 AVG Training Loss:0.488 AVG Test Loss:0.218\n",
            "Epoch:434/3000 AVG Training Loss:0.374 AVG Test Loss:0.129\n",
            "Epoch:435/3000 AVG Training Loss:0.527 AVG Test Loss:0.541\n",
            "Epoch:436/3000 AVG Training Loss:0.338 AVG Test Loss:0.438\n",
            "Epoch:437/3000 AVG Training Loss:0.327 AVG Test Loss:0.167\n",
            "Epoch:438/3000 AVG Training Loss:0.433 AVG Test Loss:0.451\n",
            "Epoch:439/3000 AVG Training Loss:0.552 AVG Test Loss:0.428\n",
            "Epoch:440/3000 AVG Training Loss:0.365 AVG Test Loss:0.411\n",
            "Epoch:441/3000 AVG Training Loss:0.599 AVG Test Loss:0.340\n",
            "Epoch:442/3000 AVG Training Loss:0.548 AVG Test Loss:0.355\n",
            "Epoch:443/3000 AVG Training Loss:0.666 AVG Test Loss:0.565\n",
            "Epoch:444/3000 AVG Training Loss:0.352 AVG Test Loss:0.471\n",
            "Epoch:445/3000 AVG Training Loss:0.281 AVG Test Loss:0.390\n",
            "Epoch:446/3000 AVG Training Loss:0.403 AVG Test Loss:0.216\n",
            "Epoch:447/3000 AVG Training Loss:0.503 AVG Test Loss:0.617\n",
            "Epoch:448/3000 AVG Training Loss:0.712 AVG Test Loss:0.309\n",
            "Epoch:449/3000 AVG Training Loss:0.282 AVG Test Loss:0.385\n",
            "Epoch:450/3000 AVG Training Loss:0.445 AVG Test Loss:0.082\n",
            "Epoch:451/3000 AVG Training Loss:0.320 AVG Test Loss:0.230\n",
            "Epoch:452/3000 AVG Training Loss:0.333 AVG Test Loss:0.292\n",
            "Epoch:453/3000 AVG Training Loss:0.412 AVG Test Loss:0.480\n",
            "Epoch:454/3000 AVG Training Loss:0.608 AVG Test Loss:0.430\n",
            "Epoch:455/3000 AVG Training Loss:0.455 AVG Test Loss:0.430\n",
            "Epoch:456/3000 AVG Training Loss:0.598 AVG Test Loss:0.279\n",
            "Epoch:457/3000 AVG Training Loss:0.596 AVG Test Loss:0.386\n",
            "Epoch:458/3000 AVG Training Loss:0.665 AVG Test Loss:0.486\n",
            "Epoch:459/3000 AVG Training Loss:0.323 AVG Test Loss:0.285\n",
            "Epoch:460/3000 AVG Training Loss:0.512 AVG Test Loss:0.358\n",
            "Epoch:461/3000 AVG Training Loss:0.560 AVG Test Loss:0.594\n",
            "Epoch:462/3000 AVG Training Loss:0.418 AVG Test Loss:0.224\n",
            "Epoch:463/3000 AVG Training Loss:0.337 AVG Test Loss:0.214\n",
            "Epoch:464/3000 AVG Training Loss:0.510 AVG Test Loss:0.204\n",
            "Epoch:465/3000 AVG Training Loss:0.539 AVG Test Loss:0.393\n",
            "Epoch:466/3000 AVG Training Loss:0.555 AVG Test Loss:0.155\n",
            "Epoch:467/3000 AVG Training Loss:0.624 AVG Test Loss:0.367\n",
            "Epoch:468/3000 AVG Training Loss:0.391 AVG Test Loss:0.510\n",
            "Epoch:469/3000 AVG Training Loss:0.417 AVG Test Loss:0.605\n",
            "Epoch:470/3000 AVG Training Loss:0.621 AVG Test Loss:0.503\n",
            "Epoch:471/3000 AVG Training Loss:0.384 AVG Test Loss:0.184\n",
            "Epoch:472/3000 AVG Training Loss:0.449 AVG Test Loss:0.429\n",
            "Epoch:473/3000 AVG Training Loss:0.303 AVG Test Loss:0.565\n",
            "Epoch:474/3000 AVG Training Loss:0.292 AVG Test Loss:0.220\n",
            "Epoch:475/3000 AVG Training Loss:0.416 AVG Test Loss:0.403\n",
            "Epoch:476/3000 AVG Training Loss:0.465 AVG Test Loss:0.299\n",
            "Epoch:477/3000 AVG Training Loss:0.436 AVG Test Loss:0.264\n",
            "Epoch:478/3000 AVG Training Loss:0.344 AVG Test Loss:0.757\n",
            "Epoch:479/3000 AVG Training Loss:0.312 AVG Test Loss:0.255\n",
            "Epoch:480/3000 AVG Training Loss:0.464 AVG Test Loss:0.103\n",
            "Epoch:481/3000 AVG Training Loss:0.357 AVG Test Loss:0.346\n",
            "Epoch:482/3000 AVG Training Loss:0.445 AVG Test Loss:0.220\n",
            "Epoch:483/3000 AVG Training Loss:0.289 AVG Test Loss:0.298\n",
            "Epoch:484/3000 AVG Training Loss:0.329 AVG Test Loss:0.331\n",
            "Epoch:485/3000 AVG Training Loss:0.245 AVG Test Loss:0.281\n",
            "Epoch:486/3000 AVG Training Loss:0.295 AVG Test Loss:0.228\n",
            "Epoch:487/3000 AVG Training Loss:0.434 AVG Test Loss:0.151\n",
            "Epoch:488/3000 AVG Training Loss:0.402 AVG Test Loss:0.327\n",
            "Epoch:489/3000 AVG Training Loss:0.482 AVG Test Loss:0.249\n",
            "Epoch:490/3000 AVG Training Loss:0.410 AVG Test Loss:0.332\n",
            "Epoch:491/3000 AVG Training Loss:0.299 AVG Test Loss:0.379\n",
            "Epoch:492/3000 AVG Training Loss:0.466 AVG Test Loss:0.325\n",
            "Epoch:493/3000 AVG Training Loss:0.405 AVG Test Loss:0.201\n",
            "Epoch:494/3000 AVG Training Loss:0.562 AVG Test Loss:0.311\n",
            "Epoch:495/3000 AVG Training Loss:0.347 AVG Test Loss:0.082\n",
            "Epoch:496/3000 AVG Training Loss:0.381 AVG Test Loss:0.332\n",
            "Epoch:497/3000 AVG Training Loss:0.482 AVG Test Loss:0.391\n",
            "Epoch:498/3000 AVG Training Loss:0.601 AVG Test Loss:0.272\n",
            "Epoch:499/3000 AVG Training Loss:0.337 AVG Test Loss:0.255\n",
            "Epoch:500/3000 AVG Training Loss:0.436 AVG Test Loss:0.416\n",
            "Epoch:501/3000 AVG Training Loss:0.359 AVG Test Loss:0.507\n",
            "Epoch:502/3000 AVG Training Loss:0.317 AVG Test Loss:0.517\n",
            "Epoch:503/3000 AVG Training Loss:0.336 AVG Test Loss:0.464\n",
            "Epoch:504/3000 AVG Training Loss:0.371 AVG Test Loss:0.609\n",
            "Epoch:505/3000 AVG Training Loss:0.414 AVG Test Loss:0.142\n",
            "Epoch:506/3000 AVG Training Loss:0.309 AVG Test Loss:0.618\n",
            "Epoch:507/3000 AVG Training Loss:0.419 AVG Test Loss:0.341\n",
            "Epoch:508/3000 AVG Training Loss:0.463 AVG Test Loss:0.370\n",
            "Epoch:509/3000 AVG Training Loss:0.435 AVG Test Loss:0.359\n",
            "Epoch:510/3000 AVG Training Loss:0.405 AVG Test Loss:0.314\n",
            "Epoch:511/3000 AVG Training Loss:0.455 AVG Test Loss:0.224\n",
            "Epoch:512/3000 AVG Training Loss:0.491 AVG Test Loss:0.481\n",
            "Epoch:513/3000 AVG Training Loss:0.377 AVG Test Loss:0.167\n",
            "Epoch:514/3000 AVG Training Loss:0.285 AVG Test Loss:0.563\n",
            "Epoch:515/3000 AVG Training Loss:0.382 AVG Test Loss:0.435\n",
            "Epoch:516/3000 AVG Training Loss:0.234 AVG Test Loss:0.150\n",
            "Epoch:517/3000 AVG Training Loss:0.349 AVG Test Loss:0.398\n",
            "Epoch:518/3000 AVG Training Loss:0.360 AVG Test Loss:0.338\n",
            "Epoch:519/3000 AVG Training Loss:0.527 AVG Test Loss:0.390\n",
            "Epoch:520/3000 AVG Training Loss:0.400 AVG Test Loss:0.249\n",
            "Epoch:521/3000 AVG Training Loss:0.290 AVG Test Loss:0.139\n",
            "Epoch:522/3000 AVG Training Loss:0.411 AVG Test Loss:0.601\n",
            "Epoch:523/3000 AVG Training Loss:0.520 AVG Test Loss:0.278\n",
            "Epoch:524/3000 AVG Training Loss:0.680 AVG Test Loss:0.349\n",
            "Epoch:525/3000 AVG Training Loss:0.239 AVG Test Loss:0.382\n",
            "Epoch:526/3000 AVG Training Loss:0.288 AVG Test Loss:0.506\n",
            "Epoch:527/3000 AVG Training Loss:0.486 AVG Test Loss:0.230\n",
            "Epoch:528/3000 AVG Training Loss:0.239 AVG Test Loss:0.393\n",
            "Epoch:529/3000 AVG Training Loss:0.483 AVG Test Loss:0.277\n",
            "Epoch:530/3000 AVG Training Loss:0.174 AVG Test Loss:0.286\n",
            "Epoch:531/3000 AVG Training Loss:0.336 AVG Test Loss:0.148\n",
            "Epoch:532/3000 AVG Training Loss:0.417 AVG Test Loss:0.433\n",
            "Epoch:533/3000 AVG Training Loss:0.354 AVG Test Loss:0.043\n",
            "Epoch:534/3000 AVG Training Loss:0.374 AVG Test Loss:0.369\n",
            "Epoch:535/3000 AVG Training Loss:0.513 AVG Test Loss:0.310\n",
            "Epoch:536/3000 AVG Training Loss:0.281 AVG Test Loss:0.103\n",
            "Epoch:537/3000 AVG Training Loss:0.328 AVG Test Loss:0.314\n",
            "Epoch:538/3000 AVG Training Loss:0.244 AVG Test Loss:0.393\n",
            "Epoch:539/3000 AVG Training Loss:0.275 AVG Test Loss:0.200\n",
            "Epoch:540/3000 AVG Training Loss:0.338 AVG Test Loss:0.101\n",
            "Epoch:541/3000 AVG Training Loss:0.450 AVG Test Loss:0.095\n",
            "Epoch:542/3000 AVG Training Loss:0.348 AVG Test Loss:0.446\n",
            "Epoch:543/3000 AVG Training Loss:0.313 AVG Test Loss:0.596\n",
            "Epoch:544/3000 AVG Training Loss:0.291 AVG Test Loss:0.108\n",
            "Epoch:545/3000 AVG Training Loss:0.345 AVG Test Loss:0.281\n",
            "Epoch:546/3000 AVG Training Loss:0.277 AVG Test Loss:0.198\n",
            "Epoch:547/3000 AVG Training Loss:0.364 AVG Test Loss:0.336\n",
            "Epoch:548/3000 AVG Training Loss:0.443 AVG Test Loss:0.717\n",
            "Epoch:549/3000 AVG Training Loss:0.411 AVG Test Loss:0.281\n",
            "Epoch:550/3000 AVG Training Loss:0.385 AVG Test Loss:0.066\n",
            "Epoch:551/3000 AVG Training Loss:0.417 AVG Test Loss:0.049\n",
            "Epoch:552/3000 AVG Training Loss:0.312 AVG Test Loss:0.301\n",
            "Epoch:553/3000 AVG Training Loss:0.264 AVG Test Loss:0.192\n",
            "Epoch:554/3000 AVG Training Loss:0.260 AVG Test Loss:0.147\n",
            "Epoch:555/3000 AVG Training Loss:0.278 AVG Test Loss:0.246\n",
            "Epoch:556/3000 AVG Training Loss:0.320 AVG Test Loss:0.459\n",
            "Epoch:557/3000 AVG Training Loss:0.407 AVG Test Loss:0.201\n",
            "Epoch:558/3000 AVG Training Loss:0.413 AVG Test Loss:0.526\n",
            "Epoch:559/3000 AVG Training Loss:0.212 AVG Test Loss:0.216\n",
            "Epoch:560/3000 AVG Training Loss:0.260 AVG Test Loss:0.288\n",
            "Epoch:561/3000 AVG Training Loss:0.376 AVG Test Loss:0.178\n",
            "Epoch:562/3000 AVG Training Loss:0.215 AVG Test Loss:0.235\n",
            "Epoch:563/3000 AVG Training Loss:0.179 AVG Test Loss:0.122\n",
            "Epoch:564/3000 AVG Training Loss:0.329 AVG Test Loss:0.178\n",
            "Epoch:565/3000 AVG Training Loss:0.378 AVG Test Loss:0.502\n",
            "Epoch:566/3000 AVG Training Loss:0.359 AVG Test Loss:0.136\n",
            "Epoch:567/3000 AVG Training Loss:0.199 AVG Test Loss:0.334\n",
            "Epoch:568/3000 AVG Training Loss:0.219 AVG Test Loss:0.299\n",
            "Epoch:569/3000 AVG Training Loss:0.259 AVG Test Loss:0.156\n",
            "Epoch:570/3000 AVG Training Loss:0.370 AVG Test Loss:0.460\n",
            "Epoch:571/3000 AVG Training Loss:0.217 AVG Test Loss:0.221\n",
            "Epoch:572/3000 AVG Training Loss:0.327 AVG Test Loss:0.211\n",
            "Epoch:573/3000 AVG Training Loss:0.305 AVG Test Loss:0.441\n",
            "Epoch:574/3000 AVG Training Loss:0.333 AVG Test Loss:0.056\n",
            "Epoch:575/3000 AVG Training Loss:0.440 AVG Test Loss:0.426\n",
            "Epoch:576/3000 AVG Training Loss:0.209 AVG Test Loss:0.047\n",
            "Epoch:577/3000 AVG Training Loss:0.314 AVG Test Loss:0.238\n",
            "Epoch:578/3000 AVG Training Loss:0.194 AVG Test Loss:0.264\n",
            "Epoch:579/3000 AVG Training Loss:0.207 AVG Test Loss:0.305\n",
            "Epoch:580/3000 AVG Training Loss:0.234 AVG Test Loss:0.221\n",
            "Epoch:581/3000 AVG Training Loss:0.317 AVG Test Loss:0.205\n",
            "Epoch:582/3000 AVG Training Loss:0.363 AVG Test Loss:0.331\n",
            "Epoch:583/3000 AVG Training Loss:0.257 AVG Test Loss:0.134\n",
            "Epoch:584/3000 AVG Training Loss:0.257 AVG Test Loss:0.118\n",
            "Epoch:585/3000 AVG Training Loss:0.217 AVG Test Loss:0.382\n",
            "Epoch:586/3000 AVG Training Loss:0.459 AVG Test Loss:0.194\n",
            "Epoch:587/3000 AVG Training Loss:0.479 AVG Test Loss:0.161\n",
            "Epoch:588/3000 AVG Training Loss:0.178 AVG Test Loss:0.216\n",
            "Epoch:589/3000 AVG Training Loss:0.255 AVG Test Loss:0.351\n",
            "Epoch:590/3000 AVG Training Loss:0.480 AVG Test Loss:0.234\n",
            "Epoch:591/3000 AVG Training Loss:0.289 AVG Test Loss:0.323\n",
            "Epoch:592/3000 AVG Training Loss:0.288 AVG Test Loss:0.244\n",
            "Epoch:593/3000 AVG Training Loss:0.317 AVG Test Loss:0.197\n",
            "Epoch:594/3000 AVG Training Loss:0.271 AVG Test Loss:0.309\n",
            "Epoch:595/3000 AVG Training Loss:0.207 AVG Test Loss:0.311\n",
            "Epoch:596/3000 AVG Training Loss:0.349 AVG Test Loss:0.277\n",
            "Epoch:597/3000 AVG Training Loss:0.298 AVG Test Loss:0.034\n",
            "Epoch:598/3000 AVG Training Loss:0.247 AVG Test Loss:0.276\n",
            "Epoch:599/3000 AVG Training Loss:0.276 AVG Test Loss:0.418\n",
            "Epoch:600/3000 AVG Training Loss:0.272 AVG Test Loss:0.318\n",
            "Epoch:601/3000 AVG Training Loss:0.372 AVG Test Loss:0.278\n",
            "Epoch:602/3000 AVG Training Loss:0.328 AVG Test Loss:0.176\n",
            "Epoch:603/3000 AVG Training Loss:0.216 AVG Test Loss:0.388\n",
            "Epoch:604/3000 AVG Training Loss:0.288 AVG Test Loss:0.244\n",
            "Epoch:605/3000 AVG Training Loss:0.351 AVG Test Loss:0.372\n",
            "Epoch:606/3000 AVG Training Loss:0.175 AVG Test Loss:0.221\n",
            "Epoch:607/3000 AVG Training Loss:0.428 AVG Test Loss:0.096\n",
            "Epoch:608/3000 AVG Training Loss:0.231 AVG Test Loss:0.158\n",
            "Epoch:609/3000 AVG Training Loss:0.191 AVG Test Loss:0.263\n",
            "Epoch:610/3000 AVG Training Loss:0.149 AVG Test Loss:0.365\n",
            "Epoch:611/3000 AVG Training Loss:0.304 AVG Test Loss:0.195\n",
            "Epoch:612/3000 AVG Training Loss:0.310 AVG Test Loss:0.260\n",
            "Epoch:613/3000 AVG Training Loss:0.324 AVG Test Loss:0.249\n",
            "Epoch:614/3000 AVG Training Loss:0.261 AVG Test Loss:0.509\n",
            "Epoch:615/3000 AVG Training Loss:0.302 AVG Test Loss:0.217\n",
            "Epoch:616/3000 AVG Training Loss:0.346 AVG Test Loss:0.303\n",
            "Epoch:617/3000 AVG Training Loss:0.277 AVG Test Loss:0.265\n",
            "Epoch:618/3000 AVG Training Loss:0.342 AVG Test Loss:0.131\n",
            "Epoch:619/3000 AVG Training Loss:0.179 AVG Test Loss:0.295\n",
            "Epoch:620/3000 AVG Training Loss:0.280 AVG Test Loss:0.394\n",
            "Epoch:621/3000 AVG Training Loss:0.260 AVG Test Loss:0.420\n",
            "Epoch:622/3000 AVG Training Loss:0.233 AVG Test Loss:0.337\n",
            "Epoch:623/3000 AVG Training Loss:0.292 AVG Test Loss:0.177\n",
            "Epoch:624/3000 AVG Training Loss:0.293 AVG Test Loss:0.412\n",
            "Epoch:625/3000 AVG Training Loss:0.227 AVG Test Loss:0.320\n",
            "Epoch:626/3000 AVG Training Loss:0.224 AVG Test Loss:0.170\n",
            "Epoch:627/3000 AVG Training Loss:0.280 AVG Test Loss:0.124\n",
            "Epoch:628/3000 AVG Training Loss:0.314 AVG Test Loss:0.224\n",
            "Epoch:629/3000 AVG Training Loss:0.180 AVG Test Loss:0.029\n",
            "Epoch:630/3000 AVG Training Loss:0.229 AVG Test Loss:0.297\n",
            "Epoch:631/3000 AVG Training Loss:0.163 AVG Test Loss:0.173\n",
            "Epoch:632/3000 AVG Training Loss:0.178 AVG Test Loss:0.213\n",
            "Epoch:633/3000 AVG Training Loss:0.338 AVG Test Loss:0.359\n",
            "Epoch:634/3000 AVG Training Loss:0.217 AVG Test Loss:0.115\n",
            "Epoch:635/3000 AVG Training Loss:0.168 AVG Test Loss:0.348\n",
            "Epoch:636/3000 AVG Training Loss:0.276 AVG Test Loss:0.324\n",
            "Epoch:637/3000 AVG Training Loss:0.198 AVG Test Loss:0.189\n",
            "Epoch:638/3000 AVG Training Loss:0.263 AVG Test Loss:0.270\n",
            "Epoch:639/3000 AVG Training Loss:0.239 AVG Test Loss:0.214\n",
            "Epoch:640/3000 AVG Training Loss:0.246 AVG Test Loss:0.266\n",
            "Epoch:641/3000 AVG Training Loss:0.223 AVG Test Loss:0.353\n",
            "Epoch:642/3000 AVG Training Loss:0.272 AVG Test Loss:0.206\n",
            "Epoch:643/3000 AVG Training Loss:0.210 AVG Test Loss:0.275\n",
            "Epoch:644/3000 AVG Training Loss:0.238 AVG Test Loss:0.180\n",
            "Epoch:645/3000 AVG Training Loss:0.226 AVG Test Loss:0.348\n",
            "Epoch:646/3000 AVG Training Loss:0.206 AVG Test Loss:0.525\n",
            "Epoch:647/3000 AVG Training Loss:0.316 AVG Test Loss:0.051\n",
            "Epoch:648/3000 AVG Training Loss:0.279 AVG Test Loss:0.378\n",
            "Epoch:649/3000 AVG Training Loss:0.237 AVG Test Loss:0.191\n",
            "Epoch:650/3000 AVG Training Loss:0.249 AVG Test Loss:0.136\n",
            "Epoch:651/3000 AVG Training Loss:0.272 AVG Test Loss:0.234\n",
            "Epoch:652/3000 AVG Training Loss:0.235 AVG Test Loss:0.057\n",
            "Epoch:653/3000 AVG Training Loss:0.198 AVG Test Loss:0.130\n",
            "Epoch:654/3000 AVG Training Loss:0.177 AVG Test Loss:0.256\n",
            "Epoch:655/3000 AVG Training Loss:0.203 AVG Test Loss:0.379\n",
            "Epoch:656/3000 AVG Training Loss:0.242 AVG Test Loss:0.108\n",
            "Epoch:657/3000 AVG Training Loss:0.218 AVG Test Loss:0.085\n",
            "Epoch:658/3000 AVG Training Loss:0.281 AVG Test Loss:0.433\n",
            "Epoch:659/3000 AVG Training Loss:0.219 AVG Test Loss:0.496\n",
            "Epoch:660/3000 AVG Training Loss:0.215 AVG Test Loss:0.063\n",
            "Epoch:661/3000 AVG Training Loss:0.352 AVG Test Loss:0.066\n",
            "Epoch:662/3000 AVG Training Loss:0.420 AVG Test Loss:0.446\n",
            "Epoch:663/3000 AVG Training Loss:0.287 AVG Test Loss:0.337\n",
            "Epoch:664/3000 AVG Training Loss:0.251 AVG Test Loss:0.299\n",
            "Epoch:665/3000 AVG Training Loss:0.367 AVG Test Loss:0.120\n",
            "Epoch:666/3000 AVG Training Loss:0.174 AVG Test Loss:0.068\n",
            "Epoch:667/3000 AVG Training Loss:0.183 AVG Test Loss:0.178\n",
            "Epoch:668/3000 AVG Training Loss:0.203 AVG Test Loss:0.300\n",
            "Epoch:669/3000 AVG Training Loss:0.220 AVG Test Loss:0.286\n",
            "Epoch:670/3000 AVG Training Loss:0.207 AVG Test Loss:0.492\n",
            "Epoch:671/3000 AVG Training Loss:0.335 AVG Test Loss:0.073\n",
            "Epoch:672/3000 AVG Training Loss:0.193 AVG Test Loss:0.355\n",
            "Epoch:673/3000 AVG Training Loss:0.227 AVG Test Loss:0.247\n",
            "Epoch:674/3000 AVG Training Loss:0.169 AVG Test Loss:0.484\n",
            "Epoch:675/3000 AVG Training Loss:0.182 AVG Test Loss:0.366\n",
            "Epoch:676/3000 AVG Training Loss:0.210 AVG Test Loss:0.317\n",
            "Epoch:677/3000 AVG Training Loss:0.301 AVG Test Loss:0.145\n",
            "Epoch:678/3000 AVG Training Loss:0.237 AVG Test Loss:0.388\n",
            "Epoch:679/3000 AVG Training Loss:0.188 AVG Test Loss:0.527\n",
            "Epoch:680/3000 AVG Training Loss:0.217 AVG Test Loss:0.035\n",
            "Epoch:681/3000 AVG Training Loss:0.261 AVG Test Loss:0.069\n",
            "Epoch:682/3000 AVG Training Loss:0.225 AVG Test Loss:0.288\n",
            "Epoch:683/3000 AVG Training Loss:0.231 AVG Test Loss:0.304\n",
            "Epoch:684/3000 AVG Training Loss:0.143 AVG Test Loss:0.464\n",
            "Epoch:685/3000 AVG Training Loss:0.144 AVG Test Loss:0.150\n",
            "Epoch:686/3000 AVG Training Loss:0.160 AVG Test Loss:0.333\n",
            "Epoch:687/3000 AVG Training Loss:0.173 AVG Test Loss:0.486\n",
            "Epoch:688/3000 AVG Training Loss:0.290 AVG Test Loss:0.259\n",
            "Epoch:689/3000 AVG Training Loss:0.205 AVG Test Loss:0.409\n",
            "Epoch:690/3000 AVG Training Loss:0.236 AVG Test Loss:0.355\n",
            "Epoch:691/3000 AVG Training Loss:0.206 AVG Test Loss:0.083\n",
            "Epoch:692/3000 AVG Training Loss:0.226 AVG Test Loss:0.336\n",
            "Epoch:693/3000 AVG Training Loss:0.172 AVG Test Loss:0.103\n",
            "Epoch:694/3000 AVG Training Loss:0.230 AVG Test Loss:0.294\n",
            "Epoch:695/3000 AVG Training Loss:0.147 AVG Test Loss:0.060\n",
            "Epoch:696/3000 AVG Training Loss:0.140 AVG Test Loss:0.166\n",
            "Epoch:697/3000 AVG Training Loss:0.219 AVG Test Loss:0.079\n",
            "Epoch:698/3000 AVG Training Loss:0.323 AVG Test Loss:0.171\n",
            "Epoch:699/3000 AVG Training Loss:0.163 AVG Test Loss:0.215\n",
            "Epoch:700/3000 AVG Training Loss:0.212 AVG Test Loss:0.085\n",
            "Epoch:701/3000 AVG Training Loss:0.276 AVG Test Loss:0.466\n",
            "Epoch:702/3000 AVG Training Loss:0.229 AVG Test Loss:0.529\n",
            "Epoch:703/3000 AVG Training Loss:0.252 AVG Test Loss:0.283\n",
            "Epoch:704/3000 AVG Training Loss:0.212 AVG Test Loss:0.245\n",
            "Epoch:705/3000 AVG Training Loss:0.163 AVG Test Loss:0.285\n",
            "Epoch:706/3000 AVG Training Loss:0.197 AVG Test Loss:0.151\n",
            "Epoch:707/3000 AVG Training Loss:0.182 AVG Test Loss:0.004\n",
            "Epoch:708/3000 AVG Training Loss:0.246 AVG Test Loss:0.187\n",
            "Epoch:709/3000 AVG Training Loss:0.213 AVG Test Loss:0.019\n",
            "Epoch:710/3000 AVG Training Loss:0.236 AVG Test Loss:0.178\n",
            "Epoch:711/3000 AVG Training Loss:0.257 AVG Test Loss:0.109\n",
            "Epoch:712/3000 AVG Training Loss:0.158 AVG Test Loss:0.154\n",
            "Epoch:713/3000 AVG Training Loss:0.245 AVG Test Loss:0.200\n",
            "Epoch:714/3000 AVG Training Loss:0.138 AVG Test Loss:0.366\n",
            "Epoch:715/3000 AVG Training Loss:0.179 AVG Test Loss:0.193\n",
            "Epoch:716/3000 AVG Training Loss:0.157 AVG Test Loss:0.106\n",
            "Epoch:717/3000 AVG Training Loss:0.134 AVG Test Loss:0.218\n",
            "Epoch:718/3000 AVG Training Loss:0.167 AVG Test Loss:0.437\n",
            "Epoch:719/3000 AVG Training Loss:0.199 AVG Test Loss:0.309\n",
            "Epoch:720/3000 AVG Training Loss:0.165 AVG Test Loss:0.211\n",
            "Epoch:721/3000 AVG Training Loss:0.254 AVG Test Loss:0.053\n",
            "Epoch:722/3000 AVG Training Loss:0.183 AVG Test Loss:0.167\n",
            "Epoch:723/3000 AVG Training Loss:0.211 AVG Test Loss:0.087\n",
            "Epoch:724/3000 AVG Training Loss:0.200 AVG Test Loss:0.075\n",
            "Epoch:725/3000 AVG Training Loss:0.275 AVG Test Loss:0.200\n",
            "Epoch:726/3000 AVG Training Loss:0.298 AVG Test Loss:0.388\n",
            "Epoch:727/3000 AVG Training Loss:0.263 AVG Test Loss:0.316\n",
            "Epoch:728/3000 AVG Training Loss:0.193 AVG Test Loss:0.171\n",
            "Epoch:729/3000 AVG Training Loss:0.143 AVG Test Loss:0.373\n",
            "Epoch:730/3000 AVG Training Loss:0.158 AVG Test Loss:0.014\n",
            "Epoch:731/3000 AVG Training Loss:0.233 AVG Test Loss:0.295\n",
            "Epoch:732/3000 AVG Training Loss:0.146 AVG Test Loss:0.141\n",
            "Epoch:733/3000 AVG Training Loss:0.199 AVG Test Loss:0.245\n",
            "Epoch:734/3000 AVG Training Loss:0.217 AVG Test Loss:0.379\n",
            "Epoch:735/3000 AVG Training Loss:0.201 AVG Test Loss:0.149\n",
            "Epoch:736/3000 AVG Training Loss:0.227 AVG Test Loss:0.084\n",
            "Epoch:737/3000 AVG Training Loss:0.274 AVG Test Loss:0.153\n",
            "Epoch:738/3000 AVG Training Loss:0.201 AVG Test Loss:0.169\n",
            "Epoch:739/3000 AVG Training Loss:0.214 AVG Test Loss:0.037\n",
            "Epoch:740/3000 AVG Training Loss:0.165 AVG Test Loss:0.190\n",
            "Epoch:741/3000 AVG Training Loss:0.193 AVG Test Loss:0.092\n",
            "Epoch:742/3000 AVG Training Loss:0.193 AVG Test Loss:0.274\n",
            "Epoch:743/3000 AVG Training Loss:0.197 AVG Test Loss:0.072\n",
            "Epoch:744/3000 AVG Training Loss:0.174 AVG Test Loss:0.070\n",
            "Epoch:745/3000 AVG Training Loss:0.212 AVG Test Loss:0.193\n",
            "Epoch:746/3000 AVG Training Loss:0.128 AVG Test Loss:0.457\n",
            "Epoch:747/3000 AVG Training Loss:0.263 AVG Test Loss:0.057\n",
            "Epoch:748/3000 AVG Training Loss:0.180 AVG Test Loss:0.189\n",
            "Epoch:749/3000 AVG Training Loss:0.375 AVG Test Loss:0.066\n",
            "Epoch:750/3000 AVG Training Loss:0.216 AVG Test Loss:0.156\n",
            "Epoch:751/3000 AVG Training Loss:0.326 AVG Test Loss:0.224\n",
            "Epoch:752/3000 AVG Training Loss:0.235 AVG Test Loss:0.330\n",
            "Epoch:753/3000 AVG Training Loss:0.250 AVG Test Loss:0.602\n",
            "Epoch:754/3000 AVG Training Loss:0.247 AVG Test Loss:0.022\n",
            "Epoch:755/3000 AVG Training Loss:0.139 AVG Test Loss:0.359\n",
            "Epoch:756/3000 AVG Training Loss:0.229 AVG Test Loss:0.183\n",
            "Epoch:757/3000 AVG Training Loss:0.202 AVG Test Loss:0.024\n",
            "Epoch:758/3000 AVG Training Loss:0.153 AVG Test Loss:0.191\n",
            "Epoch:759/3000 AVG Training Loss:0.167 AVG Test Loss:0.405\n",
            "Epoch:760/3000 AVG Training Loss:0.141 AVG Test Loss:0.108\n",
            "Epoch:761/3000 AVG Training Loss:0.163 AVG Test Loss:0.263\n",
            "Epoch:762/3000 AVG Training Loss:0.172 AVG Test Loss:0.123\n",
            "Epoch:763/3000 AVG Training Loss:0.124 AVG Test Loss:0.289\n",
            "Epoch:764/3000 AVG Training Loss:0.304 AVG Test Loss:0.299\n",
            "Epoch:765/3000 AVG Training Loss:0.183 AVG Test Loss:0.374\n",
            "Epoch:766/3000 AVG Training Loss:0.234 AVG Test Loss:0.187\n",
            "Epoch:767/3000 AVG Training Loss:0.175 AVG Test Loss:0.152\n",
            "Epoch:768/3000 AVG Training Loss:0.258 AVG Test Loss:0.287\n",
            "Epoch:769/3000 AVG Training Loss:0.183 AVG Test Loss:0.327\n",
            "Epoch:770/3000 AVG Training Loss:0.205 AVG Test Loss:0.319\n",
            "Epoch:771/3000 AVG Training Loss:0.118 AVG Test Loss:0.326\n",
            "Epoch:772/3000 AVG Training Loss:0.170 AVG Test Loss:0.014\n",
            "Epoch:773/3000 AVG Training Loss:0.202 AVG Test Loss:0.176\n",
            "Epoch:774/3000 AVG Training Loss:0.191 AVG Test Loss:0.152\n",
            "Epoch:775/3000 AVG Training Loss:0.185 AVG Test Loss:0.319\n",
            "Epoch:776/3000 AVG Training Loss:0.234 AVG Test Loss:0.538\n",
            "Epoch:777/3000 AVG Training Loss:0.131 AVG Test Loss:0.313\n",
            "Epoch:778/3000 AVG Training Loss:0.207 AVG Test Loss:0.146\n",
            "Epoch:779/3000 AVG Training Loss:0.188 AVG Test Loss:0.161\n",
            "Epoch:780/3000 AVG Training Loss:0.147 AVG Test Loss:0.193\n",
            "Epoch:781/3000 AVG Training Loss:0.199 AVG Test Loss:0.148\n",
            "Epoch:782/3000 AVG Training Loss:0.204 AVG Test Loss:0.359\n",
            "Epoch:783/3000 AVG Training Loss:0.174 AVG Test Loss:0.076\n",
            "Epoch:784/3000 AVG Training Loss:0.144 AVG Test Loss:0.231\n",
            "Epoch:785/3000 AVG Training Loss:0.103 AVG Test Loss:0.218\n",
            "Epoch:786/3000 AVG Training Loss:0.169 AVG Test Loss:0.177\n",
            "Epoch:787/3000 AVG Training Loss:0.200 AVG Test Loss:0.146\n",
            "Epoch:788/3000 AVG Training Loss:0.264 AVG Test Loss:0.122\n",
            "Epoch:789/3000 AVG Training Loss:0.162 AVG Test Loss:0.158\n",
            "Epoch:790/3000 AVG Training Loss:0.203 AVG Test Loss:0.064\n",
            "Epoch:791/3000 AVG Training Loss:0.160 AVG Test Loss:0.159\n",
            "Epoch:792/3000 AVG Training Loss:0.191 AVG Test Loss:0.202\n",
            "Epoch:793/3000 AVG Training Loss:0.156 AVG Test Loss:0.197\n",
            "Epoch:794/3000 AVG Training Loss:0.210 AVG Test Loss:0.262\n",
            "Epoch:795/3000 AVG Training Loss:0.217 AVG Test Loss:0.226\n",
            "Epoch:796/3000 AVG Training Loss:0.149 AVG Test Loss:0.224\n",
            "Epoch:797/3000 AVG Training Loss:0.177 AVG Test Loss:0.198\n",
            "Epoch:798/3000 AVG Training Loss:0.138 AVG Test Loss:0.143\n",
            "Epoch:799/3000 AVG Training Loss:0.135 AVG Test Loss:0.244\n",
            "Epoch:800/3000 AVG Training Loss:0.140 AVG Test Loss:0.483\n",
            "Epoch:801/3000 AVG Training Loss:0.185 AVG Test Loss:0.133\n",
            "Epoch:802/3000 AVG Training Loss:0.138 AVG Test Loss:0.177\n",
            "Epoch:803/3000 AVG Training Loss:0.195 AVG Test Loss:0.308\n",
            "Epoch:804/3000 AVG Training Loss:0.303 AVG Test Loss:0.117\n",
            "Epoch:805/3000 AVG Training Loss:0.165 AVG Test Loss:0.214\n",
            "Epoch:806/3000 AVG Training Loss:0.144 AVG Test Loss:0.243\n",
            "Epoch:807/3000 AVG Training Loss:0.135 AVG Test Loss:0.123\n",
            "Epoch:808/3000 AVG Training Loss:0.218 AVG Test Loss:0.390\n",
            "Epoch:809/3000 AVG Training Loss:0.156 AVG Test Loss:0.226\n",
            "Epoch:810/3000 AVG Training Loss:0.180 AVG Test Loss:0.128\n",
            "Epoch:811/3000 AVG Training Loss:0.206 AVG Test Loss:0.267\n",
            "Epoch:812/3000 AVG Training Loss:0.152 AVG Test Loss:0.139\n",
            "Epoch:813/3000 AVG Training Loss:0.166 AVG Test Loss:0.245\n",
            "Epoch:814/3000 AVG Training Loss:0.201 AVG Test Loss:0.194\n",
            "Epoch:815/3000 AVG Training Loss:0.165 AVG Test Loss:0.384\n",
            "Epoch:816/3000 AVG Training Loss:0.152 AVG Test Loss:0.441\n",
            "Epoch:817/3000 AVG Training Loss:0.226 AVG Test Loss:0.442\n",
            "Epoch:818/3000 AVG Training Loss:0.113 AVG Test Loss:0.145\n",
            "Epoch:819/3000 AVG Training Loss:0.090 AVG Test Loss:0.150\n",
            "Epoch:820/3000 AVG Training Loss:0.184 AVG Test Loss:0.265\n",
            "Epoch:821/3000 AVG Training Loss:0.120 AVG Test Loss:0.174\n",
            "Epoch:822/3000 AVG Training Loss:0.161 AVG Test Loss:0.073\n",
            "Epoch:823/3000 AVG Training Loss:0.226 AVG Test Loss:0.182\n",
            "Epoch:824/3000 AVG Training Loss:0.156 AVG Test Loss:0.172\n",
            "Epoch:825/3000 AVG Training Loss:0.140 AVG Test Loss:0.218\n",
            "Epoch:826/3000 AVG Training Loss:0.131 AVG Test Loss:0.320\n",
            "Epoch:827/3000 AVG Training Loss:0.243 AVG Test Loss:0.243\n",
            "Epoch:828/3000 AVG Training Loss:0.239 AVG Test Loss:0.271\n",
            "Epoch:829/3000 AVG Training Loss:0.190 AVG Test Loss:0.337\n",
            "Epoch:830/3000 AVG Training Loss:0.223 AVG Test Loss:0.189\n",
            "Epoch:831/3000 AVG Training Loss:0.221 AVG Test Loss:0.227\n",
            "Epoch:832/3000 AVG Training Loss:0.157 AVG Test Loss:0.083\n",
            "Epoch:833/3000 AVG Training Loss:0.282 AVG Test Loss:0.457\n",
            "Epoch:834/3000 AVG Training Loss:0.100 AVG Test Loss:0.166\n",
            "Epoch:835/3000 AVG Training Loss:0.229 AVG Test Loss:0.337\n",
            "Epoch:836/3000 AVG Training Loss:0.095 AVG Test Loss:0.376\n",
            "Epoch:837/3000 AVG Training Loss:0.250 AVG Test Loss:0.243\n",
            "Epoch:838/3000 AVG Training Loss:0.241 AVG Test Loss:0.245\n",
            "Epoch:839/3000 AVG Training Loss:0.131 AVG Test Loss:0.106\n",
            "Epoch:840/3000 AVG Training Loss:0.143 AVG Test Loss:0.344\n",
            "Epoch:841/3000 AVG Training Loss:0.183 AVG Test Loss:0.115\n",
            "Epoch:842/3000 AVG Training Loss:0.113 AVG Test Loss:0.571\n",
            "Epoch:843/3000 AVG Training Loss:0.147 AVG Test Loss:0.111\n",
            "Epoch:844/3000 AVG Training Loss:0.216 AVG Test Loss:0.239\n",
            "Epoch:845/3000 AVG Training Loss:0.095 AVG Test Loss:0.106\n",
            "Epoch:846/3000 AVG Training Loss:0.217 AVG Test Loss:0.167\n",
            "Epoch:847/3000 AVG Training Loss:0.133 AVG Test Loss:0.393\n",
            "Epoch:848/3000 AVG Training Loss:0.176 AVG Test Loss:0.244\n",
            "Epoch:849/3000 AVG Training Loss:0.173 AVG Test Loss:0.209\n",
            "Epoch:850/3000 AVG Training Loss:0.158 AVG Test Loss:0.096\n",
            "Epoch:851/3000 AVG Training Loss:0.137 AVG Test Loss:0.027\n",
            "Epoch:852/3000 AVG Training Loss:0.134 AVG Test Loss:0.321\n",
            "Epoch:853/3000 AVG Training Loss:0.146 AVG Test Loss:0.324\n",
            "Epoch:854/3000 AVG Training Loss:0.107 AVG Test Loss:0.168\n",
            "Epoch:855/3000 AVG Training Loss:0.132 AVG Test Loss:0.088\n",
            "Epoch:856/3000 AVG Training Loss:0.127 AVG Test Loss:0.052\n",
            "Epoch:857/3000 AVG Training Loss:0.163 AVG Test Loss:0.197\n",
            "Epoch:858/3000 AVG Training Loss:0.201 AVG Test Loss:0.208\n",
            "Epoch:859/3000 AVG Training Loss:0.202 AVG Test Loss:0.290\n",
            "Epoch:860/3000 AVG Training Loss:0.140 AVG Test Loss:0.104\n",
            "Epoch:861/3000 AVG Training Loss:0.134 AVG Test Loss:0.118\n",
            "Epoch:862/3000 AVG Training Loss:0.138 AVG Test Loss:0.184\n",
            "Epoch:863/3000 AVG Training Loss:0.162 AVG Test Loss:0.419\n",
            "Epoch:864/3000 AVG Training Loss:0.323 AVG Test Loss:0.220\n",
            "Epoch:865/3000 AVG Training Loss:0.148 AVG Test Loss:0.184\n",
            "Epoch:866/3000 AVG Training Loss:0.236 AVG Test Loss:0.260\n",
            "Epoch:867/3000 AVG Training Loss:0.241 AVG Test Loss:0.153\n",
            "Epoch:868/3000 AVG Training Loss:0.307 AVG Test Loss:0.283\n",
            "Epoch:869/3000 AVG Training Loss:0.135 AVG Test Loss:0.364\n",
            "Epoch:870/3000 AVG Training Loss:0.155 AVG Test Loss:0.260\n",
            "Epoch:871/3000 AVG Training Loss:0.186 AVG Test Loss:0.180\n",
            "Epoch:872/3000 AVG Training Loss:0.214 AVG Test Loss:0.291\n",
            "Epoch:873/3000 AVG Training Loss:0.217 AVG Test Loss:0.329\n",
            "Epoch:874/3000 AVG Training Loss:0.087 AVG Test Loss:0.192\n",
            "Epoch:875/3000 AVG Training Loss:0.124 AVG Test Loss:0.343\n",
            "Epoch:876/3000 AVG Training Loss:0.156 AVG Test Loss:0.183\n",
            "Epoch:877/3000 AVG Training Loss:0.143 AVG Test Loss:0.307\n",
            "Epoch:878/3000 AVG Training Loss:0.176 AVG Test Loss:0.202\n",
            "Epoch:879/3000 AVG Training Loss:0.120 AVG Test Loss:0.318\n",
            "Epoch:880/3000 AVG Training Loss:0.200 AVG Test Loss:0.288\n",
            "Epoch:881/3000 AVG Training Loss:0.202 AVG Test Loss:0.474\n",
            "Epoch:882/3000 AVG Training Loss:0.139 AVG Test Loss:0.083\n",
            "Epoch:883/3000 AVG Training Loss:0.236 AVG Test Loss:0.166\n",
            "Epoch:884/3000 AVG Training Loss:0.132 AVG Test Loss:0.139\n",
            "Epoch:885/3000 AVG Training Loss:0.168 AVG Test Loss:0.136\n",
            "Epoch:886/3000 AVG Training Loss:0.155 AVG Test Loss:0.175\n",
            "Epoch:887/3000 AVG Training Loss:0.156 AVG Test Loss:0.083\n",
            "Epoch:888/3000 AVG Training Loss:0.139 AVG Test Loss:0.231\n",
            "Epoch:889/3000 AVG Training Loss:0.231 AVG Test Loss:0.252\n",
            "Epoch:890/3000 AVG Training Loss:0.086 AVG Test Loss:0.483\n",
            "Epoch:891/3000 AVG Training Loss:0.236 AVG Test Loss:0.254\n",
            "Epoch:892/3000 AVG Training Loss:0.254 AVG Test Loss:0.435\n",
            "Epoch:893/3000 AVG Training Loss:0.193 AVG Test Loss:0.257\n",
            "Epoch:894/3000 AVG Training Loss:0.211 AVG Test Loss:0.276\n",
            "Epoch:895/3000 AVG Training Loss:0.119 AVG Test Loss:0.167\n",
            "Epoch:896/3000 AVG Training Loss:0.146 AVG Test Loss:0.331\n",
            "Epoch:897/3000 AVG Training Loss:0.135 AVG Test Loss:0.110\n",
            "Epoch:898/3000 AVG Training Loss:0.110 AVG Test Loss:0.194\n",
            "Epoch:899/3000 AVG Training Loss:0.245 AVG Test Loss:0.125\n",
            "Epoch:900/3000 AVG Training Loss:0.158 AVG Test Loss:0.129\n",
            "Epoch:901/3000 AVG Training Loss:0.199 AVG Test Loss:0.219\n",
            "Epoch:902/3000 AVG Training Loss:0.129 AVG Test Loss:0.060\n",
            "Epoch:903/3000 AVG Training Loss:0.158 AVG Test Loss:0.285\n",
            "Epoch:904/3000 AVG Training Loss:0.161 AVG Test Loss:0.298\n",
            "Epoch:905/3000 AVG Training Loss:0.207 AVG Test Loss:0.197\n",
            "Epoch:906/3000 AVG Training Loss:0.131 AVG Test Loss:0.041\n",
            "Epoch:907/3000 AVG Training Loss:0.135 AVG Test Loss:0.193\n",
            "Epoch:908/3000 AVG Training Loss:0.263 AVG Test Loss:0.060\n",
            "Epoch:909/3000 AVG Training Loss:0.180 AVG Test Loss:0.087\n",
            "Epoch:910/3000 AVG Training Loss:0.254 AVG Test Loss:0.047\n",
            "Epoch:911/3000 AVG Training Loss:0.202 AVG Test Loss:0.250\n",
            "Epoch:912/3000 AVG Training Loss:0.146 AVG Test Loss:0.219\n",
            "Epoch:913/3000 AVG Training Loss:0.145 AVG Test Loss:0.071\n",
            "Epoch:914/3000 AVG Training Loss:0.154 AVG Test Loss:0.148\n",
            "Epoch:915/3000 AVG Training Loss:0.160 AVG Test Loss:0.096\n",
            "Epoch:916/3000 AVG Training Loss:0.119 AVG Test Loss:0.370\n",
            "Epoch:917/3000 AVG Training Loss:0.141 AVG Test Loss:0.162\n",
            "Epoch:918/3000 AVG Training Loss:0.133 AVG Test Loss:0.374\n",
            "Epoch:919/3000 AVG Training Loss:0.158 AVG Test Loss:0.308\n",
            "Epoch:920/3000 AVG Training Loss:0.143 AVG Test Loss:0.460\n",
            "Epoch:921/3000 AVG Training Loss:0.221 AVG Test Loss:0.240\n",
            "Epoch:922/3000 AVG Training Loss:0.122 AVG Test Loss:0.170\n",
            "Epoch:923/3000 AVG Training Loss:0.153 AVG Test Loss:0.236\n",
            "Epoch:924/3000 AVG Training Loss:0.105 AVG Test Loss:0.077\n",
            "Epoch:925/3000 AVG Training Loss:0.107 AVG Test Loss:0.247\n",
            "Epoch:926/3000 AVG Training Loss:0.202 AVG Test Loss:0.295\n",
            "Epoch:927/3000 AVG Training Loss:0.227 AVG Test Loss:0.102\n",
            "Epoch:928/3000 AVG Training Loss:0.143 AVG Test Loss:0.328\n",
            "Epoch:929/3000 AVG Training Loss:0.088 AVG Test Loss:0.395\n",
            "Epoch:930/3000 AVG Training Loss:0.196 AVG Test Loss:0.175\n",
            "Epoch:931/3000 AVG Training Loss:0.305 AVG Test Loss:0.026\n",
            "Epoch:932/3000 AVG Training Loss:0.121 AVG Test Loss:0.144\n",
            "Epoch:933/3000 AVG Training Loss:0.179 AVG Test Loss:0.249\n",
            "Epoch:934/3000 AVG Training Loss:0.150 AVG Test Loss:0.180\n",
            "Epoch:935/3000 AVG Training Loss:0.183 AVG Test Loss:0.330\n",
            "Epoch:936/3000 AVG Training Loss:0.152 AVG Test Loss:0.306\n",
            "Epoch:937/3000 AVG Training Loss:0.091 AVG Test Loss:0.364\n",
            "Epoch:938/3000 AVG Training Loss:0.128 AVG Test Loss:0.305\n",
            "Epoch:939/3000 AVG Training Loss:0.235 AVG Test Loss:0.195\n",
            "Epoch:940/3000 AVG Training Loss:0.165 AVG Test Loss:0.212\n",
            "Epoch:941/3000 AVG Training Loss:0.196 AVG Test Loss:0.236\n",
            "Epoch:942/3000 AVG Training Loss:0.131 AVG Test Loss:0.101\n",
            "Epoch:943/3000 AVG Training Loss:0.129 AVG Test Loss:0.162\n",
            "Epoch:944/3000 AVG Training Loss:0.112 AVG Test Loss:0.335\n",
            "Epoch:945/3000 AVG Training Loss:0.160 AVG Test Loss:0.180\n",
            "Epoch:946/3000 AVG Training Loss:0.160 AVG Test Loss:0.067\n",
            "Epoch:947/3000 AVG Training Loss:0.165 AVG Test Loss:0.481\n",
            "Epoch:948/3000 AVG Training Loss:0.111 AVG Test Loss:0.132\n",
            "Epoch:949/3000 AVG Training Loss:0.217 AVG Test Loss:0.088\n",
            "Epoch:950/3000 AVG Training Loss:0.126 AVG Test Loss:0.088\n",
            "Epoch:951/3000 AVG Training Loss:0.287 AVG Test Loss:0.214\n",
            "Epoch:952/3000 AVG Training Loss:0.118 AVG Test Loss:0.118\n",
            "Epoch:953/3000 AVG Training Loss:0.216 AVG Test Loss:0.380\n",
            "Epoch:954/3000 AVG Training Loss:0.212 AVG Test Loss:0.150\n",
            "Epoch:955/3000 AVG Training Loss:0.126 AVG Test Loss:0.305\n",
            "Epoch:956/3000 AVG Training Loss:0.193 AVG Test Loss:0.221\n",
            "Epoch:957/3000 AVG Training Loss:0.167 AVG Test Loss:0.230\n",
            "Epoch:958/3000 AVG Training Loss:0.176 AVG Test Loss:0.415\n",
            "Epoch:959/3000 AVG Training Loss:0.252 AVG Test Loss:0.366\n",
            "Epoch:960/3000 AVG Training Loss:0.185 AVG Test Loss:0.359\n",
            "Epoch:961/3000 AVG Training Loss:0.121 AVG Test Loss:0.303\n",
            "Epoch:962/3000 AVG Training Loss:0.167 AVG Test Loss:0.173\n",
            "Epoch:963/3000 AVG Training Loss:0.150 AVG Test Loss:0.127\n",
            "Epoch:964/3000 AVG Training Loss:0.171 AVG Test Loss:0.174\n",
            "Epoch:965/3000 AVG Training Loss:0.165 AVG Test Loss:0.260\n",
            "Epoch:966/3000 AVG Training Loss:0.167 AVG Test Loss:0.295\n",
            "Epoch:967/3000 AVG Training Loss:0.159 AVG Test Loss:0.309\n",
            "Epoch:968/3000 AVG Training Loss:0.104 AVG Test Loss:0.387\n",
            "Epoch:969/3000 AVG Training Loss:0.129 AVG Test Loss:0.265\n",
            "Epoch:970/3000 AVG Training Loss:0.177 AVG Test Loss:0.023\n",
            "Epoch:971/3000 AVG Training Loss:0.097 AVG Test Loss:0.312\n",
            "Epoch:972/3000 AVG Training Loss:0.158 AVG Test Loss:0.057\n",
            "Epoch:973/3000 AVG Training Loss:0.183 AVG Test Loss:0.139\n",
            "Epoch:974/3000 AVG Training Loss:0.151 AVG Test Loss:0.199\n",
            "Epoch:975/3000 AVG Training Loss:0.143 AVG Test Loss:0.242\n",
            "Epoch:976/3000 AVG Training Loss:0.160 AVG Test Loss:0.281\n",
            "Epoch:977/3000 AVG Training Loss:0.167 AVG Test Loss:0.248\n",
            "Epoch:978/3000 AVG Training Loss:0.113 AVG Test Loss:0.041\n",
            "Epoch:979/3000 AVG Training Loss:0.114 AVG Test Loss:0.232\n",
            "Epoch:980/3000 AVG Training Loss:0.149 AVG Test Loss:0.234\n",
            "Epoch:981/3000 AVG Training Loss:0.118 AVG Test Loss:0.170\n",
            "Epoch:982/3000 AVG Training Loss:0.141 AVG Test Loss:0.165\n",
            "Epoch:983/3000 AVG Training Loss:0.113 AVG Test Loss:0.025\n",
            "Epoch:984/3000 AVG Training Loss:0.129 AVG Test Loss:0.493\n",
            "Epoch:985/3000 AVG Training Loss:0.132 AVG Test Loss:0.120\n",
            "Epoch:986/3000 AVG Training Loss:0.201 AVG Test Loss:0.181\n",
            "Epoch:987/3000 AVG Training Loss:0.090 AVG Test Loss:0.161\n",
            "Epoch:988/3000 AVG Training Loss:0.153 AVG Test Loss:0.413\n",
            "Epoch:989/3000 AVG Training Loss:0.143 AVG Test Loss:0.165\n",
            "Epoch:990/3000 AVG Training Loss:0.146 AVG Test Loss:0.065\n",
            "Epoch:991/3000 AVG Training Loss:0.146 AVG Test Loss:0.092\n",
            "Epoch:992/3000 AVG Training Loss:0.172 AVG Test Loss:0.128\n",
            "Epoch:993/3000 AVG Training Loss:0.179 AVG Test Loss:0.155\n",
            "Epoch:994/3000 AVG Training Loss:0.184 AVG Test Loss:0.290\n",
            "Epoch:995/3000 AVG Training Loss:0.193 AVG Test Loss:0.209\n",
            "Epoch:996/3000 AVG Training Loss:0.244 AVG Test Loss:0.170\n",
            "Epoch:997/3000 AVG Training Loss:0.151 AVG Test Loss:0.095\n",
            "Epoch:998/3000 AVG Training Loss:0.121 AVG Test Loss:0.080\n",
            "Epoch:999/3000 AVG Training Loss:0.159 AVG Test Loss:0.352\n",
            "Epoch:1000/3000 AVG Training Loss:0.189 AVG Test Loss:0.276\n",
            "Epoch:1001/3000 AVG Training Loss:0.118 AVG Test Loss:0.359\n",
            "Epoch:1002/3000 AVG Training Loss:0.142 AVG Test Loss:0.373\n",
            "Epoch:1003/3000 AVG Training Loss:0.237 AVG Test Loss:0.078\n",
            "Epoch:1004/3000 AVG Training Loss:0.158 AVG Test Loss:0.386\n",
            "Epoch:1005/3000 AVG Training Loss:0.191 AVG Test Loss:0.120\n",
            "Epoch:1006/3000 AVG Training Loss:0.187 AVG Test Loss:0.090\n",
            "Epoch:1007/3000 AVG Training Loss:0.108 AVG Test Loss:0.216\n",
            "Epoch:1008/3000 AVG Training Loss:0.116 AVG Test Loss:0.265\n",
            "Epoch:1009/3000 AVG Training Loss:0.132 AVG Test Loss:0.184\n",
            "Epoch:1010/3000 AVG Training Loss:0.136 AVG Test Loss:0.311\n",
            "Epoch:1011/3000 AVG Training Loss:0.138 AVG Test Loss:0.345\n",
            "Epoch:1012/3000 AVG Training Loss:0.203 AVG Test Loss:0.060\n",
            "Epoch:1013/3000 AVG Training Loss:0.179 AVG Test Loss:0.273\n",
            "Epoch:1014/3000 AVG Training Loss:0.160 AVG Test Loss:0.208\n",
            "Epoch:1015/3000 AVG Training Loss:0.155 AVG Test Loss:0.330\n",
            "Epoch:1016/3000 AVG Training Loss:0.168 AVG Test Loss:0.280\n",
            "Epoch:1017/3000 AVG Training Loss:0.156 AVG Test Loss:0.527\n",
            "Epoch:1018/3000 AVG Training Loss:0.208 AVG Test Loss:0.078\n",
            "Epoch:1019/3000 AVG Training Loss:0.104 AVG Test Loss:0.231\n",
            "Epoch:1020/3000 AVG Training Loss:0.154 AVG Test Loss:0.256\n",
            "Epoch:1021/3000 AVG Training Loss:0.129 AVG Test Loss:0.180\n",
            "Epoch:1022/3000 AVG Training Loss:0.221 AVG Test Loss:0.277\n",
            "Epoch:1023/3000 AVG Training Loss:0.172 AVG Test Loss:0.278\n",
            "Epoch:1024/3000 AVG Training Loss:0.126 AVG Test Loss:0.099\n",
            "Epoch:1025/3000 AVG Training Loss:0.177 AVG Test Loss:0.418\n",
            "Epoch:1026/3000 AVG Training Loss:0.200 AVG Test Loss:0.112\n",
            "Epoch:1027/3000 AVG Training Loss:0.164 AVG Test Loss:0.304\n",
            "Epoch:1028/3000 AVG Training Loss:0.147 AVG Test Loss:0.313\n",
            "Epoch:1029/3000 AVG Training Loss:0.090 AVG Test Loss:0.364\n",
            "Epoch:1030/3000 AVG Training Loss:0.132 AVG Test Loss:0.236\n",
            "Epoch:1031/3000 AVG Training Loss:0.113 AVG Test Loss:0.151\n",
            "Epoch:1032/3000 AVG Training Loss:0.123 AVG Test Loss:0.201\n",
            "Epoch:1033/3000 AVG Training Loss:0.112 AVG Test Loss:0.106\n",
            "Epoch:1034/3000 AVG Training Loss:0.080 AVG Test Loss:0.178\n",
            "Epoch:1035/3000 AVG Training Loss:0.201 AVG Test Loss:0.275\n",
            "Epoch:1036/3000 AVG Training Loss:0.186 AVG Test Loss:0.390\n",
            "Epoch:1037/3000 AVG Training Loss:0.131 AVG Test Loss:0.357\n",
            "Epoch:1038/3000 AVG Training Loss:0.158 AVG Test Loss:0.087\n",
            "Epoch:1039/3000 AVG Training Loss:0.148 AVG Test Loss:0.131\n",
            "Epoch:1040/3000 AVG Training Loss:0.160 AVG Test Loss:0.167\n",
            "Epoch:1041/3000 AVG Training Loss:0.199 AVG Test Loss:0.162\n",
            "Epoch:1042/3000 AVG Training Loss:0.157 AVG Test Loss:0.162\n",
            "Epoch:1043/3000 AVG Training Loss:0.159 AVG Test Loss:0.120\n",
            "Epoch:1044/3000 AVG Training Loss:0.222 AVG Test Loss:0.152\n",
            "Epoch:1045/3000 AVG Training Loss:0.164 AVG Test Loss:0.194\n",
            "Epoch:1046/3000 AVG Training Loss:0.200 AVG Test Loss:0.262\n",
            "Epoch:1047/3000 AVG Training Loss:0.149 AVG Test Loss:0.205\n",
            "Epoch:1048/3000 AVG Training Loss:0.165 AVG Test Loss:0.194\n",
            "Epoch:1049/3000 AVG Training Loss:0.196 AVG Test Loss:0.223\n",
            "Epoch:1050/3000 AVG Training Loss:0.110 AVG Test Loss:0.030\n",
            "Epoch:1051/3000 AVG Training Loss:0.193 AVG Test Loss:0.189\n",
            "Epoch:1052/3000 AVG Training Loss:0.239 AVG Test Loss:0.197\n",
            "Epoch:1053/3000 AVG Training Loss:0.180 AVG Test Loss:0.154\n",
            "Epoch:1054/3000 AVG Training Loss:0.179 AVG Test Loss:0.276\n",
            "Epoch:1055/3000 AVG Training Loss:0.195 AVG Test Loss:0.213\n",
            "Epoch:1056/3000 AVG Training Loss:0.149 AVG Test Loss:0.291\n",
            "Epoch:1057/3000 AVG Training Loss:0.134 AVG Test Loss:0.261\n",
            "Epoch:1058/3000 AVG Training Loss:0.098 AVG Test Loss:0.454\n",
            "Epoch:1059/3000 AVG Training Loss:0.129 AVG Test Loss:0.245\n",
            "Epoch:1060/3000 AVG Training Loss:0.149 AVG Test Loss:0.130\n",
            "Epoch:1061/3000 AVG Training Loss:0.155 AVG Test Loss:0.152\n",
            "Epoch:1062/3000 AVG Training Loss:0.194 AVG Test Loss:0.364\n",
            "Epoch:1063/3000 AVG Training Loss:0.123 AVG Test Loss:0.347\n",
            "Epoch:1064/3000 AVG Training Loss:0.221 AVG Test Loss:0.147\n",
            "Epoch:1065/3000 AVG Training Loss:0.161 AVG Test Loss:0.162\n",
            "Epoch:1066/3000 AVG Training Loss:0.146 AVG Test Loss:0.259\n",
            "Epoch:1067/3000 AVG Training Loss:0.059 AVG Test Loss:0.633\n",
            "Epoch:1068/3000 AVG Training Loss:0.114 AVG Test Loss:0.200\n",
            "Epoch:1069/3000 AVG Training Loss:0.148 AVG Test Loss:0.043\n",
            "Epoch:1070/3000 AVG Training Loss:0.150 AVG Test Loss:0.284\n",
            "Epoch:1071/3000 AVG Training Loss:0.114 AVG Test Loss:0.153\n",
            "Epoch:1072/3000 AVG Training Loss:0.121 AVG Test Loss:0.164\n",
            "Epoch:1073/3000 AVG Training Loss:0.153 AVG Test Loss:0.242\n",
            "Epoch:1074/3000 AVG Training Loss:0.137 AVG Test Loss:0.241\n",
            "Epoch:1075/3000 AVG Training Loss:0.116 AVG Test Loss:0.133\n",
            "Epoch:1076/3000 AVG Training Loss:0.208 AVG Test Loss:0.191\n",
            "Epoch:1077/3000 AVG Training Loss:0.195 AVG Test Loss:0.323\n",
            "Epoch:1078/3000 AVG Training Loss:0.287 AVG Test Loss:0.172\n",
            "Epoch:1079/3000 AVG Training Loss:0.109 AVG Test Loss:0.128\n",
            "Epoch:1080/3000 AVG Training Loss:0.180 AVG Test Loss:0.139\n",
            "Epoch:1081/3000 AVG Training Loss:0.118 AVG Test Loss:0.197\n",
            "Epoch:1082/3000 AVG Training Loss:0.151 AVG Test Loss:0.208\n",
            "Epoch:1083/3000 AVG Training Loss:0.152 AVG Test Loss:0.069\n",
            "Epoch:1084/3000 AVG Training Loss:0.110 AVG Test Loss:0.158\n",
            "Epoch:1085/3000 AVG Training Loss:0.078 AVG Test Loss:0.226\n",
            "Epoch:1086/3000 AVG Training Loss:0.116 AVG Test Loss:0.114\n",
            "Epoch:1087/3000 AVG Training Loss:0.145 AVG Test Loss:0.007\n",
            "Epoch:1088/3000 AVG Training Loss:0.157 AVG Test Loss:0.181\n",
            "Epoch:1089/3000 AVG Training Loss:0.133 AVG Test Loss:0.094\n",
            "Epoch:1090/3000 AVG Training Loss:0.167 AVG Test Loss:0.143\n",
            "Epoch:1091/3000 AVG Training Loss:0.179 AVG Test Loss:0.170\n",
            "Epoch:1092/3000 AVG Training Loss:0.255 AVG Test Loss:0.114\n",
            "Epoch:1093/3000 AVG Training Loss:0.152 AVG Test Loss:0.030\n",
            "Epoch:1094/3000 AVG Training Loss:0.159 AVG Test Loss:0.175\n",
            "Epoch:1095/3000 AVG Training Loss:0.205 AVG Test Loss:0.218\n",
            "Epoch:1096/3000 AVG Training Loss:0.193 AVG Test Loss:0.123\n",
            "Epoch:1097/3000 AVG Training Loss:0.098 AVG Test Loss:0.352\n",
            "Epoch:1098/3000 AVG Training Loss:0.126 AVG Test Loss:0.145\n",
            "Epoch:1099/3000 AVG Training Loss:0.286 AVG Test Loss:0.210\n",
            "Epoch:1100/3000 AVG Training Loss:0.181 AVG Test Loss:0.222\n",
            "Epoch:1101/3000 AVG Training Loss:0.140 AVG Test Loss:0.311\n",
            "Epoch:1102/3000 AVG Training Loss:0.205 AVG Test Loss:0.171\n",
            "Epoch:1103/3000 AVG Training Loss:0.142 AVG Test Loss:0.450\n",
            "Epoch:1104/3000 AVG Training Loss:0.164 AVG Test Loss:0.153\n",
            "Epoch:1105/3000 AVG Training Loss:0.084 AVG Test Loss:0.182\n",
            "Epoch:1106/3000 AVG Training Loss:0.119 AVG Test Loss:0.071\n",
            "Epoch:1107/3000 AVG Training Loss:0.094 AVG Test Loss:0.178\n",
            "Epoch:1108/3000 AVG Training Loss:0.093 AVG Test Loss:0.224\n",
            "Epoch:1109/3000 AVG Training Loss:0.167 AVG Test Loss:0.125\n",
            "Epoch:1110/3000 AVG Training Loss:0.142 AVG Test Loss:0.470\n",
            "Epoch:1111/3000 AVG Training Loss:0.167 AVG Test Loss:0.139\n",
            "Epoch:1112/3000 AVG Training Loss:0.096 AVG Test Loss:0.195\n",
            "Epoch:1113/3000 AVG Training Loss:0.102 AVG Test Loss:0.145\n",
            "Epoch:1114/3000 AVG Training Loss:0.210 AVG Test Loss:0.086\n",
            "Epoch:1115/3000 AVG Training Loss:0.165 AVG Test Loss:0.138\n",
            "Epoch:1116/3000 AVG Training Loss:0.102 AVG Test Loss:0.140\n",
            "Epoch:1117/3000 AVG Training Loss:0.120 AVG Test Loss:0.091\n",
            "Epoch:1118/3000 AVG Training Loss:0.125 AVG Test Loss:0.113\n",
            "Epoch:1119/3000 AVG Training Loss:0.227 AVG Test Loss:0.152\n",
            "Epoch:1120/3000 AVG Training Loss:0.082 AVG Test Loss:0.487\n",
            "Epoch:1121/3000 AVG Training Loss:0.197 AVG Test Loss:0.408\n",
            "Epoch:1122/3000 AVG Training Loss:0.162 AVG Test Loss:0.307\n",
            "Epoch:1123/3000 AVG Training Loss:0.152 AVG Test Loss:0.182\n",
            "Epoch:1124/3000 AVG Training Loss:0.209 AVG Test Loss:0.062\n",
            "Epoch:1125/3000 AVG Training Loss:0.204 AVG Test Loss:0.029\n",
            "Epoch:1126/3000 AVG Training Loss:0.223 AVG Test Loss:0.275\n",
            "Epoch:1127/3000 AVG Training Loss:0.264 AVG Test Loss:0.075\n",
            "Epoch:1128/3000 AVG Training Loss:0.135 AVG Test Loss:0.259\n",
            "Epoch:1129/3000 AVG Training Loss:0.179 AVG Test Loss:0.313\n",
            "Epoch:1130/3000 AVG Training Loss:0.188 AVG Test Loss:0.249\n",
            "Epoch:1131/3000 AVG Training Loss:0.108 AVG Test Loss:0.229\n",
            "Epoch:1132/3000 AVG Training Loss:0.147 AVG Test Loss:0.187\n",
            "Epoch:1133/3000 AVG Training Loss:0.221 AVG Test Loss:0.079\n",
            "Epoch:1134/3000 AVG Training Loss:0.114 AVG Test Loss:0.257\n",
            "Epoch:1135/3000 AVG Training Loss:0.136 AVG Test Loss:0.447\n",
            "Epoch:1136/3000 AVG Training Loss:0.149 AVG Test Loss:0.248\n",
            "Epoch:1137/3000 AVG Training Loss:0.164 AVG Test Loss:0.276\n",
            "Epoch:1138/3000 AVG Training Loss:0.109 AVG Test Loss:0.074\n",
            "Epoch:1139/3000 AVG Training Loss:0.176 AVG Test Loss:0.319\n",
            "Epoch:1140/3000 AVG Training Loss:0.068 AVG Test Loss:0.022\n",
            "Epoch:1141/3000 AVG Training Loss:0.167 AVG Test Loss:0.361\n",
            "Epoch:1142/3000 AVG Training Loss:0.112 AVG Test Loss:0.108\n",
            "Epoch:1143/3000 AVG Training Loss:0.136 AVG Test Loss:0.160\n",
            "Epoch:1144/3000 AVG Training Loss:0.151 AVG Test Loss:0.097\n",
            "Epoch:1145/3000 AVG Training Loss:0.149 AVG Test Loss:0.240\n",
            "Epoch:1146/3000 AVG Training Loss:0.214 AVG Test Loss:0.131\n",
            "Epoch:1147/3000 AVG Training Loss:0.225 AVG Test Loss:0.160\n",
            "Epoch:1148/3000 AVG Training Loss:0.123 AVG Test Loss:0.025\n",
            "Epoch:1149/3000 AVG Training Loss:0.187 AVG Test Loss:0.218\n",
            "Epoch:1150/3000 AVG Training Loss:0.143 AVG Test Loss:0.321\n",
            "Epoch:1151/3000 AVG Training Loss:0.155 AVG Test Loss:0.089\n",
            "Epoch:1152/3000 AVG Training Loss:0.101 AVG Test Loss:0.098\n",
            "Epoch:1153/3000 AVG Training Loss:0.148 AVG Test Loss:0.361\n",
            "Epoch:1154/3000 AVG Training Loss:0.117 AVG Test Loss:0.090\n",
            "Epoch:1155/3000 AVG Training Loss:0.110 AVG Test Loss:0.187\n",
            "Epoch:1156/3000 AVG Training Loss:0.119 AVG Test Loss:0.030\n",
            "Epoch:1157/3000 AVG Training Loss:0.227 AVG Test Loss:0.141\n",
            "Epoch:1158/3000 AVG Training Loss:0.090 AVG Test Loss:0.122\n",
            "Epoch:1159/3000 AVG Training Loss:0.107 AVG Test Loss:0.027\n",
            "Epoch:1160/3000 AVG Training Loss:0.110 AVG Test Loss:0.437\n",
            "Epoch:1161/3000 AVG Training Loss:0.119 AVG Test Loss:0.203\n",
            "Epoch:1162/3000 AVG Training Loss:0.165 AVG Test Loss:0.275\n",
            "Epoch:1163/3000 AVG Training Loss:0.129 AVG Test Loss:0.409\n",
            "Epoch:1164/3000 AVG Training Loss:0.164 AVG Test Loss:0.234\n",
            "Epoch:1165/3000 AVG Training Loss:0.153 AVG Test Loss:0.187\n",
            "Epoch:1166/3000 AVG Training Loss:0.192 AVG Test Loss:0.088\n",
            "Epoch:1167/3000 AVG Training Loss:0.242 AVG Test Loss:0.086\n",
            "Epoch:1168/3000 AVG Training Loss:0.121 AVG Test Loss:0.162\n",
            "Epoch:1169/3000 AVG Training Loss:0.136 AVG Test Loss:0.185\n",
            "Epoch:1170/3000 AVG Training Loss:0.146 AVG Test Loss:0.136\n",
            "Epoch:1171/3000 AVG Training Loss:0.148 AVG Test Loss:0.212\n",
            "Epoch:1172/3000 AVG Training Loss:0.213 AVG Test Loss:0.372\n",
            "Epoch:1173/3000 AVG Training Loss:0.114 AVG Test Loss:0.288\n",
            "Epoch:1174/3000 AVG Training Loss:0.106 AVG Test Loss:0.058\n",
            "Epoch:1175/3000 AVG Training Loss:0.133 AVG Test Loss:0.401\n",
            "Epoch:1176/3000 AVG Training Loss:0.141 AVG Test Loss:0.143\n",
            "Epoch:1177/3000 AVG Training Loss:0.159 AVG Test Loss:0.203\n",
            "Epoch:1178/3000 AVG Training Loss:0.110 AVG Test Loss:0.069\n",
            "Epoch:1179/3000 AVG Training Loss:0.102 AVG Test Loss:0.164\n",
            "Epoch:1180/3000 AVG Training Loss:0.161 AVG Test Loss:0.142\n",
            "Epoch:1181/3000 AVG Training Loss:0.088 AVG Test Loss:0.198\n",
            "Epoch:1182/3000 AVG Training Loss:0.151 AVG Test Loss:0.246\n",
            "Epoch:1183/3000 AVG Training Loss:0.145 AVG Test Loss:0.192\n",
            "Epoch:1184/3000 AVG Training Loss:0.132 AVG Test Loss:0.246\n",
            "Epoch:1185/3000 AVG Training Loss:0.224 AVG Test Loss:0.196\n",
            "Epoch:1186/3000 AVG Training Loss:0.159 AVG Test Loss:0.244\n",
            "Epoch:1187/3000 AVG Training Loss:0.134 AVG Test Loss:0.241\n",
            "Epoch:1188/3000 AVG Training Loss:0.238 AVG Test Loss:0.267\n",
            "Epoch:1189/3000 AVG Training Loss:0.176 AVG Test Loss:0.084\n",
            "Epoch:1190/3000 AVG Training Loss:0.092 AVG Test Loss:0.081\n",
            "Epoch:1191/3000 AVG Training Loss:0.131 AVG Test Loss:0.129\n",
            "Epoch:1192/3000 AVG Training Loss:0.114 AVG Test Loss:0.094\n",
            "Epoch:1193/3000 AVG Training Loss:0.204 AVG Test Loss:0.377\n",
            "Epoch:1194/3000 AVG Training Loss:0.118 AVG Test Loss:0.175\n",
            "Epoch:1195/3000 AVG Training Loss:0.117 AVG Test Loss:0.242\n",
            "Epoch:1196/3000 AVG Training Loss:0.091 AVG Test Loss:0.275\n",
            "Epoch:1197/3000 AVG Training Loss:0.167 AVG Test Loss:0.215\n",
            "Epoch:1198/3000 AVG Training Loss:0.144 AVG Test Loss:0.124\n",
            "Epoch:1199/3000 AVG Training Loss:0.138 AVG Test Loss:0.113\n",
            "Epoch:1200/3000 AVG Training Loss:0.120 AVG Test Loss:0.363\n",
            "Epoch:1201/3000 AVG Training Loss:0.191 AVG Test Loss:0.144\n",
            "Epoch:1202/3000 AVG Training Loss:0.147 AVG Test Loss:0.379\n",
            "Epoch:1203/3000 AVG Training Loss:0.141 AVG Test Loss:0.034\n",
            "Epoch:1204/3000 AVG Training Loss:0.166 AVG Test Loss:0.027\n",
            "Epoch:1205/3000 AVG Training Loss:0.076 AVG Test Loss:0.252\n",
            "Epoch:1206/3000 AVG Training Loss:0.112 AVG Test Loss:0.050\n",
            "Epoch:1207/3000 AVG Training Loss:0.121 AVG Test Loss:0.061\n",
            "Epoch:1208/3000 AVG Training Loss:0.140 AVG Test Loss:0.086\n",
            "Epoch:1209/3000 AVG Training Loss:0.101 AVG Test Loss:0.357\n",
            "Epoch:1210/3000 AVG Training Loss:0.077 AVG Test Loss:0.138\n",
            "Epoch:1211/3000 AVG Training Loss:0.156 AVG Test Loss:0.068\n",
            "Epoch:1212/3000 AVG Training Loss:0.133 AVG Test Loss:0.091\n",
            "Epoch:1213/3000 AVG Training Loss:0.159 AVG Test Loss:0.477\n",
            "Epoch:1214/3000 AVG Training Loss:0.253 AVG Test Loss:0.156\n",
            "Epoch:1215/3000 AVG Training Loss:0.104 AVG Test Loss:0.102\n",
            "Epoch:1216/3000 AVG Training Loss:0.114 AVG Test Loss:0.047\n",
            "Epoch:1217/3000 AVG Training Loss:0.102 AVG Test Loss:0.099\n",
            "Epoch:1218/3000 AVG Training Loss:0.133 AVG Test Loss:0.201\n",
            "Epoch:1219/3000 AVG Training Loss:0.122 AVG Test Loss:0.066\n",
            "Epoch:1220/3000 AVG Training Loss:0.129 AVG Test Loss:0.270\n",
            "Epoch:1221/3000 AVG Training Loss:0.196 AVG Test Loss:0.356\n",
            "Epoch:1222/3000 AVG Training Loss:0.135 AVG Test Loss:0.028\n",
            "Epoch:1223/3000 AVG Training Loss:0.136 AVG Test Loss:0.217\n",
            "Epoch:1224/3000 AVG Training Loss:0.166 AVG Test Loss:0.107\n",
            "Epoch:1225/3000 AVG Training Loss:0.125 AVG Test Loss:0.252\n",
            "Epoch:1226/3000 AVG Training Loss:0.096 AVG Test Loss:0.352\n",
            "Epoch:1227/3000 AVG Training Loss:0.119 AVG Test Loss:0.251\n",
            "Epoch:1228/3000 AVG Training Loss:0.152 AVG Test Loss:0.423\n",
            "Epoch:1229/3000 AVG Training Loss:0.152 AVG Test Loss:0.024\n",
            "Epoch:1230/3000 AVG Training Loss:0.144 AVG Test Loss:0.178\n",
            "Epoch:1231/3000 AVG Training Loss:0.132 AVG Test Loss:0.191\n",
            "Epoch:1232/3000 AVG Training Loss:0.108 AVG Test Loss:0.303\n",
            "Epoch:1233/3000 AVG Training Loss:0.169 AVG Test Loss:0.026\n",
            "Epoch:1234/3000 AVG Training Loss:0.174 AVG Test Loss:0.100\n",
            "Epoch:1235/3000 AVG Training Loss:0.219 AVG Test Loss:0.137\n",
            "Epoch:1236/3000 AVG Training Loss:0.078 AVG Test Loss:0.506\n",
            "Epoch:1237/3000 AVG Training Loss:0.193 AVG Test Loss:0.114\n",
            "Epoch:1238/3000 AVG Training Loss:0.134 AVG Test Loss:0.092\n",
            "Epoch:1239/3000 AVG Training Loss:0.124 AVG Test Loss:0.114\n",
            "Epoch:1240/3000 AVG Training Loss:0.222 AVG Test Loss:0.261\n",
            "Epoch:1241/3000 AVG Training Loss:0.078 AVG Test Loss:0.350\n",
            "Epoch:1242/3000 AVG Training Loss:0.121 AVG Test Loss:0.006\n",
            "Epoch:1243/3000 AVG Training Loss:0.113 AVG Test Loss:0.202\n",
            "Epoch:1244/3000 AVG Training Loss:0.161 AVG Test Loss:0.322\n",
            "Epoch:1245/3000 AVG Training Loss:0.146 AVG Test Loss:0.168\n",
            "Epoch:1246/3000 AVG Training Loss:0.187 AVG Test Loss:0.116\n",
            "Epoch:1247/3000 AVG Training Loss:0.132 AVG Test Loss:0.054\n",
            "Epoch:1248/3000 AVG Training Loss:0.235 AVG Test Loss:0.225\n",
            "Epoch:1249/3000 AVG Training Loss:0.102 AVG Test Loss:0.104\n",
            "Epoch:1250/3000 AVG Training Loss:0.291 AVG Test Loss:0.060\n",
            "Epoch:1251/3000 AVG Training Loss:0.113 AVG Test Loss:0.255\n",
            "Epoch:1252/3000 AVG Training Loss:0.111 AVG Test Loss:0.098\n",
            "Epoch:1253/3000 AVG Training Loss:0.106 AVG Test Loss:0.049\n",
            "Epoch:1254/3000 AVG Training Loss:0.112 AVG Test Loss:0.016\n",
            "Epoch:1255/3000 AVG Training Loss:0.168 AVG Test Loss:0.244\n",
            "Epoch:1256/3000 AVG Training Loss:0.124 AVG Test Loss:0.077\n",
            "Epoch:1257/3000 AVG Training Loss:0.146 AVG Test Loss:0.260\n",
            "Epoch:1258/3000 AVG Training Loss:0.144 AVG Test Loss:0.217\n",
            "Epoch:1259/3000 AVG Training Loss:0.123 AVG Test Loss:0.140\n",
            "Epoch:1260/3000 AVG Training Loss:0.173 AVG Test Loss:0.109\n",
            "Epoch:1261/3000 AVG Training Loss:0.170 AVG Test Loss:0.259\n",
            "Epoch:1262/3000 AVG Training Loss:0.102 AVG Test Loss:0.205\n",
            "Epoch:1263/3000 AVG Training Loss:0.133 AVG Test Loss:0.220\n",
            "Epoch:1264/3000 AVG Training Loss:0.110 AVG Test Loss:0.372\n",
            "Epoch:1265/3000 AVG Training Loss:0.138 AVG Test Loss:0.012\n",
            "Epoch:1266/3000 AVG Training Loss:0.138 AVG Test Loss:0.046\n",
            "Epoch:1267/3000 AVG Training Loss:0.160 AVG Test Loss:0.357\n",
            "Epoch:1268/3000 AVG Training Loss:0.113 AVG Test Loss:0.117\n",
            "Epoch:1269/3000 AVG Training Loss:0.140 AVG Test Loss:0.321\n",
            "Epoch:1270/3000 AVG Training Loss:0.107 AVG Test Loss:0.116\n",
            "Epoch:1271/3000 AVG Training Loss:0.114 AVG Test Loss:0.287\n",
            "Epoch:1272/3000 AVG Training Loss:0.134 AVG Test Loss:0.022\n",
            "Epoch:1273/3000 AVG Training Loss:0.180 AVG Test Loss:0.271\n",
            "Epoch:1274/3000 AVG Training Loss:0.155 AVG Test Loss:0.127\n",
            "Epoch:1275/3000 AVG Training Loss:0.255 AVG Test Loss:0.278\n",
            "Epoch:1276/3000 AVG Training Loss:0.064 AVG Test Loss:0.161\n",
            "Epoch:1277/3000 AVG Training Loss:0.082 AVG Test Loss:0.486\n",
            "Epoch:1278/3000 AVG Training Loss:0.096 AVG Test Loss:0.140\n",
            "Epoch:1279/3000 AVG Training Loss:0.088 AVG Test Loss:0.419\n",
            "Epoch:1280/3000 AVG Training Loss:0.123 AVG Test Loss:0.237\n",
            "Epoch:1281/3000 AVG Training Loss:0.229 AVG Test Loss:0.118\n",
            "Epoch:1282/3000 AVG Training Loss:0.265 AVG Test Loss:0.213\n",
            "Epoch:1283/3000 AVG Training Loss:0.221 AVG Test Loss:0.104\n",
            "Epoch:1284/3000 AVG Training Loss:0.082 AVG Test Loss:0.251\n",
            "Epoch:1285/3000 AVG Training Loss:0.222 AVG Test Loss:0.150\n",
            "Epoch:1286/3000 AVG Training Loss:0.163 AVG Test Loss:0.304\n",
            "Epoch:1287/3000 AVG Training Loss:0.134 AVG Test Loss:0.208\n",
            "Epoch:1288/3000 AVG Training Loss:0.206 AVG Test Loss:0.042\n",
            "Epoch:1289/3000 AVG Training Loss:0.173 AVG Test Loss:0.151\n",
            "Epoch:1290/3000 AVG Training Loss:0.137 AVG Test Loss:0.087\n",
            "Epoch:1291/3000 AVG Training Loss:0.082 AVG Test Loss:0.268\n",
            "Epoch:1292/3000 AVG Training Loss:0.124 AVG Test Loss:0.076\n",
            "Epoch:1293/3000 AVG Training Loss:0.116 AVG Test Loss:0.212\n",
            "Epoch:1294/3000 AVG Training Loss:0.115 AVG Test Loss:0.013\n",
            "Epoch:1295/3000 AVG Training Loss:0.164 AVG Test Loss:0.142\n",
            "Epoch:1296/3000 AVG Training Loss:0.103 AVG Test Loss:0.175\n",
            "Epoch:1297/3000 AVG Training Loss:0.063 AVG Test Loss:0.275\n",
            "Epoch:1298/3000 AVG Training Loss:0.100 AVG Test Loss:0.337\n",
            "Epoch:1299/3000 AVG Training Loss:0.162 AVG Test Loss:0.029\n",
            "Epoch:1300/3000 AVG Training Loss:0.163 AVG Test Loss:0.413\n",
            "Epoch:1301/3000 AVG Training Loss:0.112 AVG Test Loss:0.080\n",
            "Epoch:1302/3000 AVG Training Loss:0.122 AVG Test Loss:0.109\n",
            "Epoch:1303/3000 AVG Training Loss:0.123 AVG Test Loss:0.014\n",
            "Epoch:1304/3000 AVG Training Loss:0.107 AVG Test Loss:0.424\n",
            "Epoch:1305/3000 AVG Training Loss:0.087 AVG Test Loss:0.390\n",
            "Epoch:1306/3000 AVG Training Loss:0.150 AVG Test Loss:0.272\n",
            "Epoch:1307/3000 AVG Training Loss:0.233 AVG Test Loss:0.314\n",
            "Epoch:1308/3000 AVG Training Loss:0.212 AVG Test Loss:0.464\n",
            "Epoch:1309/3000 AVG Training Loss:0.114 AVG Test Loss:0.171\n",
            "Epoch:1310/3000 AVG Training Loss:0.188 AVG Test Loss:0.149\n",
            "Epoch:1311/3000 AVG Training Loss:0.124 AVG Test Loss:0.193\n",
            "Epoch:1312/3000 AVG Training Loss:0.247 AVG Test Loss:0.076\n",
            "Epoch:1313/3000 AVG Training Loss:0.153 AVG Test Loss:0.123\n",
            "Epoch:1314/3000 AVG Training Loss:0.227 AVG Test Loss:0.118\n",
            "Epoch:1315/3000 AVG Training Loss:0.179 AVG Test Loss:0.097\n",
            "Epoch:1316/3000 AVG Training Loss:0.138 AVG Test Loss:0.226\n",
            "Epoch:1317/3000 AVG Training Loss:0.177 AVG Test Loss:0.280\n",
            "Epoch:1318/3000 AVG Training Loss:0.120 AVG Test Loss:0.131\n",
            "Epoch:1319/3000 AVG Training Loss:0.160 AVG Test Loss:0.235\n",
            "Epoch:1320/3000 AVG Training Loss:0.089 AVG Test Loss:0.188\n",
            "Epoch:1321/3000 AVG Training Loss:0.173 AVG Test Loss:0.048\n",
            "Epoch:1322/3000 AVG Training Loss:0.170 AVG Test Loss:0.193\n",
            "Epoch:1323/3000 AVG Training Loss:0.094 AVG Test Loss:0.101\n",
            "Epoch:1324/3000 AVG Training Loss:0.100 AVG Test Loss:0.338\n",
            "Epoch:1325/3000 AVG Training Loss:0.088 AVG Test Loss:0.146\n",
            "Epoch:1326/3000 AVG Training Loss:0.124 AVG Test Loss:0.087\n",
            "Epoch:1327/3000 AVG Training Loss:0.128 AVG Test Loss:0.096\n",
            "Epoch:1328/3000 AVG Training Loss:0.100 AVG Test Loss:0.035\n",
            "Epoch:1329/3000 AVG Training Loss:0.128 AVG Test Loss:0.193\n",
            "Epoch:1330/3000 AVG Training Loss:0.136 AVG Test Loss:0.346\n",
            "Epoch:1331/3000 AVG Training Loss:0.054 AVG Test Loss:0.203\n",
            "Epoch:1332/3000 AVG Training Loss:0.130 AVG Test Loss:0.089\n",
            "Epoch:1333/3000 AVG Training Loss:0.148 AVG Test Loss:0.302\n",
            "Epoch:1334/3000 AVG Training Loss:0.097 AVG Test Loss:0.133\n",
            "Epoch:1335/3000 AVG Training Loss:0.134 AVG Test Loss:0.093\n",
            "Epoch:1336/3000 AVG Training Loss:0.201 AVG Test Loss:0.274\n",
            "Epoch:1337/3000 AVG Training Loss:0.125 AVG Test Loss:0.179\n",
            "Epoch:1338/3000 AVG Training Loss:0.135 AVG Test Loss:0.314\n",
            "Epoch:1339/3000 AVG Training Loss:0.182 AVG Test Loss:0.176\n",
            "Epoch:1340/3000 AVG Training Loss:0.219 AVG Test Loss:0.280\n",
            "Epoch:1341/3000 AVG Training Loss:0.116 AVG Test Loss:0.444\n",
            "Epoch:1342/3000 AVG Training Loss:0.340 AVG Test Loss:0.365\n",
            "Epoch:1343/3000 AVG Training Loss:0.206 AVG Test Loss:0.162\n",
            "Epoch:1344/3000 AVG Training Loss:0.181 AVG Test Loss:0.289\n",
            "Epoch:1345/3000 AVG Training Loss:0.105 AVG Test Loss:0.421\n",
            "Epoch:1346/3000 AVG Training Loss:0.131 AVG Test Loss:0.177\n",
            "Epoch:1347/3000 AVG Training Loss:0.127 AVG Test Loss:0.397\n",
            "Epoch:1348/3000 AVG Training Loss:0.159 AVG Test Loss:0.143\n",
            "Epoch:1349/3000 AVG Training Loss:0.096 AVG Test Loss:0.038\n",
            "Epoch:1350/3000 AVG Training Loss:0.098 AVG Test Loss:0.176\n",
            "Epoch:1351/3000 AVG Training Loss:0.162 AVG Test Loss:0.136\n",
            "Epoch:1352/3000 AVG Training Loss:0.157 AVG Test Loss:0.035\n",
            "Epoch:1353/3000 AVG Training Loss:0.086 AVG Test Loss:0.234\n",
            "Epoch:1354/3000 AVG Training Loss:0.083 AVG Test Loss:0.344\n",
            "Epoch:1355/3000 AVG Training Loss:0.068 AVG Test Loss:0.263\n",
            "Epoch:1356/3000 AVG Training Loss:0.090 AVG Test Loss:0.078\n",
            "Epoch:1357/3000 AVG Training Loss:0.193 AVG Test Loss:0.325\n",
            "Epoch:1358/3000 AVG Training Loss:0.103 AVG Test Loss:0.082\n",
            "Epoch:1359/3000 AVG Training Loss:0.196 AVG Test Loss:0.108\n",
            "Epoch:1360/3000 AVG Training Loss:0.113 AVG Test Loss:0.191\n",
            "Epoch:1361/3000 AVG Training Loss:0.111 AVG Test Loss:0.454\n",
            "Epoch:1362/3000 AVG Training Loss:0.115 AVG Test Loss:0.416\n",
            "Epoch:1363/3000 AVG Training Loss:0.163 AVG Test Loss:0.217\n",
            "Epoch:1364/3000 AVG Training Loss:0.208 AVG Test Loss:0.190\n",
            "Epoch:1365/3000 AVG Training Loss:0.185 AVG Test Loss:0.192\n",
            "Epoch:1366/3000 AVG Training Loss:0.164 AVG Test Loss:0.061\n",
            "Epoch:1367/3000 AVG Training Loss:0.096 AVG Test Loss:0.170\n",
            "Epoch:1368/3000 AVG Training Loss:0.106 AVG Test Loss:0.140\n",
            "Epoch:1369/3000 AVG Training Loss:0.083 AVG Test Loss:0.326\n",
            "Epoch:1370/3000 AVG Training Loss:0.113 AVG Test Loss:0.150\n",
            "Epoch:1371/3000 AVG Training Loss:0.167 AVG Test Loss:0.199\n",
            "Epoch:1372/3000 AVG Training Loss:0.098 AVG Test Loss:0.143\n",
            "Epoch:1373/3000 AVG Training Loss:0.167 AVG Test Loss:0.242\n",
            "Epoch:1374/3000 AVG Training Loss:0.185 AVG Test Loss:0.276\n",
            "Epoch:1375/3000 AVG Training Loss:0.122 AVG Test Loss:0.101\n",
            "Epoch:1376/3000 AVG Training Loss:0.136 AVG Test Loss:0.210\n",
            "Epoch:1377/3000 AVG Training Loss:0.153 AVG Test Loss:0.261\n",
            "Epoch:1378/3000 AVG Training Loss:0.138 AVG Test Loss:0.038\n",
            "Epoch:1379/3000 AVG Training Loss:0.135 AVG Test Loss:0.034\n",
            "Epoch:1380/3000 AVG Training Loss:0.090 AVG Test Loss:0.268\n",
            "Epoch:1381/3000 AVG Training Loss:0.183 AVG Test Loss:0.103\n",
            "Epoch:1382/3000 AVG Training Loss:0.156 AVG Test Loss:0.090\n",
            "Epoch:1383/3000 AVG Training Loss:0.186 AVG Test Loss:0.366\n",
            "Epoch:1384/3000 AVG Training Loss:0.186 AVG Test Loss:0.209\n",
            "Epoch:1385/3000 AVG Training Loss:0.247 AVG Test Loss:0.377\n",
            "Epoch:1386/3000 AVG Training Loss:0.187 AVG Test Loss:0.159\n",
            "Epoch:1387/3000 AVG Training Loss:0.124 AVG Test Loss:0.232\n",
            "Epoch:1388/3000 AVG Training Loss:0.139 AVG Test Loss:0.245\n",
            "Epoch:1389/3000 AVG Training Loss:0.106 AVG Test Loss:0.189\n",
            "Epoch:1390/3000 AVG Training Loss:0.115 AVG Test Loss:0.040\n",
            "Epoch:1391/3000 AVG Training Loss:0.105 AVG Test Loss:0.126\n",
            "Epoch:1392/3000 AVG Training Loss:0.131 AVG Test Loss:0.117\n",
            "Epoch:1393/3000 AVG Training Loss:0.088 AVG Test Loss:0.285\n",
            "Epoch:1394/3000 AVG Training Loss:0.100 AVG Test Loss:0.282\n",
            "Epoch:1395/3000 AVG Training Loss:0.171 AVG Test Loss:0.178\n",
            "Epoch:1396/3000 AVG Training Loss:0.172 AVG Test Loss:0.137\n",
            "Epoch:1397/3000 AVG Training Loss:0.092 AVG Test Loss:0.236\n",
            "Epoch:1398/3000 AVG Training Loss:0.171 AVG Test Loss:0.194\n",
            "Epoch:1399/3000 AVG Training Loss:0.222 AVG Test Loss:0.122\n",
            "Epoch:1400/3000 AVG Training Loss:0.234 AVG Test Loss:0.167\n",
            "Epoch:1401/3000 AVG Training Loss:0.146 AVG Test Loss:0.028\n",
            "Epoch:1402/3000 AVG Training Loss:0.138 AVG Test Loss:0.510\n",
            "Epoch:1403/3000 AVG Training Loss:0.159 AVG Test Loss:0.214\n",
            "Epoch:1404/3000 AVG Training Loss:0.117 AVG Test Loss:0.182\n",
            "Epoch:1405/3000 AVG Training Loss:0.102 AVG Test Loss:0.338\n",
            "Epoch:1406/3000 AVG Training Loss:0.208 AVG Test Loss:0.022\n",
            "Epoch:1407/3000 AVG Training Loss:0.171 AVG Test Loss:0.202\n",
            "Epoch:1408/3000 AVG Training Loss:0.163 AVG Test Loss:0.068\n",
            "Epoch:1409/3000 AVG Training Loss:0.161 AVG Test Loss:0.179\n",
            "Epoch:1410/3000 AVG Training Loss:0.134 AVG Test Loss:0.428\n",
            "Epoch:1411/3000 AVG Training Loss:0.176 AVG Test Loss:0.312\n",
            "Epoch:1412/3000 AVG Training Loss:0.173 AVG Test Loss:0.155\n",
            "Epoch:1413/3000 AVG Training Loss:0.153 AVG Test Loss:0.165\n",
            "Epoch:1414/3000 AVG Training Loss:0.148 AVG Test Loss:0.166\n",
            "Epoch:1415/3000 AVG Training Loss:0.106 AVG Test Loss:0.182\n",
            "Epoch:1416/3000 AVG Training Loss:0.140 AVG Test Loss:0.096\n",
            "Epoch:1417/3000 AVG Training Loss:0.094 AVG Test Loss:0.156\n",
            "Epoch:1418/3000 AVG Training Loss:0.112 AVG Test Loss:0.226\n",
            "Epoch:1419/3000 AVG Training Loss:0.109 AVG Test Loss:0.246\n",
            "Epoch:1420/3000 AVG Training Loss:0.138 AVG Test Loss:0.083\n",
            "Epoch:1421/3000 AVG Training Loss:0.219 AVG Test Loss:0.241\n",
            "Epoch:1422/3000 AVG Training Loss:0.122 AVG Test Loss:0.363\n",
            "Epoch:1423/3000 AVG Training Loss:0.145 AVG Test Loss:0.058\n",
            "Epoch:1424/3000 AVG Training Loss:0.104 AVG Test Loss:0.044\n",
            "Epoch:1425/3000 AVG Training Loss:0.129 AVG Test Loss:0.200\n",
            "Epoch:1426/3000 AVG Training Loss:0.224 AVG Test Loss:0.147\n",
            "Epoch:1427/3000 AVG Training Loss:0.091 AVG Test Loss:0.031\n",
            "Epoch:1428/3000 AVG Training Loss:0.198 AVG Test Loss:0.055\n",
            "Epoch:1429/3000 AVG Training Loss:0.079 AVG Test Loss:0.109\n",
            "Epoch:1430/3000 AVG Training Loss:0.120 AVG Test Loss:0.197\n",
            "Epoch:1431/3000 AVG Training Loss:0.083 AVG Test Loss:0.401\n",
            "Epoch:1432/3000 AVG Training Loss:0.085 AVG Test Loss:0.208\n",
            "Epoch:1433/3000 AVG Training Loss:0.143 AVG Test Loss:0.215\n",
            "Epoch:1434/3000 AVG Training Loss:0.199 AVG Test Loss:0.046\n",
            "Epoch:1435/3000 AVG Training Loss:0.140 AVG Test Loss:0.053\n",
            "Epoch:1436/3000 AVG Training Loss:0.115 AVG Test Loss:0.106\n",
            "Epoch:1437/3000 AVG Training Loss:0.111 AVG Test Loss:0.162\n",
            "Epoch:1438/3000 AVG Training Loss:0.117 AVG Test Loss:0.140\n",
            "Epoch:1439/3000 AVG Training Loss:0.134 AVG Test Loss:0.183\n",
            "Epoch:1440/3000 AVG Training Loss:0.157 AVG Test Loss:0.376\n",
            "Epoch:1441/3000 AVG Training Loss:0.147 AVG Test Loss:0.457\n",
            "Epoch:1442/3000 AVG Training Loss:0.266 AVG Test Loss:0.076\n",
            "Epoch:1443/3000 AVG Training Loss:0.081 AVG Test Loss:0.228\n",
            "Epoch:1444/3000 AVG Training Loss:0.112 AVG Test Loss:0.290\n",
            "Epoch:1445/3000 AVG Training Loss:0.154 AVG Test Loss:0.063\n",
            "Epoch:1446/3000 AVG Training Loss:0.110 AVG Test Loss:0.225\n",
            "Epoch:1447/3000 AVG Training Loss:0.112 AVG Test Loss:0.208\n",
            "Epoch:1448/3000 AVG Training Loss:0.123 AVG Test Loss:0.064\n",
            "Epoch:1449/3000 AVG Training Loss:0.127 AVG Test Loss:0.135\n",
            "Epoch:1450/3000 AVG Training Loss:0.147 AVG Test Loss:0.177\n",
            "Epoch:1451/3000 AVG Training Loss:0.113 AVG Test Loss:0.169\n",
            "Epoch:1452/3000 AVG Training Loss:0.080 AVG Test Loss:0.109\n",
            "Epoch:1453/3000 AVG Training Loss:0.157 AVG Test Loss:0.159\n",
            "Epoch:1454/3000 AVG Training Loss:0.158 AVG Test Loss:0.215\n",
            "Epoch:1455/3000 AVG Training Loss:0.136 AVG Test Loss:0.016\n",
            "Epoch:1456/3000 AVG Training Loss:0.093 AVG Test Loss:0.270\n",
            "Epoch:1457/3000 AVG Training Loss:0.173 AVG Test Loss:0.181\n",
            "Epoch:1458/3000 AVG Training Loss:0.169 AVG Test Loss:0.151\n",
            "Epoch:1459/3000 AVG Training Loss:0.083 AVG Test Loss:0.181\n",
            "Epoch:1460/3000 AVG Training Loss:0.097 AVG Test Loss:0.168\n",
            "Epoch:1461/3000 AVG Training Loss:0.109 AVG Test Loss:0.127\n",
            "Epoch:1462/3000 AVG Training Loss:0.121 AVG Test Loss:0.202\n",
            "Epoch:1463/3000 AVG Training Loss:0.116 AVG Test Loss:0.186\n",
            "Epoch:1464/3000 AVG Training Loss:0.068 AVG Test Loss:0.148\n",
            "Epoch:1465/3000 AVG Training Loss:0.064 AVG Test Loss:0.094\n",
            "Epoch:1466/3000 AVG Training Loss:0.138 AVG Test Loss:0.057\n",
            "Epoch:1467/3000 AVG Training Loss:0.146 AVG Test Loss:0.195\n",
            "Epoch:1468/3000 AVG Training Loss:0.100 AVG Test Loss:0.091\n",
            "Epoch:1469/3000 AVG Training Loss:0.108 AVG Test Loss:0.113\n",
            "Epoch:1470/3000 AVG Training Loss:0.112 AVG Test Loss:0.305\n",
            "Epoch:1471/3000 AVG Training Loss:0.196 AVG Test Loss:0.210\n",
            "Epoch:1472/3000 AVG Training Loss:0.118 AVG Test Loss:0.373\n",
            "Epoch:1473/3000 AVG Training Loss:0.131 AVG Test Loss:0.067\n",
            "Epoch:1474/3000 AVG Training Loss:0.082 AVG Test Loss:0.136\n",
            "Epoch:1475/3000 AVG Training Loss:0.093 AVG Test Loss:0.106\n",
            "Epoch:1476/3000 AVG Training Loss:0.079 AVG Test Loss:0.391\n",
            "Epoch:1477/3000 AVG Training Loss:0.143 AVG Test Loss:0.051\n",
            "Epoch:1478/3000 AVG Training Loss:0.144 AVG Test Loss:0.275\n",
            "Epoch:1479/3000 AVG Training Loss:0.085 AVG Test Loss:0.133\n",
            "Epoch:1480/3000 AVG Training Loss:0.105 AVG Test Loss:0.074\n",
            "Epoch:1481/3000 AVG Training Loss:0.122 AVG Test Loss:0.263\n",
            "Epoch:1482/3000 AVG Training Loss:0.141 AVG Test Loss:0.057\n",
            "Epoch:1483/3000 AVG Training Loss:0.075 AVG Test Loss:0.039\n",
            "Epoch:1484/3000 AVG Training Loss:0.153 AVG Test Loss:0.257\n",
            "Epoch:1485/3000 AVG Training Loss:0.087 AVG Test Loss:0.204\n",
            "Epoch:1486/3000 AVG Training Loss:0.181 AVG Test Loss:0.061\n",
            "Epoch:1487/3000 AVG Training Loss:0.292 AVG Test Loss:0.471\n",
            "Epoch:1488/3000 AVG Training Loss:0.150 AVG Test Loss:0.251\n",
            "Epoch:1489/3000 AVG Training Loss:0.093 AVG Test Loss:0.184\n",
            "Epoch:1490/3000 AVG Training Loss:0.196 AVG Test Loss:0.186\n",
            "Epoch:1491/3000 AVG Training Loss:0.117 AVG Test Loss:0.269\n",
            "Epoch:1492/3000 AVG Training Loss:0.148 AVG Test Loss:0.194\n",
            "Epoch:1493/3000 AVG Training Loss:0.172 AVG Test Loss:0.234\n",
            "Epoch:1494/3000 AVG Training Loss:0.147 AVG Test Loss:0.201\n",
            "Epoch:1495/3000 AVG Training Loss:0.126 AVG Test Loss:0.215\n",
            "Epoch:1496/3000 AVG Training Loss:0.109 AVG Test Loss:0.149\n",
            "Epoch:1497/3000 AVG Training Loss:0.186 AVG Test Loss:0.100\n",
            "Epoch:1498/3000 AVG Training Loss:0.167 AVG Test Loss:0.054\n",
            "Epoch:1499/3000 AVG Training Loss:0.158 AVG Test Loss:0.234\n",
            "Epoch:1500/3000 AVG Training Loss:0.181 AVG Test Loss:0.467\n",
            "Epoch:1501/3000 AVG Training Loss:0.121 AVG Test Loss:0.389\n",
            "Epoch:1502/3000 AVG Training Loss:0.197 AVG Test Loss:0.297\n",
            "Epoch:1503/3000 AVG Training Loss:0.103 AVG Test Loss:0.057\n",
            "Epoch:1504/3000 AVG Training Loss:0.114 AVG Test Loss:0.075\n",
            "Epoch:1505/3000 AVG Training Loss:0.145 AVG Test Loss:0.177\n",
            "Epoch:1506/3000 AVG Training Loss:0.156 AVG Test Loss:0.440\n",
            "Epoch:1507/3000 AVG Training Loss:0.145 AVG Test Loss:0.121\n",
            "Epoch:1508/3000 AVG Training Loss:0.177 AVG Test Loss:0.269\n",
            "Epoch:1509/3000 AVG Training Loss:0.211 AVG Test Loss:0.042\n",
            "Epoch:1510/3000 AVG Training Loss:0.130 AVG Test Loss:0.438\n",
            "Epoch:1511/3000 AVG Training Loss:0.386 AVG Test Loss:0.250\n",
            "Epoch:1512/3000 AVG Training Loss:0.088 AVG Test Loss:0.211\n",
            "Epoch:1513/3000 AVG Training Loss:0.135 AVG Test Loss:0.044\n",
            "Epoch:1514/3000 AVG Training Loss:0.207 AVG Test Loss:0.210\n",
            "Epoch:1515/3000 AVG Training Loss:0.180 AVG Test Loss:0.170\n",
            "Epoch:1516/3000 AVG Training Loss:0.142 AVG Test Loss:0.315\n",
            "Epoch:1517/3000 AVG Training Loss:0.152 AVG Test Loss:0.197\n",
            "Epoch:1518/3000 AVG Training Loss:0.100 AVG Test Loss:0.224\n",
            "Epoch:1519/3000 AVG Training Loss:0.122 AVG Test Loss:0.176\n",
            "Epoch:1520/3000 AVG Training Loss:0.186 AVG Test Loss:0.199\n",
            "Epoch:1521/3000 AVG Training Loss:0.128 AVG Test Loss:0.090\n",
            "Epoch:1522/3000 AVG Training Loss:0.112 AVG Test Loss:0.157\n",
            "Epoch:1523/3000 AVG Training Loss:0.174 AVG Test Loss:0.373\n",
            "Epoch:1524/3000 AVG Training Loss:0.108 AVG Test Loss:0.119\n",
            "Epoch:1525/3000 AVG Training Loss:0.185 AVG Test Loss:0.108\n",
            "Epoch:1526/3000 AVG Training Loss:0.144 AVG Test Loss:0.162\n",
            "Epoch:1527/3000 AVG Training Loss:0.097 AVG Test Loss:0.267\n",
            "Epoch:1528/3000 AVG Training Loss:0.074 AVG Test Loss:0.127\n",
            "Epoch:1529/3000 AVG Training Loss:0.149 AVG Test Loss:0.053\n",
            "Epoch:1530/3000 AVG Training Loss:0.172 AVG Test Loss:0.166\n",
            "Epoch:1531/3000 AVG Training Loss:0.133 AVG Test Loss:0.056\n",
            "Epoch:1532/3000 AVG Training Loss:0.102 AVG Test Loss:0.030\n",
            "Epoch:1533/3000 AVG Training Loss:0.079 AVG Test Loss:0.156\n",
            "Epoch:1534/3000 AVG Training Loss:0.128 AVG Test Loss:0.413\n",
            "Epoch:1535/3000 AVG Training Loss:0.081 AVG Test Loss:0.192\n",
            "Epoch:1536/3000 AVG Training Loss:0.115 AVG Test Loss:0.153\n",
            "Epoch:1537/3000 AVG Training Loss:0.133 AVG Test Loss:0.093\n",
            "Epoch:1538/3000 AVG Training Loss:0.082 AVG Test Loss:0.161\n",
            "Epoch:1539/3000 AVG Training Loss:0.092 AVG Test Loss:0.287\n",
            "Epoch:1540/3000 AVG Training Loss:0.184 AVG Test Loss:0.222\n",
            "Epoch:1541/3000 AVG Training Loss:0.136 AVG Test Loss:0.010\n",
            "Epoch:1542/3000 AVG Training Loss:0.070 AVG Test Loss:0.290\n",
            "Epoch:1543/3000 AVG Training Loss:0.181 AVG Test Loss:0.211\n",
            "Epoch:1544/3000 AVG Training Loss:0.154 AVG Test Loss:0.139\n",
            "Epoch:1545/3000 AVG Training Loss:0.133 AVG Test Loss:0.068\n",
            "Epoch:1546/3000 AVG Training Loss:0.089 AVG Test Loss:0.099\n",
            "Epoch:1547/3000 AVG Training Loss:0.179 AVG Test Loss:0.197\n",
            "Epoch:1548/3000 AVG Training Loss:0.249 AVG Test Loss:0.189\n",
            "Epoch:1549/3000 AVG Training Loss:0.117 AVG Test Loss:0.103\n",
            "Epoch:1550/3000 AVG Training Loss:0.098 AVG Test Loss:0.238\n",
            "Epoch:1551/3000 AVG Training Loss:0.159 AVG Test Loss:0.112\n",
            "Epoch:1552/3000 AVG Training Loss:0.146 AVG Test Loss:0.065\n",
            "Epoch:1553/3000 AVG Training Loss:0.099 AVG Test Loss:0.230\n",
            "Epoch:1554/3000 AVG Training Loss:0.125 AVG Test Loss:0.139\n",
            "Epoch:1555/3000 AVG Training Loss:0.091 AVG Test Loss:0.159\n",
            "Epoch:1556/3000 AVG Training Loss:0.087 AVG Test Loss:0.214\n",
            "Epoch:1557/3000 AVG Training Loss:0.060 AVG Test Loss:0.246\n",
            "Epoch:1558/3000 AVG Training Loss:0.166 AVG Test Loss:0.240\n",
            "Epoch:1559/3000 AVG Training Loss:0.158 AVG Test Loss:0.121\n",
            "Epoch:1560/3000 AVG Training Loss:0.096 AVG Test Loss:0.164\n",
            "Epoch:1561/3000 AVG Training Loss:0.176 AVG Test Loss:0.163\n",
            "Epoch:1562/3000 AVG Training Loss:0.163 AVG Test Loss:0.038\n",
            "Epoch:1563/3000 AVG Training Loss:0.065 AVG Test Loss:0.113\n",
            "Epoch:1564/3000 AVG Training Loss:0.179 AVG Test Loss:0.093\n",
            "Epoch:1565/3000 AVG Training Loss:0.094 AVG Test Loss:0.039\n",
            "Epoch:1566/3000 AVG Training Loss:0.209 AVG Test Loss:0.172\n",
            "Epoch:1567/3000 AVG Training Loss:0.089 AVG Test Loss:0.301\n",
            "Epoch:1568/3000 AVG Training Loss:0.127 AVG Test Loss:0.203\n",
            "Epoch:1569/3000 AVG Training Loss:0.160 AVG Test Loss:0.126\n",
            "Epoch:1570/3000 AVG Training Loss:0.139 AVG Test Loss:0.091\n",
            "Epoch:1571/3000 AVG Training Loss:0.060 AVG Test Loss:0.088\n",
            "Epoch:1572/3000 AVG Training Loss:0.130 AVG Test Loss:0.297\n",
            "Epoch:1573/3000 AVG Training Loss:0.181 AVG Test Loss:0.086\n",
            "Epoch:1574/3000 AVG Training Loss:0.122 AVG Test Loss:0.144\n",
            "Epoch:1575/3000 AVG Training Loss:0.144 AVG Test Loss:0.032\n",
            "Epoch:1576/3000 AVG Training Loss:0.118 AVG Test Loss:0.072\n",
            "Epoch:1577/3000 AVG Training Loss:0.194 AVG Test Loss:0.273\n",
            "Epoch:1578/3000 AVG Training Loss:0.122 AVG Test Loss:0.131\n",
            "Epoch:1579/3000 AVG Training Loss:0.124 AVG Test Loss:0.404\n",
            "Epoch:1580/3000 AVG Training Loss:0.074 AVG Test Loss:0.189\n",
            "Epoch:1581/3000 AVG Training Loss:0.103 AVG Test Loss:0.277\n",
            "Epoch:1582/3000 AVG Training Loss:0.107 AVG Test Loss:0.228\n",
            "Epoch:1583/3000 AVG Training Loss:0.076 AVG Test Loss:0.104\n",
            "Epoch:1584/3000 AVG Training Loss:0.152 AVG Test Loss:0.145\n",
            "Epoch:1585/3000 AVG Training Loss:0.133 AVG Test Loss:0.177\n",
            "Epoch:1586/3000 AVG Training Loss:0.129 AVG Test Loss:0.089\n",
            "Epoch:1587/3000 AVG Training Loss:0.116 AVG Test Loss:0.265\n",
            "Epoch:1588/3000 AVG Training Loss:0.105 AVG Test Loss:0.380\n",
            "Epoch:1589/3000 AVG Training Loss:0.198 AVG Test Loss:0.131\n",
            "Epoch:1590/3000 AVG Training Loss:0.156 AVG Test Loss:0.073\n",
            "Epoch:1591/3000 AVG Training Loss:0.118 AVG Test Loss:0.380\n",
            "Epoch:1592/3000 AVG Training Loss:0.108 AVG Test Loss:0.216\n",
            "Epoch:1593/3000 AVG Training Loss:0.175 AVG Test Loss:0.313\n",
            "Epoch:1594/3000 AVG Training Loss:0.116 AVG Test Loss:0.062\n",
            "Epoch:1595/3000 AVG Training Loss:0.094 AVG Test Loss:0.050\n",
            "Epoch:1596/3000 AVG Training Loss:0.053 AVG Test Loss:0.101\n",
            "Epoch:1597/3000 AVG Training Loss:0.099 AVG Test Loss:0.124\n",
            "Epoch:1598/3000 AVG Training Loss:0.134 AVG Test Loss:0.231\n",
            "Epoch:1599/3000 AVG Training Loss:0.073 AVG Test Loss:0.312\n",
            "Epoch:1600/3000 AVG Training Loss:0.122 AVG Test Loss:0.114\n",
            "Epoch:1601/3000 AVG Training Loss:0.176 AVG Test Loss:0.134\n",
            "Epoch:1602/3000 AVG Training Loss:0.108 AVG Test Loss:0.090\n",
            "Epoch:1603/3000 AVG Training Loss:0.082 AVG Test Loss:0.331\n",
            "Epoch:1604/3000 AVG Training Loss:0.173 AVG Test Loss:0.164\n",
            "Epoch:1605/3000 AVG Training Loss:0.087 AVG Test Loss:0.249\n",
            "Epoch:1606/3000 AVG Training Loss:0.137 AVG Test Loss:0.015\n",
            "Epoch:1607/3000 AVG Training Loss:0.189 AVG Test Loss:0.122\n",
            "Epoch:1608/3000 AVG Training Loss:0.142 AVG Test Loss:0.324\n",
            "Epoch:1609/3000 AVG Training Loss:0.247 AVG Test Loss:0.135\n",
            "Epoch:1610/3000 AVG Training Loss:0.140 AVG Test Loss:0.138\n",
            "Epoch:1611/3000 AVG Training Loss:0.089 AVG Test Loss:0.258\n",
            "Epoch:1612/3000 AVG Training Loss:0.115 AVG Test Loss:0.088\n",
            "Epoch:1613/3000 AVG Training Loss:0.147 AVG Test Loss:0.171\n",
            "Epoch:1614/3000 AVG Training Loss:0.138 AVG Test Loss:0.291\n",
            "Epoch:1615/3000 AVG Training Loss:0.083 AVG Test Loss:0.177\n",
            "Epoch:1616/3000 AVG Training Loss:0.133 AVG Test Loss:0.263\n",
            "Epoch:1617/3000 AVG Training Loss:0.113 AVG Test Loss:0.169\n",
            "Epoch:1618/3000 AVG Training Loss:0.099 AVG Test Loss:0.173\n",
            "Epoch:1619/3000 AVG Training Loss:0.064 AVG Test Loss:0.195\n",
            "Epoch:1620/3000 AVG Training Loss:0.151 AVG Test Loss:0.088\n",
            "Epoch:1621/3000 AVG Training Loss:0.154 AVG Test Loss:0.336\n",
            "Epoch:1622/3000 AVG Training Loss:0.115 AVG Test Loss:0.280\n",
            "Epoch:1623/3000 AVG Training Loss:0.104 AVG Test Loss:0.125\n",
            "Epoch:1624/3000 AVG Training Loss:0.082 AVG Test Loss:0.046\n",
            "Epoch:1625/3000 AVG Training Loss:0.062 AVG Test Loss:0.158\n",
            "Epoch:1626/3000 AVG Training Loss:0.178 AVG Test Loss:0.238\n",
            "Epoch:1627/3000 AVG Training Loss:0.106 AVG Test Loss:0.074\n",
            "Epoch:1628/3000 AVG Training Loss:0.142 AVG Test Loss:0.242\n",
            "Epoch:1629/3000 AVG Training Loss:0.122 AVG Test Loss:0.331\n",
            "Epoch:1630/3000 AVG Training Loss:0.193 AVG Test Loss:0.162\n",
            "Epoch:1631/3000 AVG Training Loss:0.159 AVG Test Loss:0.069\n",
            "Epoch:1632/3000 AVG Training Loss:0.070 AVG Test Loss:0.136\n",
            "Epoch:1633/3000 AVG Training Loss:0.081 AVG Test Loss:0.199\n",
            "Epoch:1634/3000 AVG Training Loss:0.192 AVG Test Loss:0.359\n",
            "Epoch:1635/3000 AVG Training Loss:0.089 AVG Test Loss:0.070\n",
            "Epoch:1636/3000 AVG Training Loss:0.097 AVG Test Loss:0.148\n",
            "Epoch:1637/3000 AVG Training Loss:0.139 AVG Test Loss:0.238\n",
            "Epoch:1638/3000 AVG Training Loss:0.096 AVG Test Loss:0.379\n",
            "Epoch:1639/3000 AVG Training Loss:0.129 AVG Test Loss:0.048\n",
            "Epoch:1640/3000 AVG Training Loss:0.153 AVG Test Loss:0.081\n",
            "Epoch:1641/3000 AVG Training Loss:0.103 AVG Test Loss:0.313\n",
            "Epoch:1642/3000 AVG Training Loss:0.090 AVG Test Loss:0.138\n",
            "Epoch:1643/3000 AVG Training Loss:0.142 AVG Test Loss:0.153\n",
            "Epoch:1644/3000 AVG Training Loss:0.117 AVG Test Loss:0.142\n",
            "Epoch:1645/3000 AVG Training Loss:0.099 AVG Test Loss:0.169\n",
            "Epoch:1646/3000 AVG Training Loss:0.090 AVG Test Loss:0.059\n",
            "Epoch:1647/3000 AVG Training Loss:0.136 AVG Test Loss:0.212\n",
            "Epoch:1648/3000 AVG Training Loss:0.074 AVG Test Loss:0.134\n",
            "Epoch:1649/3000 AVG Training Loss:0.081 AVG Test Loss:0.070\n",
            "Epoch:1650/3000 AVG Training Loss:0.133 AVG Test Loss:0.187\n",
            "Epoch:1651/3000 AVG Training Loss:0.123 AVG Test Loss:0.143\n",
            "Epoch:1652/3000 AVG Training Loss:0.106 AVG Test Loss:0.102\n",
            "Epoch:1653/3000 AVG Training Loss:0.126 AVG Test Loss:0.395\n",
            "Epoch:1654/3000 AVG Training Loss:0.177 AVG Test Loss:0.118\n",
            "Epoch:1655/3000 AVG Training Loss:0.200 AVG Test Loss:0.094\n",
            "Epoch:1656/3000 AVG Training Loss:0.148 AVG Test Loss:0.078\n",
            "Epoch:1657/3000 AVG Training Loss:0.150 AVG Test Loss:0.284\n",
            "Epoch:1658/3000 AVG Training Loss:0.105 AVG Test Loss:0.158\n",
            "Epoch:1659/3000 AVG Training Loss:0.192 AVG Test Loss:0.356\n",
            "Epoch:1660/3000 AVG Training Loss:0.189 AVG Test Loss:0.093\n",
            "Epoch:1661/3000 AVG Training Loss:0.096 AVG Test Loss:0.087\n",
            "Epoch:1662/3000 AVG Training Loss:0.252 AVG Test Loss:0.119\n",
            "Epoch:1663/3000 AVG Training Loss:0.236 AVG Test Loss:0.297\n",
            "Epoch:1664/3000 AVG Training Loss:0.141 AVG Test Loss:0.138\n",
            "Epoch:1665/3000 AVG Training Loss:0.203 AVG Test Loss:0.080\n",
            "Epoch:1666/3000 AVG Training Loss:0.058 AVG Test Loss:0.222\n",
            "Epoch:1667/3000 AVG Training Loss:0.093 AVG Test Loss:0.153\n",
            "Epoch:1668/3000 AVG Training Loss:0.256 AVG Test Loss:0.433\n",
            "Epoch:1669/3000 AVG Training Loss:0.124 AVG Test Loss:0.117\n",
            "Epoch:1670/3000 AVG Training Loss:0.067 AVG Test Loss:0.266\n",
            "Epoch:1671/3000 AVG Training Loss:0.185 AVG Test Loss:0.163\n",
            "Epoch:1672/3000 AVG Training Loss:0.102 AVG Test Loss:0.071\n",
            "Epoch:1673/3000 AVG Training Loss:0.093 AVG Test Loss:0.136\n",
            "Epoch:1674/3000 AVG Training Loss:0.148 AVG Test Loss:0.076\n",
            "Epoch:1675/3000 AVG Training Loss:0.111 AVG Test Loss:0.085\n",
            "Epoch:1676/3000 AVG Training Loss:0.141 AVG Test Loss:0.043\n",
            "Epoch:1677/3000 AVG Training Loss:0.173 AVG Test Loss:0.047\n",
            "Epoch:1678/3000 AVG Training Loss:0.072 AVG Test Loss:0.246\n",
            "Epoch:1679/3000 AVG Training Loss:0.160 AVG Test Loss:0.146\n",
            "Epoch:1680/3000 AVG Training Loss:0.254 AVG Test Loss:0.066\n",
            "Epoch:1681/3000 AVG Training Loss:0.089 AVG Test Loss:0.166\n",
            "Epoch:1682/3000 AVG Training Loss:0.078 AVG Test Loss:0.148\n",
            "Epoch:1683/3000 AVG Training Loss:0.096 AVG Test Loss:0.124\n",
            "Epoch:1684/3000 AVG Training Loss:0.133 AVG Test Loss:0.150\n",
            "Epoch:1685/3000 AVG Training Loss:0.089 AVG Test Loss:0.126\n",
            "Epoch:1686/3000 AVG Training Loss:0.103 AVG Test Loss:0.048\n",
            "Epoch:1687/3000 AVG Training Loss:0.149 AVG Test Loss:0.209\n",
            "Epoch:1688/3000 AVG Training Loss:0.117 AVG Test Loss:0.224\n",
            "Epoch:1689/3000 AVG Training Loss:0.156 AVG Test Loss:0.288\n",
            "Epoch:1690/3000 AVG Training Loss:0.152 AVG Test Loss:0.151\n",
            "Epoch:1691/3000 AVG Training Loss:0.080 AVG Test Loss:0.148\n",
            "Epoch:1692/3000 AVG Training Loss:0.110 AVG Test Loss:0.134\n",
            "Epoch:1693/3000 AVG Training Loss:0.125 AVG Test Loss:0.220\n",
            "Epoch:1694/3000 AVG Training Loss:0.066 AVG Test Loss:0.176\n",
            "Epoch:1695/3000 AVG Training Loss:0.183 AVG Test Loss:0.351\n",
            "Epoch:1696/3000 AVG Training Loss:0.141 AVG Test Loss:0.171\n",
            "Epoch:1697/3000 AVG Training Loss:0.114 AVG Test Loss:0.300\n",
            "Epoch:1698/3000 AVG Training Loss:0.062 AVG Test Loss:0.175\n",
            "Epoch:1699/3000 AVG Training Loss:0.181 AVG Test Loss:0.085\n",
            "Epoch:1700/3000 AVG Training Loss:0.136 AVG Test Loss:0.266\n",
            "Epoch:1701/3000 AVG Training Loss:0.144 AVG Test Loss:0.152\n",
            "Epoch:1702/3000 AVG Training Loss:0.194 AVG Test Loss:0.066\n",
            "Epoch:1703/3000 AVG Training Loss:0.146 AVG Test Loss:0.438\n",
            "Epoch:1704/3000 AVG Training Loss:0.196 AVG Test Loss:0.136\n",
            "Epoch:1705/3000 AVG Training Loss:0.129 AVG Test Loss:0.174\n",
            "Epoch:1706/3000 AVG Training Loss:0.190 AVG Test Loss:0.151\n",
            "Epoch:1707/3000 AVG Training Loss:0.175 AVG Test Loss:0.081\n",
            "Epoch:1708/3000 AVG Training Loss:0.125 AVG Test Loss:0.139\n",
            "Epoch:1709/3000 AVG Training Loss:0.143 AVG Test Loss:0.099\n",
            "Epoch:1710/3000 AVG Training Loss:0.110 AVG Test Loss:0.269\n",
            "Epoch:1711/3000 AVG Training Loss:0.098 AVG Test Loss:0.076\n",
            "Epoch:1712/3000 AVG Training Loss:0.098 AVG Test Loss:0.145\n",
            "Epoch:1713/3000 AVG Training Loss:0.107 AVG Test Loss:0.151\n",
            "Epoch:1714/3000 AVG Training Loss:0.260 AVG Test Loss:0.203\n",
            "Epoch:1715/3000 AVG Training Loss:0.101 AVG Test Loss:0.093\n",
            "Epoch:1716/3000 AVG Training Loss:0.109 AVG Test Loss:0.073\n",
            "Epoch:1717/3000 AVG Training Loss:0.171 AVG Test Loss:0.223\n",
            "Epoch:1718/3000 AVG Training Loss:0.185 AVG Test Loss:0.303\n",
            "Epoch:1719/3000 AVG Training Loss:0.201 AVG Test Loss:0.104\n",
            "Epoch:1720/3000 AVG Training Loss:0.132 AVG Test Loss:0.044\n",
            "Epoch:1721/3000 AVG Training Loss:0.134 AVG Test Loss:0.030\n",
            "Epoch:1722/3000 AVG Training Loss:0.240 AVG Test Loss:0.298\n",
            "Epoch:1723/3000 AVG Training Loss:0.163 AVG Test Loss:0.105\n",
            "Epoch:1724/3000 AVG Training Loss:0.091 AVG Test Loss:0.084\n",
            "Epoch:1725/3000 AVG Training Loss:0.167 AVG Test Loss:0.377\n",
            "Epoch:1726/3000 AVG Training Loss:0.120 AVG Test Loss:0.045\n",
            "Epoch:1727/3000 AVG Training Loss:0.143 AVG Test Loss:0.168\n",
            "Epoch:1728/3000 AVG Training Loss:0.082 AVG Test Loss:0.189\n",
            "Epoch:1729/3000 AVG Training Loss:0.072 AVG Test Loss:0.040\n",
            "Epoch:1730/3000 AVG Training Loss:0.135 AVG Test Loss:0.248\n",
            "Epoch:1731/3000 AVG Training Loss:0.098 AVG Test Loss:0.023\n",
            "Epoch:1732/3000 AVG Training Loss:0.080 AVG Test Loss:0.177\n",
            "Epoch:1733/3000 AVG Training Loss:0.169 AVG Test Loss:0.181\n",
            "Epoch:1734/3000 AVG Training Loss:0.097 AVG Test Loss:0.307\n",
            "Epoch:1735/3000 AVG Training Loss:0.120 AVG Test Loss:0.244\n",
            "Epoch:1736/3000 AVG Training Loss:0.057 AVG Test Loss:0.043\n",
            "Epoch:1737/3000 AVG Training Loss:0.177 AVG Test Loss:0.164\n",
            "Epoch:1738/3000 AVG Training Loss:0.184 AVG Test Loss:0.108\n",
            "Epoch:1739/3000 AVG Training Loss:0.197 AVG Test Loss:0.118\n",
            "Epoch:1740/3000 AVG Training Loss:0.071 AVG Test Loss:0.351\n",
            "Epoch:1741/3000 AVG Training Loss:0.095 AVG Test Loss:0.094\n",
            "Epoch:1742/3000 AVG Training Loss:0.101 AVG Test Loss:0.114\n",
            "Epoch:1743/3000 AVG Training Loss:0.128 AVG Test Loss:0.153\n",
            "Epoch:1744/3000 AVG Training Loss:0.062 AVG Test Loss:0.146\n",
            "Epoch:1745/3000 AVG Training Loss:0.066 AVG Test Loss:0.242\n",
            "Epoch:1746/3000 AVG Training Loss:0.109 AVG Test Loss:0.178\n",
            "Epoch:1747/3000 AVG Training Loss:0.139 AVG Test Loss:0.054\n",
            "Epoch:1748/3000 AVG Training Loss:0.159 AVG Test Loss:0.052\n",
            "Epoch:1749/3000 AVG Training Loss:0.130 AVG Test Loss:0.113\n",
            "Epoch:1750/3000 AVG Training Loss:0.140 AVG Test Loss:0.119\n",
            "Epoch:1751/3000 AVG Training Loss:0.137 AVG Test Loss:0.191\n",
            "Epoch:1752/3000 AVG Training Loss:0.144 AVG Test Loss:0.113\n",
            "Epoch:1753/3000 AVG Training Loss:0.098 AVG Test Loss:0.036\n",
            "Epoch:1754/3000 AVG Training Loss:0.112 AVG Test Loss:0.148\n",
            "Epoch:1755/3000 AVG Training Loss:0.138 AVG Test Loss:0.240\n",
            "Epoch:1756/3000 AVG Training Loss:0.056 AVG Test Loss:0.235\n",
            "Epoch:1757/3000 AVG Training Loss:0.085 AVG Test Loss:0.050\n",
            "Epoch:1758/3000 AVG Training Loss:0.105 AVG Test Loss:0.065\n",
            "Epoch:1759/3000 AVG Training Loss:0.181 AVG Test Loss:0.028\n",
            "Epoch:1760/3000 AVG Training Loss:0.146 AVG Test Loss:0.128\n",
            "Epoch:1761/3000 AVG Training Loss:0.057 AVG Test Loss:0.247\n",
            "Epoch:1762/3000 AVG Training Loss:0.098 AVG Test Loss:0.091\n",
            "Epoch:1763/3000 AVG Training Loss:0.093 AVG Test Loss:0.051\n",
            "Epoch:1764/3000 AVG Training Loss:0.192 AVG Test Loss:0.314\n",
            "Epoch:1765/3000 AVG Training Loss:0.084 AVG Test Loss:0.112\n",
            "Epoch:1766/3000 AVG Training Loss:0.089 AVG Test Loss:0.258\n",
            "Epoch:1767/3000 AVG Training Loss:0.103 AVG Test Loss:0.310\n",
            "Epoch:1768/3000 AVG Training Loss:0.116 AVG Test Loss:0.041\n",
            "Epoch:1769/3000 AVG Training Loss:0.094 AVG Test Loss:0.154\n",
            "Epoch:1770/3000 AVG Training Loss:0.140 AVG Test Loss:0.160\n",
            "Epoch:1771/3000 AVG Training Loss:0.067 AVG Test Loss:0.326\n",
            "Epoch:1772/3000 AVG Training Loss:0.148 AVG Test Loss:0.294\n",
            "Epoch:1773/3000 AVG Training Loss:0.089 AVG Test Loss:0.097\n",
            "Epoch:1774/3000 AVG Training Loss:0.144 AVG Test Loss:0.122\n",
            "Epoch:1775/3000 AVG Training Loss:0.090 AVG Test Loss:0.306\n",
            "Epoch:1776/3000 AVG Training Loss:0.189 AVG Test Loss:0.054\n",
            "Epoch:1777/3000 AVG Training Loss:0.109 AVG Test Loss:0.239\n",
            "Epoch:1778/3000 AVG Training Loss:0.146 AVG Test Loss:0.417\n",
            "Epoch:1779/3000 AVG Training Loss:0.120 AVG Test Loss:0.103\n",
            "Epoch:1780/3000 AVG Training Loss:0.113 AVG Test Loss:0.141\n",
            "Epoch:1781/3000 AVG Training Loss:0.119 AVG Test Loss:0.273\n",
            "Epoch:1782/3000 AVG Training Loss:0.072 AVG Test Loss:0.128\n",
            "Epoch:1783/3000 AVG Training Loss:0.150 AVG Test Loss:0.173\n",
            "Epoch:1784/3000 AVG Training Loss:0.102 AVG Test Loss:0.074\n",
            "Epoch:1785/3000 AVG Training Loss:0.121 AVG Test Loss:0.263\n",
            "Epoch:1786/3000 AVG Training Loss:0.100 AVG Test Loss:0.165\n",
            "Epoch:1787/3000 AVG Training Loss:0.137 AVG Test Loss:0.029\n",
            "Epoch:1788/3000 AVG Training Loss:0.101 AVG Test Loss:0.251\n",
            "Epoch:1789/3000 AVG Training Loss:0.192 AVG Test Loss:0.103\n",
            "Epoch:1790/3000 AVG Training Loss:0.095 AVG Test Loss:0.080\n",
            "Epoch:1791/3000 AVG Training Loss:0.187 AVG Test Loss:0.419\n",
            "Epoch:1792/3000 AVG Training Loss:0.140 AVG Test Loss:0.051\n",
            "Epoch:1793/3000 AVG Training Loss:0.085 AVG Test Loss:0.127\n",
            "Epoch:1794/3000 AVG Training Loss:0.116 AVG Test Loss:0.028\n",
            "Epoch:1795/3000 AVG Training Loss:0.136 AVG Test Loss:0.265\n",
            "Epoch:1796/3000 AVG Training Loss:0.175 AVG Test Loss:0.298\n",
            "Epoch:1797/3000 AVG Training Loss:0.122 AVG Test Loss:0.063\n",
            "Epoch:1798/3000 AVG Training Loss:0.067 AVG Test Loss:0.067\n",
            "Epoch:1799/3000 AVG Training Loss:0.119 AVG Test Loss:0.216\n",
            "Epoch:1800/3000 AVG Training Loss:0.123 AVG Test Loss:0.159\n",
            "Epoch:1801/3000 AVG Training Loss:0.130 AVG Test Loss:0.177\n",
            "Epoch:1802/3000 AVG Training Loss:0.123 AVG Test Loss:0.356\n",
            "Epoch:1803/3000 AVG Training Loss:0.085 AVG Test Loss:0.185\n",
            "Epoch:1804/3000 AVG Training Loss:0.114 AVG Test Loss:0.312\n",
            "Epoch:1805/3000 AVG Training Loss:0.141 AVG Test Loss:0.089\n",
            "Epoch:1806/3000 AVG Training Loss:0.101 AVG Test Loss:0.031\n",
            "Epoch:1807/3000 AVG Training Loss:0.105 AVG Test Loss:0.074\n",
            "Epoch:1808/3000 AVG Training Loss:0.136 AVG Test Loss:0.196\n",
            "Epoch:1809/3000 AVG Training Loss:0.116 AVG Test Loss:0.177\n",
            "Epoch:1810/3000 AVG Training Loss:0.065 AVG Test Loss:0.157\n",
            "Epoch:1811/3000 AVG Training Loss:0.131 AVG Test Loss:0.149\n",
            "Epoch:1812/3000 AVG Training Loss:0.104 AVG Test Loss:0.208\n",
            "Epoch:1813/3000 AVG Training Loss:0.115 AVG Test Loss:0.008\n",
            "Epoch:1814/3000 AVG Training Loss:0.104 AVG Test Loss:0.343\n",
            "Epoch:1815/3000 AVG Training Loss:0.120 AVG Test Loss:0.148\n",
            "Epoch:1816/3000 AVG Training Loss:0.139 AVG Test Loss:0.127\n",
            "Epoch:1817/3000 AVG Training Loss:0.102 AVG Test Loss:0.138\n",
            "Epoch:1818/3000 AVG Training Loss:0.130 AVG Test Loss:0.037\n",
            "Epoch:1819/3000 AVG Training Loss:0.065 AVG Test Loss:0.040\n",
            "Epoch:1820/3000 AVG Training Loss:0.188 AVG Test Loss:0.091\n",
            "Epoch:1821/3000 AVG Training Loss:0.121 AVG Test Loss:0.100\n",
            "Epoch:1822/3000 AVG Training Loss:0.198 AVG Test Loss:0.063\n",
            "Epoch:1823/3000 AVG Training Loss:0.149 AVG Test Loss:0.053\n",
            "Epoch:1824/3000 AVG Training Loss:0.122 AVG Test Loss:0.178\n",
            "Epoch:1825/3000 AVG Training Loss:0.087 AVG Test Loss:0.133\n",
            "Epoch:1826/3000 AVG Training Loss:0.169 AVG Test Loss:0.309\n",
            "Epoch:1827/3000 AVG Training Loss:0.142 AVG Test Loss:0.172\n",
            "Epoch:1828/3000 AVG Training Loss:0.081 AVG Test Loss:0.168\n",
            "Epoch:1829/3000 AVG Training Loss:0.080 AVG Test Loss:0.063\n",
            "Epoch:1830/3000 AVG Training Loss:0.089 AVG Test Loss:0.251\n",
            "Epoch:1831/3000 AVG Training Loss:0.120 AVG Test Loss:0.179\n",
            "Epoch:1832/3000 AVG Training Loss:0.183 AVG Test Loss:0.174\n",
            "Epoch:1833/3000 AVG Training Loss:0.131 AVG Test Loss:0.242\n",
            "Epoch:1834/3000 AVG Training Loss:0.153 AVG Test Loss:0.008\n",
            "Epoch:1835/3000 AVG Training Loss:0.067 AVG Test Loss:0.089\n",
            "Epoch:1836/3000 AVG Training Loss:0.188 AVG Test Loss:0.107\n",
            "Epoch:1837/3000 AVG Training Loss:0.105 AVG Test Loss:0.142\n",
            "Epoch:1838/3000 AVG Training Loss:0.170 AVG Test Loss:0.183\n",
            "Epoch:1839/3000 AVG Training Loss:0.050 AVG Test Loss:0.255\n",
            "Epoch:1840/3000 AVG Training Loss:0.081 AVG Test Loss:0.211\n",
            "Epoch:1841/3000 AVG Training Loss:0.086 AVG Test Loss:0.168\n",
            "Epoch:1842/3000 AVG Training Loss:0.136 AVG Test Loss:0.051\n",
            "Epoch:1843/3000 AVG Training Loss:0.118 AVG Test Loss:0.026\n",
            "Epoch:1844/3000 AVG Training Loss:0.080 AVG Test Loss:0.064\n",
            "Epoch:1845/3000 AVG Training Loss:0.093 AVG Test Loss:0.057\n",
            "Epoch:1846/3000 AVG Training Loss:0.064 AVG Test Loss:0.076\n",
            "Epoch:1847/3000 AVG Training Loss:0.089 AVG Test Loss:0.342\n",
            "Epoch:1848/3000 AVG Training Loss:0.094 AVG Test Loss:0.337\n",
            "Epoch:1849/3000 AVG Training Loss:0.158 AVG Test Loss:0.203\n",
            "Epoch:1850/3000 AVG Training Loss:0.086 AVG Test Loss:0.137\n",
            "Epoch:1851/3000 AVG Training Loss:0.142 AVG Test Loss:0.057\n",
            "Epoch:1852/3000 AVG Training Loss:0.117 AVG Test Loss:0.087\n",
            "Epoch:1853/3000 AVG Training Loss:0.179 AVG Test Loss:0.056\n",
            "Epoch:1854/3000 AVG Training Loss:0.084 AVG Test Loss:0.095\n",
            "Epoch:1855/3000 AVG Training Loss:0.191 AVG Test Loss:0.283\n",
            "Epoch:1856/3000 AVG Training Loss:0.234 AVG Test Loss:0.073\n",
            "Epoch:1857/3000 AVG Training Loss:0.138 AVG Test Loss:0.170\n",
            "Epoch:1858/3000 AVG Training Loss:0.072 AVG Test Loss:0.177\n",
            "Epoch:1859/3000 AVG Training Loss:0.151 AVG Test Loss:0.073\n",
            "Epoch:1860/3000 AVG Training Loss:0.093 AVG Test Loss:0.261\n",
            "Epoch:1861/3000 AVG Training Loss:0.134 AVG Test Loss:0.169\n",
            "Epoch:1862/3000 AVG Training Loss:0.071 AVG Test Loss:0.061\n",
            "Epoch:1863/3000 AVG Training Loss:0.143 AVG Test Loss:0.116\n",
            "Epoch:1864/3000 AVG Training Loss:0.117 AVG Test Loss:0.191\n",
            "Epoch:1865/3000 AVG Training Loss:0.099 AVG Test Loss:0.216\n",
            "Epoch:1866/3000 AVG Training Loss:0.158 AVG Test Loss:0.045\n",
            "Epoch:1867/3000 AVG Training Loss:0.049 AVG Test Loss:0.145\n",
            "Epoch:1868/3000 AVG Training Loss:0.155 AVG Test Loss:0.064\n",
            "Epoch:1869/3000 AVG Training Loss:0.088 AVG Test Loss:0.141\n",
            "Epoch:1870/3000 AVG Training Loss:0.107 AVG Test Loss:0.059\n",
            "Epoch:1871/3000 AVG Training Loss:0.130 AVG Test Loss:0.290\n",
            "Epoch:1872/3000 AVG Training Loss:0.064 AVG Test Loss:0.238\n",
            "Epoch:1873/3000 AVG Training Loss:0.080 AVG Test Loss:0.072\n",
            "Epoch:1874/3000 AVG Training Loss:0.105 AVG Test Loss:0.087\n",
            "Epoch:1875/3000 AVG Training Loss:0.067 AVG Test Loss:0.032\n",
            "Epoch:1876/3000 AVG Training Loss:0.047 AVG Test Loss:0.319\n",
            "Epoch:1877/3000 AVG Training Loss:0.120 AVG Test Loss:0.484\n",
            "Epoch:1878/3000 AVG Training Loss:0.118 AVG Test Loss:0.079\n",
            "Epoch:1879/3000 AVG Training Loss:0.132 AVG Test Loss:0.156\n",
            "Epoch:1880/3000 AVG Training Loss:0.102 AVG Test Loss:0.346\n",
            "Epoch:1881/3000 AVG Training Loss:0.166 AVG Test Loss:0.028\n",
            "Epoch:1882/3000 AVG Training Loss:0.221 AVG Test Loss:0.081\n",
            "Epoch:1883/3000 AVG Training Loss:0.108 AVG Test Loss:0.206\n",
            "Epoch:1884/3000 AVG Training Loss:0.173 AVG Test Loss:0.195\n",
            "Epoch:1885/3000 AVG Training Loss:0.086 AVG Test Loss:0.060\n",
            "Epoch:1886/3000 AVG Training Loss:0.140 AVG Test Loss:0.077\n",
            "Epoch:1887/3000 AVG Training Loss:0.095 AVG Test Loss:0.156\n",
            "Epoch:1888/3000 AVG Training Loss:0.067 AVG Test Loss:0.135\n",
            "Epoch:1889/3000 AVG Training Loss:0.137 AVG Test Loss:0.137\n",
            "Epoch:1890/3000 AVG Training Loss:0.102 AVG Test Loss:0.220\n",
            "Epoch:1891/3000 AVG Training Loss:0.122 AVG Test Loss:0.191\n",
            "Epoch:1892/3000 AVG Training Loss:0.093 AVG Test Loss:0.285\n",
            "Epoch:1893/3000 AVG Training Loss:0.094 AVG Test Loss:0.245\n",
            "Epoch:1894/3000 AVG Training Loss:0.104 AVG Test Loss:0.100\n",
            "Epoch:1895/3000 AVG Training Loss:0.107 AVG Test Loss:0.112\n",
            "Epoch:1896/3000 AVG Training Loss:0.133 AVG Test Loss:0.186\n",
            "Epoch:1897/3000 AVG Training Loss:0.165 AVG Test Loss:0.184\n",
            "Epoch:1898/3000 AVG Training Loss:0.081 AVG Test Loss:0.069\n",
            "Epoch:1899/3000 AVG Training Loss:0.156 AVG Test Loss:0.142\n",
            "Epoch:1900/3000 AVG Training Loss:0.154 AVG Test Loss:0.082\n",
            "Epoch:1901/3000 AVG Training Loss:0.116 AVG Test Loss:0.254\n",
            "Epoch:1902/3000 AVG Training Loss:0.080 AVG Test Loss:0.357\n",
            "Epoch:1903/3000 AVG Training Loss:0.117 AVG Test Loss:0.056\n",
            "Epoch:1904/3000 AVG Training Loss:0.116 AVG Test Loss:0.027\n",
            "Epoch:1905/3000 AVG Training Loss:0.079 AVG Test Loss:0.091\n",
            "Epoch:1906/3000 AVG Training Loss:0.128 AVG Test Loss:0.039\n",
            "Epoch:1907/3000 AVG Training Loss:0.067 AVG Test Loss:0.226\n",
            "Epoch:1908/3000 AVG Training Loss:0.123 AVG Test Loss:0.018\n",
            "Epoch:1909/3000 AVG Training Loss:0.108 AVG Test Loss:0.207\n",
            "Epoch:1910/3000 AVG Training Loss:0.088 AVG Test Loss:0.166\n",
            "Epoch:1911/3000 AVG Training Loss:0.157 AVG Test Loss:0.037\n",
            "Epoch:1912/3000 AVG Training Loss:0.135 AVG Test Loss:0.034\n",
            "Epoch:1913/3000 AVG Training Loss:0.105 AVG Test Loss:0.304\n",
            "Epoch:1914/3000 AVG Training Loss:0.111 AVG Test Loss:0.302\n",
            "Epoch:1915/3000 AVG Training Loss:0.108 AVG Test Loss:0.119\n",
            "Epoch:1916/3000 AVG Training Loss:0.127 AVG Test Loss:0.185\n",
            "Epoch:1917/3000 AVG Training Loss:0.109 AVG Test Loss:0.188\n",
            "Epoch:1918/3000 AVG Training Loss:0.139 AVG Test Loss:0.079\n",
            "Epoch:1919/3000 AVG Training Loss:0.155 AVG Test Loss:0.054\n",
            "Epoch:1920/3000 AVG Training Loss:0.048 AVG Test Loss:0.167\n",
            "Epoch:1921/3000 AVG Training Loss:0.127 AVG Test Loss:0.343\n",
            "Epoch:1922/3000 AVG Training Loss:0.216 AVG Test Loss:0.124\n",
            "Epoch:1923/3000 AVG Training Loss:0.110 AVG Test Loss:0.070\n",
            "Epoch:1924/3000 AVG Training Loss:0.113 AVG Test Loss:0.176\n",
            "Epoch:1925/3000 AVG Training Loss:0.131 AVG Test Loss:0.487\n",
            "Epoch:1926/3000 AVG Training Loss:0.097 AVG Test Loss:0.126\n",
            "Epoch:1927/3000 AVG Training Loss:0.094 AVG Test Loss:0.121\n",
            "Epoch:1928/3000 AVG Training Loss:0.120 AVG Test Loss:0.168\n",
            "Epoch:1929/3000 AVG Training Loss:0.134 AVG Test Loss:0.042\n",
            "Epoch:1930/3000 AVG Training Loss:0.080 AVG Test Loss:0.085\n",
            "Epoch:1931/3000 AVG Training Loss:0.140 AVG Test Loss:0.224\n",
            "Epoch:1932/3000 AVG Training Loss:0.163 AVG Test Loss:0.185\n",
            "Epoch:1933/3000 AVG Training Loss:0.055 AVG Test Loss:0.149\n",
            "Epoch:1934/3000 AVG Training Loss:0.095 AVG Test Loss:0.129\n",
            "Epoch:1935/3000 AVG Training Loss:0.102 AVG Test Loss:0.202\n",
            "Epoch:1936/3000 AVG Training Loss:0.094 AVG Test Loss:0.186\n",
            "Epoch:1937/3000 AVG Training Loss:0.153 AVG Test Loss:0.195\n",
            "Epoch:1938/3000 AVG Training Loss:0.117 AVG Test Loss:0.193\n",
            "Epoch:1939/3000 AVG Training Loss:0.110 AVG Test Loss:0.091\n",
            "Epoch:1940/3000 AVG Training Loss:0.121 AVG Test Loss:0.088\n",
            "Epoch:1941/3000 AVG Training Loss:0.068 AVG Test Loss:0.213\n",
            "Epoch:1942/3000 AVG Training Loss:0.138 AVG Test Loss:0.076\n",
            "Epoch:1943/3000 AVG Training Loss:0.141 AVG Test Loss:0.196\n",
            "Epoch:1944/3000 AVG Training Loss:0.113 AVG Test Loss:0.157\n",
            "Epoch:1945/3000 AVG Training Loss:0.107 AVG Test Loss:0.111\n",
            "Epoch:1946/3000 AVG Training Loss:0.134 AVG Test Loss:0.080\n",
            "Epoch:1947/3000 AVG Training Loss:0.183 AVG Test Loss:0.081\n",
            "Epoch:1948/3000 AVG Training Loss:0.143 AVG Test Loss:0.211\n",
            "Epoch:1949/3000 AVG Training Loss:0.079 AVG Test Loss:0.130\n",
            "Epoch:1950/3000 AVG Training Loss:0.143 AVG Test Loss:0.045\n",
            "Epoch:1951/3000 AVG Training Loss:0.118 AVG Test Loss:0.184\n",
            "Epoch:1952/3000 AVG Training Loss:0.089 AVG Test Loss:0.232\n",
            "Epoch:1953/3000 AVG Training Loss:0.122 AVG Test Loss:0.076\n",
            "Epoch:1954/3000 AVG Training Loss:0.117 AVG Test Loss:0.262\n",
            "Epoch:1955/3000 AVG Training Loss:0.127 AVG Test Loss:0.137\n",
            "Epoch:1956/3000 AVG Training Loss:0.143 AVG Test Loss:0.210\n",
            "Epoch:1957/3000 AVG Training Loss:0.150 AVG Test Loss:0.316\n",
            "Epoch:1958/3000 AVG Training Loss:0.140 AVG Test Loss:0.037\n",
            "Epoch:1959/3000 AVG Training Loss:0.231 AVG Test Loss:0.149\n",
            "Epoch:1960/3000 AVG Training Loss:0.085 AVG Test Loss:0.315\n",
            "Epoch:1961/3000 AVG Training Loss:0.114 AVG Test Loss:0.293\n",
            "Epoch:1962/3000 AVG Training Loss:0.161 AVG Test Loss:0.106\n",
            "Epoch:1963/3000 AVG Training Loss:0.237 AVG Test Loss:0.147\n",
            "Epoch:1964/3000 AVG Training Loss:0.126 AVG Test Loss:0.449\n",
            "Epoch:1965/3000 AVG Training Loss:0.117 AVG Test Loss:0.121\n",
            "Epoch:1966/3000 AVG Training Loss:0.238 AVG Test Loss:0.339\n",
            "Epoch:1967/3000 AVG Training Loss:0.102 AVG Test Loss:0.234\n",
            "Epoch:1968/3000 AVG Training Loss:0.158 AVG Test Loss:0.039\n",
            "Epoch:1969/3000 AVG Training Loss:0.118 AVG Test Loss:0.274\n",
            "Epoch:1970/3000 AVG Training Loss:0.153 AVG Test Loss:0.204\n",
            "Epoch:1971/3000 AVG Training Loss:0.151 AVG Test Loss:0.160\n",
            "Epoch:1972/3000 AVG Training Loss:0.202 AVG Test Loss:0.034\n",
            "Epoch:1973/3000 AVG Training Loss:0.176 AVG Test Loss:0.127\n",
            "Epoch:1974/3000 AVG Training Loss:0.145 AVG Test Loss:0.301\n",
            "Epoch:1975/3000 AVG Training Loss:0.067 AVG Test Loss:0.203\n",
            "Epoch:1976/3000 AVG Training Loss:0.110 AVG Test Loss:0.165\n",
            "Epoch:1977/3000 AVG Training Loss:0.163 AVG Test Loss:0.296\n",
            "Epoch:1978/3000 AVG Training Loss:0.116 AVG Test Loss:0.150\n",
            "Epoch:1979/3000 AVG Training Loss:0.122 AVG Test Loss:0.235\n",
            "Epoch:1980/3000 AVG Training Loss:0.105 AVG Test Loss:0.085\n",
            "Epoch:1981/3000 AVG Training Loss:0.164 AVG Test Loss:0.256\n",
            "Epoch:1982/3000 AVG Training Loss:0.145 AVG Test Loss:0.174\n",
            "Epoch:1983/3000 AVG Training Loss:0.048 AVG Test Loss:0.153\n",
            "Epoch:1984/3000 AVG Training Loss:0.074 AVG Test Loss:0.181\n",
            "Epoch:1985/3000 AVG Training Loss:0.070 AVG Test Loss:0.195\n",
            "Epoch:1986/3000 AVG Training Loss:0.063 AVG Test Loss:0.122\n",
            "Epoch:1987/3000 AVG Training Loss:0.148 AVG Test Loss:0.388\n",
            "Epoch:1988/3000 AVG Training Loss:0.118 AVG Test Loss:0.041\n",
            "Epoch:1989/3000 AVG Training Loss:0.089 AVG Test Loss:0.063\n",
            "Epoch:1990/3000 AVG Training Loss:0.103 AVG Test Loss:0.055\n",
            "Epoch:1991/3000 AVG Training Loss:0.052 AVG Test Loss:0.067\n",
            "Epoch:1992/3000 AVG Training Loss:0.088 AVG Test Loss:0.121\n",
            "Epoch:1993/3000 AVG Training Loss:0.061 AVG Test Loss:0.212\n",
            "Epoch:1994/3000 AVG Training Loss:0.092 AVG Test Loss:0.377\n",
            "Epoch:1995/3000 AVG Training Loss:0.111 AVG Test Loss:0.241\n",
            "Epoch:1996/3000 AVG Training Loss:0.105 AVG Test Loss:0.155\n",
            "Epoch:1997/3000 AVG Training Loss:0.112 AVG Test Loss:0.150\n",
            "Epoch:1998/3000 AVG Training Loss:0.133 AVG Test Loss:0.157\n",
            "Epoch:1999/3000 AVG Training Loss:0.089 AVG Test Loss:0.180\n",
            "Epoch:2000/3000 AVG Training Loss:0.251 AVG Test Loss:0.031\n",
            "Epoch:2001/3000 AVG Training Loss:0.079 AVG Test Loss:0.080\n",
            "Epoch:2002/3000 AVG Training Loss:0.126 AVG Test Loss:0.240\n",
            "Epoch:2003/3000 AVG Training Loss:0.178 AVG Test Loss:0.263\n",
            "Epoch:2004/3000 AVG Training Loss:0.054 AVG Test Loss:0.072\n",
            "Epoch:2005/3000 AVG Training Loss:0.170 AVG Test Loss:0.166\n",
            "Epoch:2006/3000 AVG Training Loss:0.079 AVG Test Loss:0.150\n",
            "Epoch:2007/3000 AVG Training Loss:0.140 AVG Test Loss:0.271\n",
            "Epoch:2008/3000 AVG Training Loss:0.136 AVG Test Loss:0.235\n",
            "Epoch:2009/3000 AVG Training Loss:0.138 AVG Test Loss:0.204\n",
            "Epoch:2010/3000 AVG Training Loss:0.168 AVG Test Loss:0.141\n",
            "Epoch:2011/3000 AVG Training Loss:0.104 AVG Test Loss:0.110\n",
            "Epoch:2012/3000 AVG Training Loss:0.073 AVG Test Loss:0.115\n",
            "Epoch:2013/3000 AVG Training Loss:0.119 AVG Test Loss:0.106\n",
            "Epoch:2014/3000 AVG Training Loss:0.113 AVG Test Loss:0.198\n",
            "Epoch:2015/3000 AVG Training Loss:0.147 AVG Test Loss:0.241\n",
            "Epoch:2016/3000 AVG Training Loss:0.159 AVG Test Loss:0.176\n",
            "Epoch:2017/3000 AVG Training Loss:0.140 AVG Test Loss:0.151\n",
            "Epoch:2018/3000 AVG Training Loss:0.167 AVG Test Loss:0.187\n",
            "Epoch:2019/3000 AVG Training Loss:0.109 AVG Test Loss:0.228\n",
            "Epoch:2020/3000 AVG Training Loss:0.118 AVG Test Loss:0.226\n",
            "Epoch:2021/3000 AVG Training Loss:0.081 AVG Test Loss:0.119\n",
            "Epoch:2022/3000 AVG Training Loss:0.080 AVG Test Loss:0.111\n",
            "Epoch:2023/3000 AVG Training Loss:0.099 AVG Test Loss:0.202\n",
            "Epoch:2024/3000 AVG Training Loss:0.125 AVG Test Loss:0.313\n",
            "Epoch:2025/3000 AVG Training Loss:0.152 AVG Test Loss:0.167\n",
            "Epoch:2026/3000 AVG Training Loss:0.177 AVG Test Loss:0.318\n",
            "Epoch:2027/3000 AVG Training Loss:0.153 AVG Test Loss:0.100\n",
            "Epoch:2028/3000 AVG Training Loss:0.079 AVG Test Loss:0.045\n",
            "Epoch:2029/3000 AVG Training Loss:0.182 AVG Test Loss:0.074\n",
            "Epoch:2030/3000 AVG Training Loss:0.107 AVG Test Loss:0.248\n",
            "Epoch:2031/3000 AVG Training Loss:0.204 AVG Test Loss:0.218\n",
            "Epoch:2032/3000 AVG Training Loss:0.169 AVG Test Loss:0.419\n",
            "Epoch:2033/3000 AVG Training Loss:0.139 AVG Test Loss:0.241\n",
            "Epoch:2034/3000 AVG Training Loss:0.084 AVG Test Loss:0.183\n",
            "Epoch:2035/3000 AVG Training Loss:0.150 AVG Test Loss:0.145\n",
            "Epoch:2036/3000 AVG Training Loss:0.178 AVG Test Loss:0.383\n",
            "Epoch:2037/3000 AVG Training Loss:0.187 AVG Test Loss:0.174\n",
            "Epoch:2038/3000 AVG Training Loss:0.171 AVG Test Loss:0.322\n",
            "Epoch:2039/3000 AVG Training Loss:0.155 AVG Test Loss:0.148\n",
            "Epoch:2040/3000 AVG Training Loss:0.139 AVG Test Loss:0.211\n",
            "Epoch:2041/3000 AVG Training Loss:0.108 AVG Test Loss:0.194\n",
            "Epoch:2042/3000 AVG Training Loss:0.184 AVG Test Loss:0.373\n",
            "Epoch:2043/3000 AVG Training Loss:0.084 AVG Test Loss:0.024\n",
            "Epoch:2044/3000 AVG Training Loss:0.147 AVG Test Loss:0.152\n",
            "Epoch:2045/3000 AVG Training Loss:0.168 AVG Test Loss:0.259\n",
            "Epoch:2046/3000 AVG Training Loss:0.094 AVG Test Loss:0.205\n",
            "Epoch:2047/3000 AVG Training Loss:0.099 AVG Test Loss:0.155\n",
            "Epoch:2048/3000 AVG Training Loss:0.136 AVG Test Loss:0.290\n",
            "Epoch:2049/3000 AVG Training Loss:0.090 AVG Test Loss:0.150\n",
            "Epoch:2050/3000 AVG Training Loss:0.101 AVG Test Loss:0.171\n",
            "Epoch:2051/3000 AVG Training Loss:0.101 AVG Test Loss:0.096\n",
            "Epoch:2052/3000 AVG Training Loss:0.079 AVG Test Loss:0.201\n",
            "Epoch:2053/3000 AVG Training Loss:0.156 AVG Test Loss:0.094\n",
            "Epoch:2054/3000 AVG Training Loss:0.143 AVG Test Loss:0.054\n",
            "Epoch:2055/3000 AVG Training Loss:0.057 AVG Test Loss:0.307\n",
            "Epoch:2056/3000 AVG Training Loss:0.105 AVG Test Loss:0.144\n",
            "Epoch:2057/3000 AVG Training Loss:0.117 AVG Test Loss:0.210\n",
            "Epoch:2058/3000 AVG Training Loss:0.089 AVG Test Loss:0.223\n",
            "Epoch:2059/3000 AVG Training Loss:0.219 AVG Test Loss:0.112\n",
            "Epoch:2060/3000 AVG Training Loss:0.111 AVG Test Loss:0.269\n",
            "Epoch:2061/3000 AVG Training Loss:0.109 AVG Test Loss:0.310\n",
            "Epoch:2062/3000 AVG Training Loss:0.105 AVG Test Loss:0.112\n",
            "Epoch:2063/3000 AVG Training Loss:0.160 AVG Test Loss:0.372\n",
            "Epoch:2064/3000 AVG Training Loss:0.216 AVG Test Loss:0.030\n",
            "Epoch:2065/3000 AVG Training Loss:0.121 AVG Test Loss:0.198\n",
            "Epoch:2066/3000 AVG Training Loss:0.116 AVG Test Loss:0.074\n",
            "Epoch:2067/3000 AVG Training Loss:0.074 AVG Test Loss:0.177\n",
            "Epoch:2068/3000 AVG Training Loss:0.098 AVG Test Loss:0.142\n",
            "Epoch:2069/3000 AVG Training Loss:0.124 AVG Test Loss:0.112\n",
            "Epoch:2070/3000 AVG Training Loss:0.191 AVG Test Loss:0.021\n",
            "Epoch:2071/3000 AVG Training Loss:0.169 AVG Test Loss:0.145\n",
            "Epoch:2072/3000 AVG Training Loss:0.149 AVG Test Loss:0.134\n",
            "Epoch:2073/3000 AVG Training Loss:0.095 AVG Test Loss:0.078\n",
            "Epoch:2074/3000 AVG Training Loss:0.113 AVG Test Loss:0.193\n",
            "Epoch:2075/3000 AVG Training Loss:0.090 AVG Test Loss:0.159\n",
            "Epoch:2076/3000 AVG Training Loss:0.106 AVG Test Loss:0.134\n",
            "Epoch:2077/3000 AVG Training Loss:0.265 AVG Test Loss:0.254\n",
            "Epoch:2078/3000 AVG Training Loss:0.123 AVG Test Loss:0.074\n",
            "Epoch:2079/3000 AVG Training Loss:0.106 AVG Test Loss:0.086\n",
            "Epoch:2080/3000 AVG Training Loss:0.102 AVG Test Loss:0.055\n",
            "Epoch:2081/3000 AVG Training Loss:0.141 AVG Test Loss:0.440\n",
            "Epoch:2082/3000 AVG Training Loss:0.127 AVG Test Loss:0.156\n",
            "Epoch:2083/3000 AVG Training Loss:0.076 AVG Test Loss:0.058\n",
            "Epoch:2084/3000 AVG Training Loss:0.152 AVG Test Loss:0.134\n",
            "Epoch:2085/3000 AVG Training Loss:0.150 AVG Test Loss:0.229\n",
            "Epoch:2086/3000 AVG Training Loss:0.085 AVG Test Loss:0.238\n",
            "Epoch:2087/3000 AVG Training Loss:0.144 AVG Test Loss:0.036\n",
            "Epoch:2088/3000 AVG Training Loss:0.147 AVG Test Loss:0.193\n",
            "Epoch:2089/3000 AVG Training Loss:0.082 AVG Test Loss:0.051\n",
            "Epoch:2090/3000 AVG Training Loss:0.159 AVG Test Loss:0.383\n",
            "Epoch:2091/3000 AVG Training Loss:0.101 AVG Test Loss:0.203\n",
            "Epoch:2092/3000 AVG Training Loss:0.090 AVG Test Loss:0.040\n",
            "Epoch:2093/3000 AVG Training Loss:0.095 AVG Test Loss:0.314\n",
            "Epoch:2094/3000 AVG Training Loss:0.114 AVG Test Loss:0.056\n",
            "Epoch:2095/3000 AVG Training Loss:0.104 AVG Test Loss:0.084\n",
            "Epoch:2096/3000 AVG Training Loss:0.125 AVG Test Loss:0.139\n",
            "Epoch:2097/3000 AVG Training Loss:0.203 AVG Test Loss:0.077\n",
            "Epoch:2098/3000 AVG Training Loss:0.102 AVG Test Loss:0.218\n",
            "Epoch:2099/3000 AVG Training Loss:0.110 AVG Test Loss:0.297\n",
            "Epoch:2100/3000 AVG Training Loss:0.106 AVG Test Loss:0.222\n",
            "Epoch:2101/3000 AVG Training Loss:0.223 AVG Test Loss:0.204\n",
            "Epoch:2102/3000 AVG Training Loss:0.159 AVG Test Loss:0.333\n",
            "Epoch:2103/3000 AVG Training Loss:0.104 AVG Test Loss:0.186\n",
            "Epoch:2104/3000 AVG Training Loss:0.096 AVG Test Loss:0.118\n",
            "Epoch:2105/3000 AVG Training Loss:0.043 AVG Test Loss:0.030\n",
            "Epoch:2106/3000 AVG Training Loss:0.169 AVG Test Loss:0.064\n",
            "Epoch:2107/3000 AVG Training Loss:0.089 AVG Test Loss:0.355\n",
            "Epoch:2108/3000 AVG Training Loss:0.131 AVG Test Loss:0.252\n",
            "Epoch:2109/3000 AVG Training Loss:0.094 AVG Test Loss:0.018\n",
            "Epoch:2110/3000 AVG Training Loss:0.108 AVG Test Loss:0.037\n",
            "Epoch:2111/3000 AVG Training Loss:0.086 AVG Test Loss:0.183\n",
            "Epoch:2112/3000 AVG Training Loss:0.154 AVG Test Loss:0.144\n",
            "Epoch:2113/3000 AVG Training Loss:0.061 AVG Test Loss:0.071\n",
            "Epoch:2114/3000 AVG Training Loss:0.146 AVG Test Loss:0.138\n",
            "Epoch:2115/3000 AVG Training Loss:0.119 AVG Test Loss:0.260\n",
            "Epoch:2116/3000 AVG Training Loss:0.175 AVG Test Loss:0.176\n",
            "Epoch:2117/3000 AVG Training Loss:0.107 AVG Test Loss:0.048\n",
            "Epoch:2118/3000 AVG Training Loss:0.157 AVG Test Loss:0.137\n",
            "Epoch:2119/3000 AVG Training Loss:0.095 AVG Test Loss:0.177\n",
            "Epoch:2120/3000 AVG Training Loss:0.122 AVG Test Loss:0.128\n",
            "Epoch:2121/3000 AVG Training Loss:0.130 AVG Test Loss:0.307\n",
            "Epoch:2122/3000 AVG Training Loss:0.060 AVG Test Loss:0.360\n",
            "Epoch:2123/3000 AVG Training Loss:0.086 AVG Test Loss:0.078\n",
            "Epoch:2124/3000 AVG Training Loss:0.158 AVG Test Loss:0.150\n",
            "Epoch:2125/3000 AVG Training Loss:0.152 AVG Test Loss:0.128\n",
            "Epoch:2126/3000 AVG Training Loss:0.053 AVG Test Loss:0.287\n",
            "Epoch:2127/3000 AVG Training Loss:0.064 AVG Test Loss:0.224\n",
            "Epoch:2128/3000 AVG Training Loss:0.218 AVG Test Loss:0.034\n",
            "Epoch:2129/3000 AVG Training Loss:0.101 AVG Test Loss:0.016\n",
            "Epoch:2130/3000 AVG Training Loss:0.124 AVG Test Loss:0.029\n",
            "Epoch:2131/3000 AVG Training Loss:0.073 AVG Test Loss:0.477\n",
            "Epoch:2132/3000 AVG Training Loss:0.120 AVG Test Loss:0.288\n",
            "Epoch:2133/3000 AVG Training Loss:0.143 AVG Test Loss:0.315\n",
            "Epoch:2134/3000 AVG Training Loss:0.120 AVG Test Loss:0.044\n",
            "Epoch:2135/3000 AVG Training Loss:0.163 AVG Test Loss:0.370\n",
            "Epoch:2136/3000 AVG Training Loss:0.111 AVG Test Loss:0.041\n",
            "Epoch:2137/3000 AVG Training Loss:0.117 AVG Test Loss:0.200\n",
            "Epoch:2138/3000 AVG Training Loss:0.112 AVG Test Loss:0.137\n",
            "Epoch:2139/3000 AVG Training Loss:0.094 AVG Test Loss:0.052\n",
            "Epoch:2140/3000 AVG Training Loss:0.098 AVG Test Loss:0.127\n",
            "Epoch:2141/3000 AVG Training Loss:0.124 AVG Test Loss:0.168\n",
            "Epoch:2142/3000 AVG Training Loss:0.103 AVG Test Loss:0.129\n",
            "Epoch:2143/3000 AVG Training Loss:0.098 AVG Test Loss:0.476\n",
            "Epoch:2144/3000 AVG Training Loss:0.161 AVG Test Loss:0.075\n",
            "Epoch:2145/3000 AVG Training Loss:0.099 AVG Test Loss:0.247\n",
            "Epoch:2146/3000 AVG Training Loss:0.152 AVG Test Loss:0.422\n",
            "Epoch:2147/3000 AVG Training Loss:0.156 AVG Test Loss:0.076\n",
            "Epoch:2148/3000 AVG Training Loss:0.099 AVG Test Loss:0.230\n",
            "Epoch:2149/3000 AVG Training Loss:0.145 AVG Test Loss:0.017\n",
            "Epoch:2150/3000 AVG Training Loss:0.134 AVG Test Loss:0.025\n",
            "Epoch:2151/3000 AVG Training Loss:0.066 AVG Test Loss:0.091\n",
            "Epoch:2152/3000 AVG Training Loss:0.081 AVG Test Loss:0.096\n",
            "Epoch:2153/3000 AVG Training Loss:0.088 AVG Test Loss:0.314\n",
            "Epoch:2154/3000 AVG Training Loss:0.051 AVG Test Loss:0.184\n",
            "Epoch:2155/3000 AVG Training Loss:0.090 AVG Test Loss:0.209\n",
            "Epoch:2156/3000 AVG Training Loss:0.111 AVG Test Loss:0.137\n",
            "Epoch:2157/3000 AVG Training Loss:0.070 AVG Test Loss:0.175\n",
            "Epoch:2158/3000 AVG Training Loss:0.112 AVG Test Loss:0.025\n",
            "Epoch:2159/3000 AVG Training Loss:0.115 AVG Test Loss:0.164\n",
            "Epoch:2160/3000 AVG Training Loss:0.112 AVG Test Loss:0.319\n",
            "Epoch:2161/3000 AVG Training Loss:0.085 AVG Test Loss:0.040\n",
            "Epoch:2162/3000 AVG Training Loss:0.063 AVG Test Loss:0.089\n",
            "Epoch:2163/3000 AVG Training Loss:0.145 AVG Test Loss:0.186\n",
            "Epoch:2164/3000 AVG Training Loss:0.080 AVG Test Loss:0.032\n",
            "Epoch:2165/3000 AVG Training Loss:0.060 AVG Test Loss:0.190\n",
            "Epoch:2166/3000 AVG Training Loss:0.091 AVG Test Loss:0.185\n",
            "Epoch:2167/3000 AVG Training Loss:0.161 AVG Test Loss:0.077\n",
            "Epoch:2168/3000 AVG Training Loss:0.107 AVG Test Loss:0.091\n",
            "Epoch:2169/3000 AVG Training Loss:0.136 AVG Test Loss:0.117\n",
            "Epoch:2170/3000 AVG Training Loss:0.167 AVG Test Loss:0.185\n",
            "Epoch:2171/3000 AVG Training Loss:0.055 AVG Test Loss:0.076\n",
            "Epoch:2172/3000 AVG Training Loss:0.100 AVG Test Loss:0.141\n",
            "Epoch:2173/3000 AVG Training Loss:0.067 AVG Test Loss:0.096\n",
            "Epoch:2174/3000 AVG Training Loss:0.103 AVG Test Loss:0.522\n",
            "Epoch:2175/3000 AVG Training Loss:0.170 AVG Test Loss:0.162\n",
            "Epoch:2176/3000 AVG Training Loss:0.167 AVG Test Loss:0.066\n",
            "Epoch:2177/3000 AVG Training Loss:0.096 AVG Test Loss:0.101\n",
            "Epoch:2178/3000 AVG Training Loss:0.132 AVG Test Loss:0.171\n",
            "Epoch:2179/3000 AVG Training Loss:0.101 AVG Test Loss:0.142\n",
            "Epoch:2180/3000 AVG Training Loss:0.128 AVG Test Loss:0.068\n",
            "Epoch:2181/3000 AVG Training Loss:0.049 AVG Test Loss:0.290\n",
            "Epoch:2182/3000 AVG Training Loss:0.110 AVG Test Loss:0.135\n",
            "Epoch:2183/3000 AVG Training Loss:0.105 AVG Test Loss:0.110\n",
            "Epoch:2184/3000 AVG Training Loss:0.139 AVG Test Loss:0.223\n",
            "Epoch:2185/3000 AVG Training Loss:0.197 AVG Test Loss:0.126\n",
            "Epoch:2186/3000 AVG Training Loss:0.130 AVG Test Loss:0.131\n",
            "Epoch:2187/3000 AVG Training Loss:0.094 AVG Test Loss:0.028\n",
            "Epoch:2188/3000 AVG Training Loss:0.113 AVG Test Loss:0.011\n",
            "Epoch:2189/3000 AVG Training Loss:0.074 AVG Test Loss:0.176\n",
            "Epoch:2190/3000 AVG Training Loss:0.069 AVG Test Loss:0.096\n",
            "Epoch:2191/3000 AVG Training Loss:0.128 AVG Test Loss:0.053\n",
            "Epoch:2192/3000 AVG Training Loss:0.125 AVG Test Loss:0.114\n",
            "Epoch:2193/3000 AVG Training Loss:0.169 AVG Test Loss:0.088\n",
            "Epoch:2194/3000 AVG Training Loss:0.106 AVG Test Loss:0.015\n",
            "Epoch:2195/3000 AVG Training Loss:0.123 AVG Test Loss:0.069\n",
            "Epoch:2196/3000 AVG Training Loss:0.111 AVG Test Loss:0.118\n",
            "Epoch:2197/3000 AVG Training Loss:0.098 AVG Test Loss:0.124\n",
            "Epoch:2198/3000 AVG Training Loss:0.125 AVG Test Loss:0.077\n",
            "Epoch:2199/3000 AVG Training Loss:0.169 AVG Test Loss:0.264\n",
            "Epoch:2200/3000 AVG Training Loss:0.145 AVG Test Loss:0.099\n",
            "Epoch:2201/3000 AVG Training Loss:0.101 AVG Test Loss:0.131\n",
            "Epoch:2202/3000 AVG Training Loss:0.149 AVG Test Loss:0.159\n",
            "Epoch:2203/3000 AVG Training Loss:0.154 AVG Test Loss:0.036\n",
            "Epoch:2204/3000 AVG Training Loss:0.105 AVG Test Loss:0.068\n",
            "Epoch:2205/3000 AVG Training Loss:0.101 AVG Test Loss:0.344\n",
            "Epoch:2206/3000 AVG Training Loss:0.105 AVG Test Loss:0.148\n",
            "Epoch:2207/3000 AVG Training Loss:0.060 AVG Test Loss:0.140\n",
            "Epoch:2208/3000 AVG Training Loss:0.128 AVG Test Loss:0.164\n",
            "Epoch:2209/3000 AVG Training Loss:0.083 AVG Test Loss:0.191\n",
            "Epoch:2210/3000 AVG Training Loss:0.074 AVG Test Loss:0.254\n",
            "Epoch:2211/3000 AVG Training Loss:0.126 AVG Test Loss:0.274\n",
            "Epoch:2212/3000 AVG Training Loss:0.098 AVG Test Loss:0.089\n",
            "Epoch:2213/3000 AVG Training Loss:0.097 AVG Test Loss:0.166\n",
            "Epoch:2214/3000 AVG Training Loss:0.052 AVG Test Loss:0.324\n",
            "Epoch:2215/3000 AVG Training Loss:0.177 AVG Test Loss:0.172\n",
            "Epoch:2216/3000 AVG Training Loss:0.085 AVG Test Loss:0.203\n",
            "Epoch:2217/3000 AVG Training Loss:0.125 AVG Test Loss:0.336\n",
            "Epoch:2218/3000 AVG Training Loss:0.105 AVG Test Loss:0.157\n",
            "Epoch:2219/3000 AVG Training Loss:0.125 AVG Test Loss:0.205\n",
            "Epoch:2220/3000 AVG Training Loss:0.099 AVG Test Loss:0.169\n",
            "Epoch:2221/3000 AVG Training Loss:0.118 AVG Test Loss:0.227\n",
            "Epoch:2222/3000 AVG Training Loss:0.145 AVG Test Loss:0.269\n",
            "Epoch:2223/3000 AVG Training Loss:0.068 AVG Test Loss:0.063\n",
            "Epoch:2224/3000 AVG Training Loss:0.108 AVG Test Loss:0.205\n",
            "Epoch:2225/3000 AVG Training Loss:0.152 AVG Test Loss:0.168\n",
            "Epoch:2226/3000 AVG Training Loss:0.102 AVG Test Loss:0.107\n",
            "Epoch:2227/3000 AVG Training Loss:0.099 AVG Test Loss:0.144\n",
            "Epoch:2228/3000 AVG Training Loss:0.085 AVG Test Loss:0.074\n",
            "Epoch:2229/3000 AVG Training Loss:0.092 AVG Test Loss:0.378\n",
            "Epoch:2230/3000 AVG Training Loss:0.066 AVG Test Loss:0.302\n",
            "Epoch:2231/3000 AVG Training Loss:0.073 AVG Test Loss:0.223\n",
            "Epoch:2232/3000 AVG Training Loss:0.084 AVG Test Loss:0.169\n",
            "Epoch:2233/3000 AVG Training Loss:0.134 AVG Test Loss:0.140\n",
            "Epoch:2234/3000 AVG Training Loss:0.071 AVG Test Loss:0.273\n",
            "Epoch:2235/3000 AVG Training Loss:0.066 AVG Test Loss:0.006\n",
            "Epoch:2236/3000 AVG Training Loss:0.086 AVG Test Loss:0.149\n",
            "Epoch:2237/3000 AVG Training Loss:0.116 AVG Test Loss:0.355\n",
            "Epoch:2238/3000 AVG Training Loss:0.111 AVG Test Loss:0.164\n",
            "Epoch:2239/3000 AVG Training Loss:0.162 AVG Test Loss:0.187\n",
            "Epoch:2240/3000 AVG Training Loss:0.116 AVG Test Loss:0.112\n",
            "Epoch:2241/3000 AVG Training Loss:0.176 AVG Test Loss:0.171\n",
            "Epoch:2242/3000 AVG Training Loss:0.088 AVG Test Loss:0.307\n",
            "Epoch:2243/3000 AVG Training Loss:0.124 AVG Test Loss:0.344\n",
            "Epoch:2244/3000 AVG Training Loss:0.142 AVG Test Loss:0.041\n",
            "Epoch:2245/3000 AVG Training Loss:0.072 AVG Test Loss:0.144\n",
            "Epoch:2246/3000 AVG Training Loss:0.141 AVG Test Loss:0.174\n",
            "Epoch:2247/3000 AVG Training Loss:0.113 AVG Test Loss:0.128\n",
            "Epoch:2248/3000 AVG Training Loss:0.093 AVG Test Loss:0.042\n",
            "Epoch:2249/3000 AVG Training Loss:0.129 AVG Test Loss:0.159\n",
            "Epoch:2250/3000 AVG Training Loss:0.131 AVG Test Loss:0.148\n",
            "Epoch:2251/3000 AVG Training Loss:0.135 AVG Test Loss:0.071\n",
            "Epoch:2252/3000 AVG Training Loss:0.088 AVG Test Loss:0.016\n",
            "Epoch:2253/3000 AVG Training Loss:0.096 AVG Test Loss:0.188\n",
            "Epoch:2254/3000 AVG Training Loss:0.123 AVG Test Loss:0.078\n",
            "Epoch:2255/3000 AVG Training Loss:0.098 AVG Test Loss:0.143\n",
            "Epoch:2256/3000 AVG Training Loss:0.073 AVG Test Loss:0.197\n",
            "Epoch:2257/3000 AVG Training Loss:0.111 AVG Test Loss:0.244\n",
            "Epoch:2258/3000 AVG Training Loss:0.082 AVG Test Loss:0.283\n",
            "Epoch:2259/3000 AVG Training Loss:0.143 AVG Test Loss:0.197\n",
            "Epoch:2260/3000 AVG Training Loss:0.082 AVG Test Loss:0.213\n",
            "Epoch:2261/3000 AVG Training Loss:0.144 AVG Test Loss:0.055\n",
            "Epoch:2262/3000 AVG Training Loss:0.128 AVG Test Loss:0.038\n",
            "Epoch:2263/3000 AVG Training Loss:0.098 AVG Test Loss:0.072\n",
            "Epoch:2264/3000 AVG Training Loss:0.149 AVG Test Loss:0.086\n",
            "Epoch:2265/3000 AVG Training Loss:0.091 AVG Test Loss:0.308\n",
            "Epoch:2266/3000 AVG Training Loss:0.123 AVG Test Loss:0.156\n",
            "Epoch:2267/3000 AVG Training Loss:0.111 AVG Test Loss:0.065\n",
            "Epoch:2268/3000 AVG Training Loss:0.126 AVG Test Loss:0.111\n",
            "Epoch:2269/3000 AVG Training Loss:0.058 AVG Test Loss:0.096\n",
            "Epoch:2270/3000 AVG Training Loss:0.213 AVG Test Loss:0.143\n",
            "Epoch:2271/3000 AVG Training Loss:0.102 AVG Test Loss:0.156\n",
            "Epoch:2272/3000 AVG Training Loss:0.171 AVG Test Loss:0.204\n",
            "Epoch:2273/3000 AVG Training Loss:0.082 AVG Test Loss:0.175\n",
            "Epoch:2274/3000 AVG Training Loss:0.111 AVG Test Loss:0.391\n",
            "Epoch:2275/3000 AVG Training Loss:0.087 AVG Test Loss:0.080\n",
            "Epoch:2276/3000 AVG Training Loss:0.149 AVG Test Loss:0.124\n",
            "Epoch:2277/3000 AVG Training Loss:0.085 AVG Test Loss:0.182\n",
            "Epoch:2278/3000 AVG Training Loss:0.104 AVG Test Loss:0.214\n",
            "Epoch:2279/3000 AVG Training Loss:0.170 AVG Test Loss:0.505\n",
            "Epoch:2280/3000 AVG Training Loss:0.091 AVG Test Loss:0.063\n",
            "Epoch:2281/3000 AVG Training Loss:0.090 AVG Test Loss:0.151\n",
            "Epoch:2282/3000 AVG Training Loss:0.057 AVG Test Loss:0.161\n",
            "Epoch:2283/3000 AVG Training Loss:0.136 AVG Test Loss:0.039\n",
            "Epoch:2284/3000 AVG Training Loss:0.090 AVG Test Loss:0.116\n",
            "Epoch:2285/3000 AVG Training Loss:0.108 AVG Test Loss:0.248\n",
            "Epoch:2286/3000 AVG Training Loss:0.147 AVG Test Loss:0.102\n",
            "Epoch:2287/3000 AVG Training Loss:0.122 AVG Test Loss:0.269\n",
            "Epoch:2288/3000 AVG Training Loss:0.128 AVG Test Loss:0.259\n",
            "Epoch:2289/3000 AVG Training Loss:0.059 AVG Test Loss:0.068\n",
            "Epoch:2290/3000 AVG Training Loss:0.102 AVG Test Loss:0.093\n",
            "Epoch:2291/3000 AVG Training Loss:0.146 AVG Test Loss:0.126\n",
            "Epoch:2292/3000 AVG Training Loss:0.124 AVG Test Loss:0.087\n",
            "Epoch:2293/3000 AVG Training Loss:0.068 AVG Test Loss:0.378\n",
            "Epoch:2294/3000 AVG Training Loss:0.103 AVG Test Loss:0.116\n",
            "Epoch:2295/3000 AVG Training Loss:0.075 AVG Test Loss:0.037\n",
            "Epoch:2296/3000 AVG Training Loss:0.088 AVG Test Loss:0.227\n",
            "Epoch:2297/3000 AVG Training Loss:0.154 AVG Test Loss:0.052\n",
            "Epoch:2298/3000 AVG Training Loss:0.114 AVG Test Loss:0.217\n",
            "Epoch:2299/3000 AVG Training Loss:0.067 AVG Test Loss:0.062\n",
            "Epoch:2300/3000 AVG Training Loss:0.049 AVG Test Loss:0.061\n",
            "Epoch:2301/3000 AVG Training Loss:0.126 AVG Test Loss:0.040\n",
            "Epoch:2302/3000 AVG Training Loss:0.104 AVG Test Loss:0.204\n",
            "Epoch:2303/3000 AVG Training Loss:0.097 AVG Test Loss:0.391\n",
            "Epoch:2304/3000 AVG Training Loss:0.087 AVG Test Loss:0.114\n",
            "Epoch:2305/3000 AVG Training Loss:0.090 AVG Test Loss:0.136\n",
            "Epoch:2306/3000 AVG Training Loss:0.103 AVG Test Loss:0.148\n",
            "Epoch:2307/3000 AVG Training Loss:0.114 AVG Test Loss:0.024\n",
            "Epoch:2308/3000 AVG Training Loss:0.098 AVG Test Loss:0.035\n",
            "Epoch:2309/3000 AVG Training Loss:0.102 AVG Test Loss:0.139\n",
            "Epoch:2310/3000 AVG Training Loss:0.115 AVG Test Loss:0.100\n",
            "Epoch:2311/3000 AVG Training Loss:0.100 AVG Test Loss:0.029\n",
            "Epoch:2312/3000 AVG Training Loss:0.090 AVG Test Loss:0.391\n",
            "Epoch:2313/3000 AVG Training Loss:0.132 AVG Test Loss:0.072\n",
            "Epoch:2314/3000 AVG Training Loss:0.179 AVG Test Loss:0.150\n",
            "Epoch:2315/3000 AVG Training Loss:0.118 AVG Test Loss:0.263\n",
            "Epoch:2316/3000 AVG Training Loss:0.117 AVG Test Loss:0.155\n",
            "Epoch:2317/3000 AVG Training Loss:0.106 AVG Test Loss:0.248\n",
            "Epoch:2318/3000 AVG Training Loss:0.127 AVG Test Loss:0.346\n",
            "Epoch:2319/3000 AVG Training Loss:0.136 AVG Test Loss:0.137\n",
            "Epoch:2320/3000 AVG Training Loss:0.087 AVG Test Loss:0.264\n",
            "Epoch:2321/3000 AVG Training Loss:0.130 AVG Test Loss:0.165\n",
            "Epoch:2322/3000 AVG Training Loss:0.110 AVG Test Loss:0.042\n",
            "Epoch:2323/3000 AVG Training Loss:0.150 AVG Test Loss:0.034\n",
            "Epoch:2324/3000 AVG Training Loss:0.144 AVG Test Loss:0.043\n",
            "Epoch:2325/3000 AVG Training Loss:0.111 AVG Test Loss:0.290\n",
            "Epoch:2326/3000 AVG Training Loss:0.154 AVG Test Loss:0.241\n",
            "Epoch:2327/3000 AVG Training Loss:0.119 AVG Test Loss:0.096\n",
            "Epoch:2328/3000 AVG Training Loss:0.084 AVG Test Loss:0.011\n",
            "Epoch:2329/3000 AVG Training Loss:0.108 AVG Test Loss:0.058\n",
            "Epoch:2330/3000 AVG Training Loss:0.173 AVG Test Loss:0.349\n",
            "Epoch:2331/3000 AVG Training Loss:0.127 AVG Test Loss:0.326\n",
            "Epoch:2332/3000 AVG Training Loss:0.074 AVG Test Loss:0.309\n",
            "Epoch:2333/3000 AVG Training Loss:0.158 AVG Test Loss:0.131\n",
            "Epoch:2334/3000 AVG Training Loss:0.127 AVG Test Loss:0.292\n",
            "Epoch:2335/3000 AVG Training Loss:0.078 AVG Test Loss:0.115\n",
            "Epoch:2336/3000 AVG Training Loss:0.192 AVG Test Loss:0.069\n",
            "Epoch:2337/3000 AVG Training Loss:0.078 AVG Test Loss:0.129\n",
            "Epoch:2338/3000 AVG Training Loss:0.191 AVG Test Loss:0.024\n",
            "Epoch:2339/3000 AVG Training Loss:0.139 AVG Test Loss:0.082\n",
            "Epoch:2340/3000 AVG Training Loss:0.079 AVG Test Loss:0.085\n",
            "Epoch:2341/3000 AVG Training Loss:0.103 AVG Test Loss:0.167\n",
            "Epoch:2342/3000 AVG Training Loss:0.047 AVG Test Loss:0.198\n",
            "Epoch:2343/3000 AVG Training Loss:0.172 AVG Test Loss:0.139\n",
            "Epoch:2344/3000 AVG Training Loss:0.105 AVG Test Loss:0.248\n",
            "Epoch:2345/3000 AVG Training Loss:0.100 AVG Test Loss:0.166\n",
            "Epoch:2346/3000 AVG Training Loss:0.079 AVG Test Loss:0.261\n",
            "Epoch:2347/3000 AVG Training Loss:0.082 AVG Test Loss:0.021\n",
            "Epoch:2348/3000 AVG Training Loss:0.130 AVG Test Loss:0.127\n",
            "Epoch:2349/3000 AVG Training Loss:0.065 AVG Test Loss:0.139\n",
            "Epoch:2350/3000 AVG Training Loss:0.132 AVG Test Loss:0.138\n",
            "Epoch:2351/3000 AVG Training Loss:0.169 AVG Test Loss:0.316\n",
            "Epoch:2352/3000 AVG Training Loss:0.181 AVG Test Loss:0.037\n",
            "Epoch:2353/3000 AVG Training Loss:0.094 AVG Test Loss:0.217\n",
            "Epoch:2354/3000 AVG Training Loss:0.107 AVG Test Loss:0.245\n",
            "Epoch:2355/3000 AVG Training Loss:0.029 AVG Test Loss:0.284\n",
            "Epoch:2356/3000 AVG Training Loss:0.116 AVG Test Loss:0.176\n",
            "Epoch:2357/3000 AVG Training Loss:0.083 AVG Test Loss:0.050\n",
            "Epoch:2358/3000 AVG Training Loss:0.164 AVG Test Loss:0.032\n",
            "Epoch:2359/3000 AVG Training Loss:0.159 AVG Test Loss:0.061\n",
            "Epoch:2360/3000 AVG Training Loss:0.196 AVG Test Loss:0.096\n",
            "Epoch:2361/3000 AVG Training Loss:0.148 AVG Test Loss:0.294\n",
            "Epoch:2362/3000 AVG Training Loss:0.162 AVG Test Loss:0.050\n",
            "Epoch:2363/3000 AVG Training Loss:0.076 AVG Test Loss:0.174\n",
            "Epoch:2364/3000 AVG Training Loss:0.070 AVG Test Loss:0.121\n",
            "Epoch:2365/3000 AVG Training Loss:0.129 AVG Test Loss:0.072\n",
            "Epoch:2366/3000 AVG Training Loss:0.078 AVG Test Loss:0.076\n",
            "Epoch:2367/3000 AVG Training Loss:0.110 AVG Test Loss:0.144\n",
            "Epoch:2368/3000 AVG Training Loss:0.120 AVG Test Loss:0.094\n",
            "Epoch:2369/3000 AVG Training Loss:0.153 AVG Test Loss:0.217\n",
            "Epoch:2370/3000 AVG Training Loss:0.172 AVG Test Loss:0.317\n",
            "Epoch:2371/3000 AVG Training Loss:0.209 AVG Test Loss:0.132\n",
            "Epoch:2372/3000 AVG Training Loss:0.124 AVG Test Loss:0.249\n",
            "Epoch:2373/3000 AVG Training Loss:0.178 AVG Test Loss:0.154\n",
            "Epoch:2374/3000 AVG Training Loss:0.093 AVG Test Loss:0.210\n",
            "Epoch:2375/3000 AVG Training Loss:0.111 AVG Test Loss:0.051\n",
            "Epoch:2376/3000 AVG Training Loss:0.102 AVG Test Loss:0.198\n",
            "Epoch:2377/3000 AVG Training Loss:0.081 AVG Test Loss:0.147\n",
            "Epoch:2378/3000 AVG Training Loss:0.101 AVG Test Loss:0.107\n",
            "Epoch:2379/3000 AVG Training Loss:0.161 AVG Test Loss:0.249\n",
            "Epoch:2380/3000 AVG Training Loss:0.104 AVG Test Loss:0.157\n",
            "Epoch:2381/3000 AVG Training Loss:0.052 AVG Test Loss:0.231\n",
            "Epoch:2382/3000 AVG Training Loss:0.154 AVG Test Loss:0.029\n",
            "Epoch:2383/3000 AVG Training Loss:0.191 AVG Test Loss:0.012\n",
            "Epoch:2384/3000 AVG Training Loss:0.115 AVG Test Loss:0.248\n",
            "Epoch:2385/3000 AVG Training Loss:0.107 AVG Test Loss:0.159\n",
            "Epoch:2386/3000 AVG Training Loss:0.073 AVG Test Loss:0.291\n",
            "Epoch:2387/3000 AVG Training Loss:0.145 AVG Test Loss:0.157\n",
            "Epoch:2388/3000 AVG Training Loss:0.129 AVG Test Loss:0.417\n",
            "Epoch:2389/3000 AVG Training Loss:0.066 AVG Test Loss:0.107\n",
            "Epoch:2390/3000 AVG Training Loss:0.174 AVG Test Loss:0.202\n",
            "Epoch:2391/3000 AVG Training Loss:0.118 AVG Test Loss:0.189\n",
            "Epoch:2392/3000 AVG Training Loss:0.103 AVG Test Loss:0.144\n",
            "Epoch:2393/3000 AVG Training Loss:0.086 AVG Test Loss:0.196\n",
            "Epoch:2394/3000 AVG Training Loss:0.078 AVG Test Loss:0.344\n",
            "Epoch:2395/3000 AVG Training Loss:0.164 AVG Test Loss:0.042\n",
            "Epoch:2396/3000 AVG Training Loss:0.104 AVG Test Loss:0.137\n",
            "Epoch:2397/3000 AVG Training Loss:0.143 AVG Test Loss:0.104\n",
            "Epoch:2398/3000 AVG Training Loss:0.132 AVG Test Loss:0.204\n",
            "Epoch:2399/3000 AVG Training Loss:0.209 AVG Test Loss:0.260\n",
            "Epoch:2400/3000 AVG Training Loss:0.209 AVG Test Loss:0.173\n",
            "Epoch:2401/3000 AVG Training Loss:0.140 AVG Test Loss:0.177\n",
            "Epoch:2402/3000 AVG Training Loss:0.059 AVG Test Loss:0.293\n",
            "Epoch:2403/3000 AVG Training Loss:0.086 AVG Test Loss:0.063\n",
            "Epoch:2404/3000 AVG Training Loss:0.135 AVG Test Loss:0.270\n",
            "Epoch:2405/3000 AVG Training Loss:0.107 AVG Test Loss:0.170\n",
            "Epoch:2406/3000 AVG Training Loss:0.100 AVG Test Loss:0.166\n",
            "Epoch:2407/3000 AVG Training Loss:0.138 AVG Test Loss:0.275\n",
            "Epoch:2408/3000 AVG Training Loss:0.208 AVG Test Loss:0.121\n",
            "Epoch:2409/3000 AVG Training Loss:0.112 AVG Test Loss:0.252\n",
            "Epoch:2410/3000 AVG Training Loss:0.125 AVG Test Loss:0.182\n",
            "Epoch:2411/3000 AVG Training Loss:0.062 AVG Test Loss:0.258\n",
            "Epoch:2412/3000 AVG Training Loss:0.136 AVG Test Loss:0.185\n",
            "Epoch:2413/3000 AVG Training Loss:0.118 AVG Test Loss:0.108\n",
            "Epoch:2414/3000 AVG Training Loss:0.121 AVG Test Loss:0.268\n",
            "Epoch:2415/3000 AVG Training Loss:0.107 AVG Test Loss:0.246\n",
            "Epoch:2416/3000 AVG Training Loss:0.093 AVG Test Loss:0.202\n",
            "Epoch:2417/3000 AVG Training Loss:0.089 AVG Test Loss:0.026\n",
            "Epoch:2418/3000 AVG Training Loss:0.094 AVG Test Loss:0.330\n",
            "Epoch:2419/3000 AVG Training Loss:0.113 AVG Test Loss:0.355\n",
            "Epoch:2420/3000 AVG Training Loss:0.188 AVG Test Loss:0.223\n",
            "Epoch:2421/3000 AVG Training Loss:0.161 AVG Test Loss:0.261\n",
            "Epoch:2422/3000 AVG Training Loss:0.095 AVG Test Loss:0.156\n",
            "Epoch:2423/3000 AVG Training Loss:0.135 AVG Test Loss:0.054\n",
            "Epoch:2424/3000 AVG Training Loss:0.123 AVG Test Loss:0.132\n",
            "Epoch:2425/3000 AVG Training Loss:0.088 AVG Test Loss:0.330\n",
            "Epoch:2426/3000 AVG Training Loss:0.146 AVG Test Loss:0.087\n",
            "Epoch:2427/3000 AVG Training Loss:0.150 AVG Test Loss:0.292\n",
            "Epoch:2428/3000 AVG Training Loss:0.142 AVG Test Loss:0.129\n",
            "Epoch:2429/3000 AVG Training Loss:0.116 AVG Test Loss:0.195\n",
            "Epoch:2430/3000 AVG Training Loss:0.141 AVG Test Loss:0.070\n",
            "Epoch:2431/3000 AVG Training Loss:0.120 AVG Test Loss:0.111\n",
            "Epoch:2432/3000 AVG Training Loss:0.091 AVG Test Loss:0.257\n",
            "Epoch:2433/3000 AVG Training Loss:0.158 AVG Test Loss:0.163\n",
            "Epoch:2434/3000 AVG Training Loss:0.144 AVG Test Loss:0.232\n",
            "Epoch:2435/3000 AVG Training Loss:0.129 AVG Test Loss:0.216\n",
            "Epoch:2436/3000 AVG Training Loss:0.049 AVG Test Loss:0.339\n",
            "Epoch:2437/3000 AVG Training Loss:0.083 AVG Test Loss:0.195\n",
            "Epoch:2438/3000 AVG Training Loss:0.082 AVG Test Loss:0.052\n",
            "Epoch:2439/3000 AVG Training Loss:0.136 AVG Test Loss:0.197\n",
            "Epoch:2440/3000 AVG Training Loss:0.106 AVG Test Loss:0.078\n",
            "Epoch:2441/3000 AVG Training Loss:0.185 AVG Test Loss:0.171\n",
            "Epoch:2442/3000 AVG Training Loss:0.119 AVG Test Loss:0.165\n",
            "Epoch:2443/3000 AVG Training Loss:0.145 AVG Test Loss:0.208\n",
            "Epoch:2444/3000 AVG Training Loss:0.089 AVG Test Loss:0.140\n",
            "Epoch:2445/3000 AVG Training Loss:0.086 AVG Test Loss:0.235\n",
            "Epoch:2446/3000 AVG Training Loss:0.057 AVG Test Loss:0.159\n",
            "Epoch:2447/3000 AVG Training Loss:0.089 AVG Test Loss:0.027\n",
            "Epoch:2448/3000 AVG Training Loss:0.087 AVG Test Loss:0.167\n",
            "Epoch:2449/3000 AVG Training Loss:0.070 AVG Test Loss:0.283\n",
            "Epoch:2450/3000 AVG Training Loss:0.115 AVG Test Loss:0.261\n",
            "Epoch:2451/3000 AVG Training Loss:0.085 AVG Test Loss:0.256\n",
            "Epoch:2452/3000 AVG Training Loss:0.157 AVG Test Loss:0.124\n",
            "Epoch:2453/3000 AVG Training Loss:0.107 AVG Test Loss:0.209\n",
            "Epoch:2454/3000 AVG Training Loss:0.111 AVG Test Loss:0.268\n",
            "Epoch:2455/3000 AVG Training Loss:0.125 AVG Test Loss:0.211\n",
            "Epoch:2456/3000 AVG Training Loss:0.071 AVG Test Loss:0.044\n",
            "Epoch:2457/3000 AVG Training Loss:0.141 AVG Test Loss:0.350\n",
            "Epoch:2458/3000 AVG Training Loss:0.154 AVG Test Loss:0.159\n",
            "Epoch:2459/3000 AVG Training Loss:0.076 AVG Test Loss:0.121\n",
            "Epoch:2460/3000 AVG Training Loss:0.094 AVG Test Loss:0.028\n",
            "Epoch:2461/3000 AVG Training Loss:0.089 AVG Test Loss:0.164\n",
            "Epoch:2462/3000 AVG Training Loss:0.105 AVG Test Loss:0.063\n",
            "Epoch:2463/3000 AVG Training Loss:0.062 AVG Test Loss:0.209\n",
            "Epoch:2464/3000 AVG Training Loss:0.120 AVG Test Loss:0.211\n",
            "Epoch:2465/3000 AVG Training Loss:0.072 AVG Test Loss:0.122\n",
            "Epoch:2466/3000 AVG Training Loss:0.085 AVG Test Loss:0.116\n",
            "Epoch:2467/3000 AVG Training Loss:0.121 AVG Test Loss:0.389\n",
            "Epoch:2468/3000 AVG Training Loss:0.121 AVG Test Loss:0.184\n",
            "Epoch:2469/3000 AVG Training Loss:0.079 AVG Test Loss:0.053\n",
            "Epoch:2470/3000 AVG Training Loss:0.083 AVG Test Loss:0.073\n",
            "Epoch:2471/3000 AVG Training Loss:0.129 AVG Test Loss:0.098\n",
            "Epoch:2472/3000 AVG Training Loss:0.086 AVG Test Loss:0.041\n",
            "Epoch:2473/3000 AVG Training Loss:0.146 AVG Test Loss:0.344\n",
            "Epoch:2474/3000 AVG Training Loss:0.155 AVG Test Loss:0.040\n",
            "Epoch:2475/3000 AVG Training Loss:0.144 AVG Test Loss:0.310\n",
            "Epoch:2476/3000 AVG Training Loss:0.081 AVG Test Loss:0.140\n",
            "Epoch:2477/3000 AVG Training Loss:0.125 AVG Test Loss:0.151\n",
            "Epoch:2478/3000 AVG Training Loss:0.087 AVG Test Loss:0.049\n",
            "Epoch:2479/3000 AVG Training Loss:0.144 AVG Test Loss:0.017\n",
            "Epoch:2480/3000 AVG Training Loss:0.105 AVG Test Loss:0.241\n",
            "Epoch:2481/3000 AVG Training Loss:0.114 AVG Test Loss:0.320\n",
            "Epoch:2482/3000 AVG Training Loss:0.087 AVG Test Loss:0.458\n",
            "Epoch:2483/3000 AVG Training Loss:0.103 AVG Test Loss:0.274\n",
            "Epoch:2484/3000 AVG Training Loss:0.081 AVG Test Loss:0.165\n",
            "Epoch:2485/3000 AVG Training Loss:0.109 AVG Test Loss:0.123\n",
            "Epoch:2486/3000 AVG Training Loss:0.136 AVG Test Loss:0.105\n",
            "Epoch:2487/3000 AVG Training Loss:0.156 AVG Test Loss:0.159\n",
            "Epoch:2488/3000 AVG Training Loss:0.145 AVG Test Loss:0.051\n",
            "Epoch:2489/3000 AVG Training Loss:0.099 AVG Test Loss:0.151\n",
            "Epoch:2490/3000 AVG Training Loss:0.146 AVG Test Loss:0.088\n",
            "Epoch:2491/3000 AVG Training Loss:0.122 AVG Test Loss:0.033\n",
            "Epoch:2492/3000 AVG Training Loss:0.072 AVG Test Loss:0.272\n",
            "Epoch:2493/3000 AVG Training Loss:0.088 AVG Test Loss:0.182\n",
            "Epoch:2494/3000 AVG Training Loss:0.094 AVG Test Loss:0.029\n",
            "Epoch:2495/3000 AVG Training Loss:0.107 AVG Test Loss:0.126\n",
            "Epoch:2496/3000 AVG Training Loss:0.066 AVG Test Loss:0.269\n",
            "Epoch:2497/3000 AVG Training Loss:0.103 AVG Test Loss:0.112\n",
            "Epoch:2498/3000 AVG Training Loss:0.107 AVG Test Loss:0.076\n",
            "Epoch:2499/3000 AVG Training Loss:0.046 AVG Test Loss:0.079\n",
            "Epoch:2500/3000 AVG Training Loss:0.068 AVG Test Loss:0.098\n",
            "Epoch:2501/3000 AVG Training Loss:0.084 AVG Test Loss:0.153\n",
            "Epoch:2502/3000 AVG Training Loss:0.134 AVG Test Loss:0.108\n",
            "Epoch:2503/3000 AVG Training Loss:0.078 AVG Test Loss:0.217\n",
            "Epoch:2504/3000 AVG Training Loss:0.061 AVG Test Loss:0.107\n",
            "Epoch:2505/3000 AVG Training Loss:0.169 AVG Test Loss:0.201\n",
            "Epoch:2506/3000 AVG Training Loss:0.078 AVG Test Loss:0.259\n",
            "Epoch:2507/3000 AVG Training Loss:0.128 AVG Test Loss:0.164\n",
            "Epoch:2508/3000 AVG Training Loss:0.164 AVG Test Loss:0.013\n",
            "Epoch:2509/3000 AVG Training Loss:0.046 AVG Test Loss:0.129\n",
            "Epoch:2510/3000 AVG Training Loss:0.189 AVG Test Loss:0.176\n",
            "Epoch:2511/3000 AVG Training Loss:0.118 AVG Test Loss:0.005\n",
            "Epoch:2512/3000 AVG Training Loss:0.134 AVG Test Loss:0.264\n",
            "Epoch:2513/3000 AVG Training Loss:0.096 AVG Test Loss:0.178\n",
            "Epoch:2514/3000 AVG Training Loss:0.104 AVG Test Loss:0.188\n",
            "Epoch:2515/3000 AVG Training Loss:0.110 AVG Test Loss:0.145\n",
            "Epoch:2516/3000 AVG Training Loss:0.121 AVG Test Loss:0.110\n",
            "Epoch:2517/3000 AVG Training Loss:0.062 AVG Test Loss:0.193\n",
            "Epoch:2518/3000 AVG Training Loss:0.104 AVG Test Loss:0.254\n",
            "Epoch:2519/3000 AVG Training Loss:0.145 AVG Test Loss:0.091\n",
            "Epoch:2520/3000 AVG Training Loss:0.099 AVG Test Loss:0.165\n",
            "Epoch:2521/3000 AVG Training Loss:0.088 AVG Test Loss:0.208\n",
            "Epoch:2522/3000 AVG Training Loss:0.114 AVG Test Loss:0.152\n",
            "Epoch:2523/3000 AVG Training Loss:0.122 AVG Test Loss:0.250\n",
            "Epoch:2524/3000 AVG Training Loss:0.151 AVG Test Loss:0.190\n",
            "Epoch:2525/3000 AVG Training Loss:0.143 AVG Test Loss:0.048\n",
            "Epoch:2526/3000 AVG Training Loss:0.063 AVG Test Loss:0.097\n",
            "Epoch:2527/3000 AVG Training Loss:0.070 AVG Test Loss:0.096\n",
            "Epoch:2528/3000 AVG Training Loss:0.098 AVG Test Loss:0.111\n",
            "Epoch:2529/3000 AVG Training Loss:0.163 AVG Test Loss:0.166\n",
            "Epoch:2530/3000 AVG Training Loss:0.131 AVG Test Loss:0.136\n",
            "Epoch:2531/3000 AVG Training Loss:0.133 AVG Test Loss:0.236\n",
            "Epoch:2532/3000 AVG Training Loss:0.093 AVG Test Loss:0.201\n",
            "Epoch:2533/3000 AVG Training Loss:0.053 AVG Test Loss:0.284\n",
            "Epoch:2534/3000 AVG Training Loss:0.087 AVG Test Loss:0.147\n",
            "Epoch:2535/3000 AVG Training Loss:0.152 AVG Test Loss:0.370\n",
            "Epoch:2536/3000 AVG Training Loss:0.123 AVG Test Loss:0.029\n",
            "Epoch:2537/3000 AVG Training Loss:0.082 AVG Test Loss:0.047\n",
            "Epoch:2538/3000 AVG Training Loss:0.084 AVG Test Loss:0.162\n",
            "Epoch:2539/3000 AVG Training Loss:0.122 AVG Test Loss:0.121\n",
            "Epoch:2540/3000 AVG Training Loss:0.096 AVG Test Loss:0.041\n",
            "Epoch:2541/3000 AVG Training Loss:0.083 AVG Test Loss:0.375\n",
            "Epoch:2542/3000 AVG Training Loss:0.101 AVG Test Loss:0.081\n",
            "Epoch:2543/3000 AVG Training Loss:0.137 AVG Test Loss:0.028\n",
            "Epoch:2544/3000 AVG Training Loss:0.122 AVG Test Loss:0.022\n",
            "Epoch:2545/3000 AVG Training Loss:0.098 AVG Test Loss:0.180\n",
            "Epoch:2546/3000 AVG Training Loss:0.106 AVG Test Loss:0.241\n",
            "Epoch:2547/3000 AVG Training Loss:0.092 AVG Test Loss:0.070\n",
            "Epoch:2548/3000 AVG Training Loss:0.088 AVG Test Loss:0.162\n",
            "Epoch:2549/3000 AVG Training Loss:0.057 AVG Test Loss:0.129\n",
            "Epoch:2550/3000 AVG Training Loss:0.076 AVG Test Loss:0.134\n",
            "Epoch:2551/3000 AVG Training Loss:0.145 AVG Test Loss:0.183\n",
            "Epoch:2552/3000 AVG Training Loss:0.109 AVG Test Loss:0.359\n",
            "Epoch:2553/3000 AVG Training Loss:0.069 AVG Test Loss:0.053\n",
            "Epoch:2554/3000 AVG Training Loss:0.076 AVG Test Loss:0.293\n",
            "Epoch:2555/3000 AVG Training Loss:0.083 AVG Test Loss:0.344\n",
            "Epoch:2556/3000 AVG Training Loss:0.110 AVG Test Loss:0.135\n",
            "Epoch:2557/3000 AVG Training Loss:0.071 AVG Test Loss:0.064\n",
            "Epoch:2558/3000 AVG Training Loss:0.194 AVG Test Loss:0.208\n",
            "Epoch:2559/3000 AVG Training Loss:0.083 AVG Test Loss:0.081\n",
            "Epoch:2560/3000 AVG Training Loss:0.165 AVG Test Loss:0.051\n",
            "Epoch:2561/3000 AVG Training Loss:0.079 AVG Test Loss:0.157\n",
            "Epoch:2562/3000 AVG Training Loss:0.063 AVG Test Loss:0.317\n",
            "Epoch:2563/3000 AVG Training Loss:0.097 AVG Test Loss:0.185\n",
            "Epoch:2564/3000 AVG Training Loss:0.084 AVG Test Loss:0.078\n",
            "Epoch:2565/3000 AVG Training Loss:0.081 AVG Test Loss:0.106\n",
            "Epoch:2566/3000 AVG Training Loss:0.072 AVG Test Loss:0.135\n",
            "Epoch:2567/3000 AVG Training Loss:0.158 AVG Test Loss:0.250\n",
            "Epoch:2568/3000 AVG Training Loss:0.101 AVG Test Loss:0.236\n",
            "Epoch:2569/3000 AVG Training Loss:0.096 AVG Test Loss:0.347\n",
            "Epoch:2570/3000 AVG Training Loss:0.067 AVG Test Loss:0.165\n",
            "Epoch:2571/3000 AVG Training Loss:0.119 AVG Test Loss:0.233\n",
            "Epoch:2572/3000 AVG Training Loss:0.109 AVG Test Loss:0.261\n",
            "Epoch:2573/3000 AVG Training Loss:0.147 AVG Test Loss:0.117\n",
            "Epoch:2574/3000 AVG Training Loss:0.081 AVG Test Loss:0.042\n",
            "Epoch:2575/3000 AVG Training Loss:0.087 AVG Test Loss:0.325\n",
            "Epoch:2576/3000 AVG Training Loss:0.150 AVG Test Loss:0.012\n",
            "Epoch:2577/3000 AVG Training Loss:0.138 AVG Test Loss:0.237\n",
            "Epoch:2578/3000 AVG Training Loss:0.133 AVG Test Loss:0.243\n",
            "Epoch:2579/3000 AVG Training Loss:0.088 AVG Test Loss:0.100\n",
            "Epoch:2580/3000 AVG Training Loss:0.111 AVG Test Loss:0.144\n",
            "Epoch:2581/3000 AVG Training Loss:0.144 AVG Test Loss:0.288\n",
            "Epoch:2582/3000 AVG Training Loss:0.120 AVG Test Loss:0.329\n",
            "Epoch:2583/3000 AVG Training Loss:0.129 AVG Test Loss:0.129\n",
            "Epoch:2584/3000 AVG Training Loss:0.111 AVG Test Loss:0.113\n",
            "Epoch:2585/3000 AVG Training Loss:0.076 AVG Test Loss:0.095\n",
            "Epoch:2586/3000 AVG Training Loss:0.089 AVG Test Loss:0.215\n",
            "Epoch:2587/3000 AVG Training Loss:0.154 AVG Test Loss:0.306\n",
            "Epoch:2588/3000 AVG Training Loss:0.037 AVG Test Loss:0.096\n",
            "Epoch:2589/3000 AVG Training Loss:0.066 AVG Test Loss:0.045\n",
            "Epoch:2590/3000 AVG Training Loss:0.093 AVG Test Loss:0.051\n",
            "Epoch:2591/3000 AVG Training Loss:0.176 AVG Test Loss:0.274\n",
            "Epoch:2592/3000 AVG Training Loss:0.107 AVG Test Loss:0.268\n",
            "Epoch:2593/3000 AVG Training Loss:0.117 AVG Test Loss:0.034\n",
            "Epoch:2594/3000 AVG Training Loss:0.094 AVG Test Loss:0.010\n",
            "Epoch:2595/3000 AVG Training Loss:0.111 AVG Test Loss:0.060\n",
            "Epoch:2596/3000 AVG Training Loss:0.117 AVG Test Loss:0.202\n",
            "Epoch:2597/3000 AVG Training Loss:0.106 AVG Test Loss:0.203\n",
            "Epoch:2598/3000 AVG Training Loss:0.085 AVG Test Loss:0.068\n",
            "Epoch:2599/3000 AVG Training Loss:0.146 AVG Test Loss:0.128\n",
            "Epoch:2600/3000 AVG Training Loss:0.081 AVG Test Loss:0.134\n",
            "Epoch:2601/3000 AVG Training Loss:0.104 AVG Test Loss:0.259\n",
            "Epoch:2602/3000 AVG Training Loss:0.180 AVG Test Loss:0.138\n",
            "Epoch:2603/3000 AVG Training Loss:0.093 AVG Test Loss:0.102\n",
            "Epoch:2604/3000 AVG Training Loss:0.126 AVG Test Loss:0.234\n",
            "Epoch:2605/3000 AVG Training Loss:0.125 AVG Test Loss:0.259\n",
            "Epoch:2606/3000 AVG Training Loss:0.125 AVG Test Loss:0.245\n",
            "Epoch:2607/3000 AVG Training Loss:0.147 AVG Test Loss:0.081\n",
            "Epoch:2608/3000 AVG Training Loss:0.106 AVG Test Loss:0.034\n",
            "Epoch:2609/3000 AVG Training Loss:0.143 AVG Test Loss:0.196\n",
            "Epoch:2610/3000 AVG Training Loss:0.110 AVG Test Loss:0.033\n",
            "Epoch:2611/3000 AVG Training Loss:0.075 AVG Test Loss:0.205\n",
            "Epoch:2612/3000 AVG Training Loss:0.088 AVG Test Loss:0.147\n",
            "Epoch:2613/3000 AVG Training Loss:0.123 AVG Test Loss:0.022\n",
            "Epoch:2614/3000 AVG Training Loss:0.106 AVG Test Loss:0.414\n",
            "Epoch:2615/3000 AVG Training Loss:0.120 AVG Test Loss:0.172\n",
            "Epoch:2616/3000 AVG Training Loss:0.192 AVG Test Loss:0.376\n",
            "Epoch:2617/3000 AVG Training Loss:0.108 AVG Test Loss:0.162\n",
            "Epoch:2618/3000 AVG Training Loss:0.136 AVG Test Loss:0.119\n",
            "Epoch:2619/3000 AVG Training Loss:0.078 AVG Test Loss:0.148\n",
            "Epoch:2620/3000 AVG Training Loss:0.137 AVG Test Loss:0.135\n",
            "Epoch:2621/3000 AVG Training Loss:0.117 AVG Test Loss:0.356\n",
            "Epoch:2622/3000 AVG Training Loss:0.138 AVG Test Loss:0.110\n",
            "Epoch:2623/3000 AVG Training Loss:0.093 AVG Test Loss:0.154\n",
            "Epoch:2624/3000 AVG Training Loss:0.172 AVG Test Loss:0.322\n",
            "Epoch:2625/3000 AVG Training Loss:0.120 AVG Test Loss:0.032\n",
            "Epoch:2626/3000 AVG Training Loss:0.076 AVG Test Loss:0.336\n",
            "Epoch:2627/3000 AVG Training Loss:0.063 AVG Test Loss:0.299\n",
            "Epoch:2628/3000 AVG Training Loss:0.103 AVG Test Loss:0.091\n",
            "Epoch:2629/3000 AVG Training Loss:0.057 AVG Test Loss:0.245\n",
            "Epoch:2630/3000 AVG Training Loss:0.166 AVG Test Loss:0.249\n",
            "Epoch:2631/3000 AVG Training Loss:0.061 AVG Test Loss:0.142\n",
            "Epoch:2632/3000 AVG Training Loss:0.186 AVG Test Loss:0.093\n",
            "Epoch:2633/3000 AVG Training Loss:0.075 AVG Test Loss:0.201\n",
            "Epoch:2634/3000 AVG Training Loss:0.071 AVG Test Loss:0.238\n",
            "Epoch:2635/3000 AVG Training Loss:0.085 AVG Test Loss:0.259\n",
            "Epoch:2636/3000 AVG Training Loss:0.100 AVG Test Loss:0.261\n",
            "Epoch:2637/3000 AVG Training Loss:0.075 AVG Test Loss:0.198\n",
            "Epoch:2638/3000 AVG Training Loss:0.130 AVG Test Loss:0.147\n",
            "Epoch:2639/3000 AVG Training Loss:0.063 AVG Test Loss:0.223\n",
            "Epoch:2640/3000 AVG Training Loss:0.098 AVG Test Loss:0.067\n",
            "Epoch:2641/3000 AVG Training Loss:0.060 AVG Test Loss:0.424\n",
            "Epoch:2642/3000 AVG Training Loss:0.108 AVG Test Loss:0.188\n",
            "Epoch:2643/3000 AVG Training Loss:0.126 AVG Test Loss:0.277\n",
            "Epoch:2644/3000 AVG Training Loss:0.085 AVG Test Loss:0.189\n",
            "Epoch:2645/3000 AVG Training Loss:0.112 AVG Test Loss:0.084\n",
            "Epoch:2646/3000 AVG Training Loss:0.104 AVG Test Loss:0.068\n",
            "Epoch:2647/3000 AVG Training Loss:0.078 AVG Test Loss:0.109\n",
            "Epoch:2648/3000 AVG Training Loss:0.059 AVG Test Loss:0.071\n",
            "Epoch:2649/3000 AVG Training Loss:0.090 AVG Test Loss:0.173\n",
            "Epoch:2650/3000 AVG Training Loss:0.101 AVG Test Loss:0.049\n",
            "Epoch:2651/3000 AVG Training Loss:0.145 AVG Test Loss:0.018\n",
            "Epoch:2652/3000 AVG Training Loss:0.111 AVG Test Loss:0.211\n",
            "Epoch:2653/3000 AVG Training Loss:0.081 AVG Test Loss:0.038\n",
            "Epoch:2654/3000 AVG Training Loss:0.117 AVG Test Loss:0.019\n",
            "Epoch:2655/3000 AVG Training Loss:0.123 AVG Test Loss:0.181\n",
            "Epoch:2656/3000 AVG Training Loss:0.098 AVG Test Loss:0.045\n",
            "Epoch:2657/3000 AVG Training Loss:0.141 AVG Test Loss:0.057\n",
            "Epoch:2658/3000 AVG Training Loss:0.109 AVG Test Loss:0.193\n",
            "Epoch:2659/3000 AVG Training Loss:0.111 AVG Test Loss:0.458\n",
            "Epoch:2660/3000 AVG Training Loss:0.075 AVG Test Loss:0.328\n",
            "Epoch:2661/3000 AVG Training Loss:0.079 AVG Test Loss:0.256\n",
            "Epoch:2662/3000 AVG Training Loss:0.108 AVG Test Loss:0.119\n",
            "Epoch:2663/3000 AVG Training Loss:0.148 AVG Test Loss:0.138\n",
            "Epoch:2664/3000 AVG Training Loss:0.040 AVG Test Loss:0.183\n",
            "Epoch:2665/3000 AVG Training Loss:0.063 AVG Test Loss:0.117\n",
            "Epoch:2666/3000 AVG Training Loss:0.136 AVG Test Loss:0.033\n",
            "Epoch:2667/3000 AVG Training Loss:0.117 AVG Test Loss:0.146\n",
            "Epoch:2668/3000 AVG Training Loss:0.139 AVG Test Loss:0.041\n",
            "Epoch:2669/3000 AVG Training Loss:0.096 AVG Test Loss:0.188\n",
            "Epoch:2670/3000 AVG Training Loss:0.160 AVG Test Loss:0.051\n",
            "Epoch:2671/3000 AVG Training Loss:0.125 AVG Test Loss:0.167\n",
            "Epoch:2672/3000 AVG Training Loss:0.183 AVG Test Loss:0.045\n",
            "Epoch:2673/3000 AVG Training Loss:0.108 AVG Test Loss:0.334\n",
            "Epoch:2674/3000 AVG Training Loss:0.155 AVG Test Loss:0.281\n",
            "Epoch:2675/3000 AVG Training Loss:0.171 AVG Test Loss:0.331\n",
            "Epoch:2676/3000 AVG Training Loss:0.066 AVG Test Loss:0.087\n",
            "Epoch:2677/3000 AVG Training Loss:0.075 AVG Test Loss:0.221\n",
            "Epoch:2678/3000 AVG Training Loss:0.108 AVG Test Loss:0.232\n",
            "Epoch:2679/3000 AVG Training Loss:0.102 AVG Test Loss:0.083\n",
            "Epoch:2680/3000 AVG Training Loss:0.048 AVG Test Loss:0.187\n",
            "Epoch:2681/3000 AVG Training Loss:0.155 AVG Test Loss:0.087\n",
            "Epoch:2682/3000 AVG Training Loss:0.130 AVG Test Loss:0.038\n",
            "Epoch:2683/3000 AVG Training Loss:0.220 AVG Test Loss:0.363\n",
            "Epoch:2684/3000 AVG Training Loss:0.067 AVG Test Loss:0.075\n",
            "Epoch:2685/3000 AVG Training Loss:0.092 AVG Test Loss:0.178\n",
            "Epoch:2686/3000 AVG Training Loss:0.108 AVG Test Loss:0.051\n",
            "Epoch:2687/3000 AVG Training Loss:0.107 AVG Test Loss:0.211\n",
            "Epoch:2688/3000 AVG Training Loss:0.081 AVG Test Loss:0.130\n",
            "Epoch:2689/3000 AVG Training Loss:0.070 AVG Test Loss:0.080\n",
            "Epoch:2690/3000 AVG Training Loss:0.061 AVG Test Loss:0.239\n",
            "Epoch:2691/3000 AVG Training Loss:0.110 AVG Test Loss:0.231\n",
            "Epoch:2692/3000 AVG Training Loss:0.153 AVG Test Loss:0.105\n",
            "Epoch:2693/3000 AVG Training Loss:0.139 AVG Test Loss:0.227\n",
            "Epoch:2694/3000 AVG Training Loss:0.052 AVG Test Loss:0.196\n",
            "Epoch:2695/3000 AVG Training Loss:0.100 AVG Test Loss:0.314\n",
            "Epoch:2696/3000 AVG Training Loss:0.082 AVG Test Loss:0.308\n",
            "Epoch:2697/3000 AVG Training Loss:0.113 AVG Test Loss:0.046\n",
            "Epoch:2698/3000 AVG Training Loss:0.090 AVG Test Loss:0.107\n",
            "Epoch:2699/3000 AVG Training Loss:0.086 AVG Test Loss:0.193\n",
            "Epoch:2700/3000 AVG Training Loss:0.103 AVG Test Loss:0.229\n",
            "Epoch:2701/3000 AVG Training Loss:0.136 AVG Test Loss:0.129\n",
            "Epoch:2702/3000 AVG Training Loss:0.121 AVG Test Loss:0.145\n",
            "Epoch:2703/3000 AVG Training Loss:0.097 AVG Test Loss:0.093\n",
            "Epoch:2704/3000 AVG Training Loss:0.105 AVG Test Loss:0.058\n",
            "Epoch:2705/3000 AVG Training Loss:0.158 AVG Test Loss:0.018\n",
            "Epoch:2706/3000 AVG Training Loss:0.194 AVG Test Loss:0.198\n",
            "Epoch:2707/3000 AVG Training Loss:0.088 AVG Test Loss:0.156\n",
            "Epoch:2708/3000 AVG Training Loss:0.084 AVG Test Loss:0.172\n",
            "Epoch:2709/3000 AVG Training Loss:0.090 AVG Test Loss:0.031\n",
            "Epoch:2710/3000 AVG Training Loss:0.147 AVG Test Loss:0.018\n",
            "Epoch:2711/3000 AVG Training Loss:0.074 AVG Test Loss:0.063\n",
            "Epoch:2712/3000 AVG Training Loss:0.095 AVG Test Loss:0.318\n",
            "Epoch:2713/3000 AVG Training Loss:0.142 AVG Test Loss:0.166\n",
            "Epoch:2714/3000 AVG Training Loss:0.067 AVG Test Loss:0.038\n",
            "Epoch:2715/3000 AVG Training Loss:0.081 AVG Test Loss:0.102\n",
            "Epoch:2716/3000 AVG Training Loss:0.118 AVG Test Loss:0.052\n",
            "Epoch:2717/3000 AVG Training Loss:0.184 AVG Test Loss:0.041\n",
            "Epoch:2718/3000 AVG Training Loss:0.108 AVG Test Loss:0.084\n",
            "Epoch:2719/3000 AVG Training Loss:0.141 AVG Test Loss:0.010\n",
            "Epoch:2720/3000 AVG Training Loss:0.156 AVG Test Loss:0.290\n",
            "Epoch:2721/3000 AVG Training Loss:0.112 AVG Test Loss:0.187\n",
            "Epoch:2722/3000 AVG Training Loss:0.076 AVG Test Loss:0.095\n",
            "Epoch:2723/3000 AVG Training Loss:0.215 AVG Test Loss:0.066\n",
            "Epoch:2724/3000 AVG Training Loss:0.159 AVG Test Loss:0.139\n",
            "Epoch:2725/3000 AVG Training Loss:0.092 AVG Test Loss:0.153\n",
            "Epoch:2726/3000 AVG Training Loss:0.058 AVG Test Loss:0.021\n",
            "Epoch:2727/3000 AVG Training Loss:0.122 AVG Test Loss:0.197\n",
            "Epoch:2728/3000 AVG Training Loss:0.110 AVG Test Loss:0.016\n",
            "Epoch:2729/3000 AVG Training Loss:0.071 AVG Test Loss:0.012\n",
            "Epoch:2730/3000 AVG Training Loss:0.074 AVG Test Loss:0.181\n",
            "Epoch:2731/3000 AVG Training Loss:0.131 AVG Test Loss:0.298\n",
            "Epoch:2732/3000 AVG Training Loss:0.156 AVG Test Loss:0.008\n",
            "Epoch:2733/3000 AVG Training Loss:0.145 AVG Test Loss:0.161\n",
            "Epoch:2734/3000 AVG Training Loss:0.107 AVG Test Loss:0.037\n",
            "Epoch:2735/3000 AVG Training Loss:0.112 AVG Test Loss:0.016\n",
            "Epoch:2736/3000 AVG Training Loss:0.079 AVG Test Loss:0.315\n",
            "Epoch:2737/3000 AVG Training Loss:0.073 AVG Test Loss:0.043\n",
            "Epoch:2738/3000 AVG Training Loss:0.071 AVG Test Loss:0.070\n",
            "Epoch:2739/3000 AVG Training Loss:0.119 AVG Test Loss:0.173\n",
            "Epoch:2740/3000 AVG Training Loss:0.063 AVG Test Loss:0.053\n",
            "Epoch:2741/3000 AVG Training Loss:0.118 AVG Test Loss:0.107\n",
            "Epoch:2742/3000 AVG Training Loss:0.154 AVG Test Loss:0.184\n",
            "Epoch:2743/3000 AVG Training Loss:0.151 AVG Test Loss:0.074\n",
            "Epoch:2744/3000 AVG Training Loss:0.129 AVG Test Loss:0.052\n",
            "Epoch:2745/3000 AVG Training Loss:0.067 AVG Test Loss:0.215\n",
            "Epoch:2746/3000 AVG Training Loss:0.064 AVG Test Loss:0.173\n",
            "Epoch:2747/3000 AVG Training Loss:0.114 AVG Test Loss:0.176\n",
            "Epoch:2748/3000 AVG Training Loss:0.105 AVG Test Loss:0.217\n",
            "Epoch:2749/3000 AVG Training Loss:0.073 AVG Test Loss:0.153\n",
            "Epoch:2750/3000 AVG Training Loss:0.173 AVG Test Loss:0.217\n",
            "Epoch:2751/3000 AVG Training Loss:0.188 AVG Test Loss:0.287\n",
            "Epoch:2752/3000 AVG Training Loss:0.126 AVG Test Loss:0.449\n",
            "Epoch:2753/3000 AVG Training Loss:0.070 AVG Test Loss:0.087\n",
            "Epoch:2754/3000 AVG Training Loss:0.152 AVG Test Loss:0.012\n",
            "Epoch:2755/3000 AVG Training Loss:0.084 AVG Test Loss:0.225\n",
            "Epoch:2756/3000 AVG Training Loss:0.162 AVG Test Loss:0.179\n",
            "Epoch:2757/3000 AVG Training Loss:0.103 AVG Test Loss:0.175\n",
            "Epoch:2758/3000 AVG Training Loss:0.063 AVG Test Loss:0.422\n",
            "Epoch:2759/3000 AVG Training Loss:0.126 AVG Test Loss:0.204\n",
            "Epoch:2760/3000 AVG Training Loss:0.128 AVG Test Loss:0.235\n",
            "Epoch:2761/3000 AVG Training Loss:0.082 AVG Test Loss:0.021\n",
            "Epoch:2762/3000 AVG Training Loss:0.110 AVG Test Loss:0.087\n",
            "Epoch:2763/3000 AVG Training Loss:0.120 AVG Test Loss:0.245\n",
            "Epoch:2764/3000 AVG Training Loss:0.087 AVG Test Loss:0.160\n",
            "Epoch:2765/3000 AVG Training Loss:0.101 AVG Test Loss:0.223\n",
            "Epoch:2766/3000 AVG Training Loss:0.060 AVG Test Loss:0.030\n",
            "Epoch:2767/3000 AVG Training Loss:0.115 AVG Test Loss:0.131\n",
            "Epoch:2768/3000 AVG Training Loss:0.138 AVG Test Loss:0.057\n",
            "Epoch:2769/3000 AVG Training Loss:0.130 AVG Test Loss:0.095\n",
            "Epoch:2770/3000 AVG Training Loss:0.055 AVG Test Loss:0.118\n",
            "Epoch:2771/3000 AVG Training Loss:0.106 AVG Test Loss:0.035\n",
            "Epoch:2772/3000 AVG Training Loss:0.070 AVG Test Loss:0.176\n",
            "Epoch:2773/3000 AVG Training Loss:0.138 AVG Test Loss:0.077\n",
            "Epoch:2774/3000 AVG Training Loss:0.074 AVG Test Loss:0.246\n",
            "Epoch:2775/3000 AVG Training Loss:0.130 AVG Test Loss:0.207\n",
            "Epoch:2776/3000 AVG Training Loss:0.090 AVG Test Loss:0.055\n",
            "Epoch:2777/3000 AVG Training Loss:0.092 AVG Test Loss:0.233\n",
            "Epoch:2778/3000 AVG Training Loss:0.136 AVG Test Loss:0.234\n",
            "Epoch:2779/3000 AVG Training Loss:0.102 AVG Test Loss:0.263\n",
            "Epoch:2780/3000 AVG Training Loss:0.138 AVG Test Loss:0.095\n",
            "Epoch:2781/3000 AVG Training Loss:0.057 AVG Test Loss:0.037\n",
            "Epoch:2782/3000 AVG Training Loss:0.106 AVG Test Loss:0.221\n",
            "Epoch:2783/3000 AVG Training Loss:0.151 AVG Test Loss:0.319\n",
            "Epoch:2784/3000 AVG Training Loss:0.170 AVG Test Loss:0.215\n",
            "Epoch:2785/3000 AVG Training Loss:0.087 AVG Test Loss:0.030\n",
            "Epoch:2786/3000 AVG Training Loss:0.112 AVG Test Loss:0.038\n",
            "Epoch:2787/3000 AVG Training Loss:0.115 AVG Test Loss:0.266\n",
            "Epoch:2788/3000 AVG Training Loss:0.067 AVG Test Loss:0.290\n",
            "Epoch:2789/3000 AVG Training Loss:0.068 AVG Test Loss:0.274\n",
            "Epoch:2790/3000 AVG Training Loss:0.066 AVG Test Loss:0.094\n",
            "Epoch:2791/3000 AVG Training Loss:0.075 AVG Test Loss:0.045\n",
            "Epoch:2792/3000 AVG Training Loss:0.100 AVG Test Loss:0.076\n",
            "Epoch:2793/3000 AVG Training Loss:0.089 AVG Test Loss:0.372\n",
            "Epoch:2794/3000 AVG Training Loss:0.130 AVG Test Loss:0.109\n",
            "Epoch:2795/3000 AVG Training Loss:0.104 AVG Test Loss:0.135\n",
            "Epoch:2796/3000 AVG Training Loss:0.090 AVG Test Loss:0.208\n",
            "Epoch:2797/3000 AVG Training Loss:0.111 AVG Test Loss:0.173\n",
            "Epoch:2798/3000 AVG Training Loss:0.094 AVG Test Loss:0.035\n",
            "Epoch:2799/3000 AVG Training Loss:0.117 AVG Test Loss:0.064\n",
            "Epoch:2800/3000 AVG Training Loss:0.120 AVG Test Loss:0.011\n",
            "Epoch:2801/3000 AVG Training Loss:0.120 AVG Test Loss:0.390\n",
            "Epoch:2802/3000 AVG Training Loss:0.167 AVG Test Loss:0.171\n",
            "Epoch:2803/3000 AVG Training Loss:0.096 AVG Test Loss:0.101\n",
            "Epoch:2804/3000 AVG Training Loss:0.140 AVG Test Loss:0.043\n",
            "Epoch:2805/3000 AVG Training Loss:0.111 AVG Test Loss:0.243\n",
            "Epoch:2806/3000 AVG Training Loss:0.097 AVG Test Loss:0.128\n",
            "Epoch:2807/3000 AVG Training Loss:0.114 AVG Test Loss:0.293\n",
            "Epoch:2808/3000 AVG Training Loss:0.165 AVG Test Loss:0.164\n",
            "Epoch:2809/3000 AVG Training Loss:0.094 AVG Test Loss:0.160\n",
            "Epoch:2810/3000 AVG Training Loss:0.145 AVG Test Loss:0.313\n",
            "Epoch:2811/3000 AVG Training Loss:0.145 AVG Test Loss:0.010\n",
            "Epoch:2812/3000 AVG Training Loss:0.053 AVG Test Loss:0.108\n",
            "Epoch:2813/3000 AVG Training Loss:0.138 AVG Test Loss:0.155\n",
            "Epoch:2814/3000 AVG Training Loss:0.152 AVG Test Loss:0.233\n",
            "Epoch:2815/3000 AVG Training Loss:0.159 AVG Test Loss:0.049\n",
            "Epoch:2816/3000 AVG Training Loss:0.111 AVG Test Loss:0.032\n",
            "Epoch:2817/3000 AVG Training Loss:0.082 AVG Test Loss:0.157\n",
            "Epoch:2818/3000 AVG Training Loss:0.079 AVG Test Loss:0.256\n",
            "Epoch:2819/3000 AVG Training Loss:0.099 AVG Test Loss:0.061\n",
            "Epoch:2820/3000 AVG Training Loss:0.147 AVG Test Loss:0.149\n",
            "Epoch:2821/3000 AVG Training Loss:0.126 AVG Test Loss:0.137\n",
            "Epoch:2822/3000 AVG Training Loss:0.123 AVG Test Loss:0.053\n",
            "Epoch:2823/3000 AVG Training Loss:0.099 AVG Test Loss:0.085\n",
            "Epoch:2824/3000 AVG Training Loss:0.118 AVG Test Loss:0.294\n",
            "Epoch:2825/3000 AVG Training Loss:0.112 AVG Test Loss:0.198\n",
            "Epoch:2826/3000 AVG Training Loss:0.095 AVG Test Loss:0.244\n",
            "Epoch:2827/3000 AVG Training Loss:0.085 AVG Test Loss:0.101\n",
            "Epoch:2828/3000 AVG Training Loss:0.081 AVG Test Loss:0.208\n",
            "Epoch:2829/3000 AVG Training Loss:0.092 AVG Test Loss:0.107\n",
            "Epoch:2830/3000 AVG Training Loss:0.096 AVG Test Loss:0.134\n",
            "Epoch:2831/3000 AVG Training Loss:0.158 AVG Test Loss:0.152\n",
            "Epoch:2832/3000 AVG Training Loss:0.163 AVG Test Loss:0.048\n",
            "Epoch:2833/3000 AVG Training Loss:0.084 AVG Test Loss:0.102\n",
            "Epoch:2834/3000 AVG Training Loss:0.082 AVG Test Loss:0.065\n",
            "Epoch:2835/3000 AVG Training Loss:0.083 AVG Test Loss:0.341\n",
            "Epoch:2836/3000 AVG Training Loss:0.124 AVG Test Loss:0.238\n",
            "Epoch:2837/3000 AVG Training Loss:0.115 AVG Test Loss:0.069\n",
            "Epoch:2838/3000 AVG Training Loss:0.107 AVG Test Loss:0.277\n",
            "Epoch:2839/3000 AVG Training Loss:0.166 AVG Test Loss:0.037\n",
            "Epoch:2840/3000 AVG Training Loss:0.168 AVG Test Loss:0.028\n",
            "Epoch:2841/3000 AVG Training Loss:0.083 AVG Test Loss:0.094\n",
            "Epoch:2842/3000 AVG Training Loss:0.139 AVG Test Loss:0.149\n",
            "Epoch:2843/3000 AVG Training Loss:0.073 AVG Test Loss:0.282\n",
            "Epoch:2844/3000 AVG Training Loss:0.090 AVG Test Loss:0.120\n",
            "Epoch:2845/3000 AVG Training Loss:0.132 AVG Test Loss:0.134\n",
            "Epoch:2846/3000 AVG Training Loss:0.043 AVG Test Loss:0.126\n",
            "Epoch:2847/3000 AVG Training Loss:0.151 AVG Test Loss:0.045\n",
            "Epoch:2848/3000 AVG Training Loss:0.146 AVG Test Loss:0.132\n",
            "Epoch:2849/3000 AVG Training Loss:0.138 AVG Test Loss:0.142\n",
            "Epoch:2850/3000 AVG Training Loss:0.079 AVG Test Loss:0.035\n",
            "Epoch:2851/3000 AVG Training Loss:0.060 AVG Test Loss:0.089\n",
            "Epoch:2852/3000 AVG Training Loss:0.129 AVG Test Loss:0.121\n",
            "Epoch:2853/3000 AVG Training Loss:0.112 AVG Test Loss:0.222\n",
            "Epoch:2854/3000 AVG Training Loss:0.134 AVG Test Loss:0.296\n",
            "Epoch:2855/3000 AVG Training Loss:0.092 AVG Test Loss:0.069\n",
            "Epoch:2856/3000 AVG Training Loss:0.068 AVG Test Loss:0.177\n",
            "Epoch:2857/3000 AVG Training Loss:0.116 AVG Test Loss:0.019\n",
            "Epoch:2858/3000 AVG Training Loss:0.117 AVG Test Loss:0.061\n",
            "Epoch:2859/3000 AVG Training Loss:0.064 AVG Test Loss:0.261\n",
            "Epoch:2860/3000 AVG Training Loss:0.088 AVG Test Loss:0.224\n",
            "Epoch:2861/3000 AVG Training Loss:0.084 AVG Test Loss:0.184\n",
            "Epoch:2862/3000 AVG Training Loss:0.157 AVG Test Loss:0.184\n",
            "Epoch:2863/3000 AVG Training Loss:0.142 AVG Test Loss:0.125\n",
            "Epoch:2864/3000 AVG Training Loss:0.176 AVG Test Loss:0.346\n",
            "Epoch:2865/3000 AVG Training Loss:0.083 AVG Test Loss:0.149\n",
            "Epoch:2866/3000 AVG Training Loss:0.124 AVG Test Loss:0.436\n",
            "Epoch:2867/3000 AVG Training Loss:0.139 AVG Test Loss:0.080\n",
            "Epoch:2868/3000 AVG Training Loss:0.077 AVG Test Loss:0.100\n",
            "Epoch:2869/3000 AVG Training Loss:0.114 AVG Test Loss:0.181\n",
            "Epoch:2870/3000 AVG Training Loss:0.105 AVG Test Loss:0.255\n",
            "Epoch:2871/3000 AVG Training Loss:0.079 AVG Test Loss:0.167\n",
            "Epoch:2872/3000 AVG Training Loss:0.164 AVG Test Loss:0.051\n",
            "Epoch:2873/3000 AVG Training Loss:0.112 AVG Test Loss:0.230\n",
            "Epoch:2874/3000 AVG Training Loss:0.053 AVG Test Loss:0.079\n",
            "Epoch:2875/3000 AVG Training Loss:0.082 AVG Test Loss:0.089\n",
            "Epoch:2876/3000 AVG Training Loss:0.150 AVG Test Loss:0.273\n",
            "Epoch:2877/3000 AVG Training Loss:0.142 AVG Test Loss:0.059\n",
            "Epoch:2878/3000 AVG Training Loss:0.114 AVG Test Loss:0.132\n",
            "Epoch:2879/3000 AVG Training Loss:0.118 AVG Test Loss:0.203\n",
            "Epoch:2880/3000 AVG Training Loss:0.121 AVG Test Loss:0.333\n",
            "Epoch:2881/3000 AVG Training Loss:0.202 AVG Test Loss:0.172\n",
            "Epoch:2882/3000 AVG Training Loss:0.048 AVG Test Loss:0.341\n",
            "Epoch:2883/3000 AVG Training Loss:0.091 AVG Test Loss:0.040\n",
            "Epoch:2884/3000 AVG Training Loss:0.113 AVG Test Loss:0.112\n",
            "Epoch:2885/3000 AVG Training Loss:0.136 AVG Test Loss:0.542\n",
            "Epoch:2886/3000 AVG Training Loss:0.117 AVG Test Loss:0.214\n",
            "Epoch:2887/3000 AVG Training Loss:0.091 AVG Test Loss:0.120\n",
            "Epoch:2888/3000 AVG Training Loss:0.118 AVG Test Loss:0.160\n",
            "Epoch:2889/3000 AVG Training Loss:0.145 AVG Test Loss:0.020\n",
            "Epoch:2890/3000 AVG Training Loss:0.109 AVG Test Loss:0.299\n",
            "Epoch:2891/3000 AVG Training Loss:0.144 AVG Test Loss:0.194\n",
            "Epoch:2892/3000 AVG Training Loss:0.142 AVG Test Loss:0.084\n",
            "Epoch:2893/3000 AVG Training Loss:0.088 AVG Test Loss:0.083\n",
            "Epoch:2894/3000 AVG Training Loss:0.090 AVG Test Loss:0.012\n",
            "Epoch:2895/3000 AVG Training Loss:0.158 AVG Test Loss:0.188\n",
            "Epoch:2896/3000 AVG Training Loss:0.128 AVG Test Loss:0.362\n",
            "Epoch:2897/3000 AVG Training Loss:0.132 AVG Test Loss:0.045\n",
            "Epoch:2898/3000 AVG Training Loss:0.122 AVG Test Loss:0.309\n",
            "Epoch:2899/3000 AVG Training Loss:0.063 AVG Test Loss:0.287\n",
            "Epoch:2900/3000 AVG Training Loss:0.153 AVG Test Loss:0.126\n",
            "Epoch:2901/3000 AVG Training Loss:0.106 AVG Test Loss:0.395\n",
            "Epoch:2902/3000 AVG Training Loss:0.102 AVG Test Loss:0.415\n",
            "Epoch:2903/3000 AVG Training Loss:0.119 AVG Test Loss:0.141\n",
            "Epoch:2904/3000 AVG Training Loss:0.051 AVG Test Loss:0.119\n",
            "Epoch:2905/3000 AVG Training Loss:0.068 AVG Test Loss:0.061\n",
            "Epoch:2906/3000 AVG Training Loss:0.150 AVG Test Loss:0.333\n",
            "Epoch:2907/3000 AVG Training Loss:0.065 AVG Test Loss:0.081\n",
            "Epoch:2908/3000 AVG Training Loss:0.081 AVG Test Loss:0.168\n",
            "Epoch:2909/3000 AVG Training Loss:0.125 AVG Test Loss:0.313\n",
            "Epoch:2910/3000 AVG Training Loss:0.088 AVG Test Loss:0.037\n",
            "Epoch:2911/3000 AVG Training Loss:0.128 AVG Test Loss:0.084\n",
            "Epoch:2912/3000 AVG Training Loss:0.131 AVG Test Loss:0.086\n",
            "Epoch:2913/3000 AVG Training Loss:0.142 AVG Test Loss:0.109\n",
            "Epoch:2914/3000 AVG Training Loss:0.047 AVG Test Loss:0.049\n",
            "Epoch:2915/3000 AVG Training Loss:0.116 AVG Test Loss:0.389\n",
            "Epoch:2916/3000 AVG Training Loss:0.153 AVG Test Loss:0.105\n",
            "Epoch:2917/3000 AVG Training Loss:0.129 AVG Test Loss:0.200\n",
            "Epoch:2918/3000 AVG Training Loss:0.183 AVG Test Loss:0.061\n",
            "Epoch:2919/3000 AVG Training Loss:0.094 AVG Test Loss:0.203\n",
            "Epoch:2920/3000 AVG Training Loss:0.079 AVG Test Loss:0.142\n",
            "Epoch:2921/3000 AVG Training Loss:0.159 AVG Test Loss:0.301\n",
            "Epoch:2922/3000 AVG Training Loss:0.119 AVG Test Loss:0.085\n",
            "Epoch:2923/3000 AVG Training Loss:0.121 AVG Test Loss:0.226\n",
            "Epoch:2924/3000 AVG Training Loss:0.151 AVG Test Loss:0.232\n",
            "Epoch:2925/3000 AVG Training Loss:0.182 AVG Test Loss:0.128\n",
            "Epoch:2926/3000 AVG Training Loss:0.141 AVG Test Loss:0.194\n",
            "Epoch:2927/3000 AVG Training Loss:0.099 AVG Test Loss:0.203\n",
            "Epoch:2928/3000 AVG Training Loss:0.190 AVG Test Loss:0.429\n",
            "Epoch:2929/3000 AVG Training Loss:0.075 AVG Test Loss:0.126\n",
            "Epoch:2930/3000 AVG Training Loss:0.140 AVG Test Loss:0.245\n",
            "Epoch:2931/3000 AVG Training Loss:0.150 AVG Test Loss:0.077\n",
            "Epoch:2932/3000 AVG Training Loss:0.086 AVG Test Loss:0.227\n",
            "Epoch:2933/3000 AVG Training Loss:0.077 AVG Test Loss:0.063\n",
            "Epoch:2934/3000 AVG Training Loss:0.066 AVG Test Loss:0.066\n",
            "Epoch:2935/3000 AVG Training Loss:0.065 AVG Test Loss:0.015\n",
            "Epoch:2936/3000 AVG Training Loss:0.080 AVG Test Loss:0.238\n",
            "Epoch:2937/3000 AVG Training Loss:0.097 AVG Test Loss:0.263\n",
            "Epoch:2938/3000 AVG Training Loss:0.066 AVG Test Loss:0.080\n",
            "Epoch:2939/3000 AVG Training Loss:0.092 AVG Test Loss:0.164\n",
            "Epoch:2940/3000 AVG Training Loss:0.142 AVG Test Loss:0.277\n",
            "Epoch:2941/3000 AVG Training Loss:0.062 AVG Test Loss:0.205\n",
            "Epoch:2942/3000 AVG Training Loss:0.058 AVG Test Loss:0.108\n",
            "Epoch:2943/3000 AVG Training Loss:0.089 AVG Test Loss:0.058\n",
            "Epoch:2944/3000 AVG Training Loss:0.128 AVG Test Loss:0.309\n",
            "Epoch:2945/3000 AVG Training Loss:0.096 AVG Test Loss:0.176\n",
            "Epoch:2946/3000 AVG Training Loss:0.150 AVG Test Loss:0.128\n",
            "Epoch:2947/3000 AVG Training Loss:0.171 AVG Test Loss:0.192\n",
            "Epoch:2948/3000 AVG Training Loss:0.109 AVG Test Loss:0.065\n",
            "Epoch:2949/3000 AVG Training Loss:0.134 AVG Test Loss:0.370\n",
            "Epoch:2950/3000 AVG Training Loss:0.055 AVG Test Loss:0.206\n",
            "Epoch:2951/3000 AVG Training Loss:0.105 AVG Test Loss:0.022\n",
            "Epoch:2952/3000 AVG Training Loss:0.148 AVG Test Loss:0.183\n",
            "Epoch:2953/3000 AVG Training Loss:0.108 AVG Test Loss:0.022\n",
            "Epoch:2954/3000 AVG Training Loss:0.053 AVG Test Loss:0.059\n",
            "Epoch:2955/3000 AVG Training Loss:0.125 AVG Test Loss:0.196\n",
            "Epoch:2956/3000 AVG Training Loss:0.072 AVG Test Loss:0.069\n",
            "Epoch:2957/3000 AVG Training Loss:0.127 AVG Test Loss:0.188\n",
            "Epoch:2958/3000 AVG Training Loss:0.112 AVG Test Loss:0.157\n",
            "Epoch:2959/3000 AVG Training Loss:0.101 AVG Test Loss:0.027\n",
            "Epoch:2960/3000 AVG Training Loss:0.098 AVG Test Loss:0.041\n",
            "Epoch:2961/3000 AVG Training Loss:0.138 AVG Test Loss:0.193\n",
            "Epoch:2962/3000 AVG Training Loss:0.086 AVG Test Loss:0.291\n",
            "Epoch:2963/3000 AVG Training Loss:0.191 AVG Test Loss:0.297\n",
            "Epoch:2964/3000 AVG Training Loss:0.086 AVG Test Loss:0.082\n",
            "Epoch:2965/3000 AVG Training Loss:0.107 AVG Test Loss:0.202\n",
            "Epoch:2966/3000 AVG Training Loss:0.182 AVG Test Loss:0.057\n",
            "Epoch:2967/3000 AVG Training Loss:0.145 AVG Test Loss:0.267\n",
            "Epoch:2968/3000 AVG Training Loss:0.081 AVG Test Loss:0.029\n",
            "Epoch:2969/3000 AVG Training Loss:0.123 AVG Test Loss:0.269\n",
            "Epoch:2970/3000 AVG Training Loss:0.131 AVG Test Loss:0.098\n",
            "Epoch:2971/3000 AVG Training Loss:0.056 AVG Test Loss:0.087\n",
            "Epoch:2972/3000 AVG Training Loss:0.137 AVG Test Loss:0.061\n",
            "Epoch:2973/3000 AVG Training Loss:0.091 AVG Test Loss:0.064\n",
            "Epoch:2974/3000 AVG Training Loss:0.112 AVG Test Loss:0.087\n",
            "Epoch:2975/3000 AVG Training Loss:0.165 AVG Test Loss:0.116\n",
            "Epoch:2976/3000 AVG Training Loss:0.099 AVG Test Loss:0.409\n",
            "Epoch:2977/3000 AVG Training Loss:0.183 AVG Test Loss:0.180\n",
            "Epoch:2978/3000 AVG Training Loss:0.068 AVG Test Loss:0.244\n",
            "Epoch:2979/3000 AVG Training Loss:0.087 AVG Test Loss:0.108\n",
            "Epoch:2980/3000 AVG Training Loss:0.145 AVG Test Loss:0.155\n",
            "Epoch:2981/3000 AVG Training Loss:0.147 AVG Test Loss:0.222\n",
            "Epoch:2982/3000 AVG Training Loss:0.109 AVG Test Loss:0.259\n",
            "Epoch:2983/3000 AVG Training Loss:0.116 AVG Test Loss:0.126\n",
            "Epoch:2984/3000 AVG Training Loss:0.079 AVG Test Loss:0.050\n",
            "Epoch:2985/3000 AVG Training Loss:0.149 AVG Test Loss:0.214\n",
            "Epoch:2986/3000 AVG Training Loss:0.077 AVG Test Loss:0.031\n",
            "Epoch:2987/3000 AVG Training Loss:0.076 AVG Test Loss:0.285\n",
            "Epoch:2988/3000 AVG Training Loss:0.153 AVG Test Loss:0.251\n",
            "Epoch:2989/3000 AVG Training Loss:0.115 AVG Test Loss:0.155\n",
            "Epoch:2990/3000 AVG Training Loss:0.063 AVG Test Loss:0.112\n",
            "Epoch:2991/3000 AVG Training Loss:0.180 AVG Test Loss:0.112\n",
            "Epoch:2992/3000 AVG Training Loss:0.136 AVG Test Loss:0.138\n",
            "Epoch:2993/3000 AVG Training Loss:0.079 AVG Test Loss:0.123\n",
            "Epoch:2994/3000 AVG Training Loss:0.145 AVG Test Loss:0.272\n",
            "Epoch:2995/3000 AVG Training Loss:0.102 AVG Test Loss:0.263\n",
            "Epoch:2996/3000 AVG Training Loss:0.099 AVG Test Loss:0.125\n",
            "Epoch:2997/3000 AVG Training Loss:0.073 AVG Test Loss:0.065\n",
            "Epoch:2998/3000 AVG Training Loss:0.097 AVG Test Loss:0.128\n",
            "Epoch:2999/3000 AVG Training Loss:0.194 AVG Test Loss:0.080\n",
            "Epoch:3000/3000 AVG Training Loss:0.083 AVG Test Loss:0.159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_log = []\n",
        "val_loss_log = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  \n",
        "  train_loss_log.append((foldperf['fold1']['train_loss'][i] +\n",
        "                          foldperf['fold2']['train_loss'][i] +\n",
        "                          foldperf['fold3']['train_loss'][i] +\n",
        "                          foldperf['fold4']['train_loss'][i] +\n",
        "                          foldperf['fold5']['train_loss'][i]\n",
        "                          ) / 5)\n",
        "  \n",
        "  val_loss_log.append((foldperf['fold1']['test_loss'][i] +\n",
        "                          foldperf['fold2']['test_loss'][i] +\n",
        "                          foldperf['fold3']['test_loss'][i] +\n",
        "                          foldperf['fold4']['test_loss'][i] +\n",
        "                          foldperf['fold5']['test_loss'][i]\n",
        "                          ) / 5)"
      ],
      "metadata": {
        "id": "cM_qe2VD7Fag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.semilogy(train_loss_log, label='Train loss')\n",
        "plt.semilogy(val_loss_log, label='Validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "3ebJ9AlL5CUV",
        "outputId": "a9ba8d77-a7f0-46fc-d641-fe91e4f5dd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('regression_dataset/train_data.csv')\n",
        "test_df = pd.read_csv('regression_dataset/test_data.csv')\n",
        "all_data_df = pd.concat([train_df, test_df], axis=0)\n",
        "\n",
        "# Input vector\n",
        "x_vec = torch.linspace(-5,5,1000)\n",
        "x_vec = x_vec.to(device)\n",
        "x_vec = x_vec.unsqueeze(-1)  # Adding a dimension to the input vector\n",
        "print(f\"Input shape: {x_vec.shape}\")\n",
        "\n",
        "# Network output\n",
        "model.eval()\n",
        "with torch.no_grad(): # turn off gradients computation\n",
        "    y_vec = model(x_vec)\n",
        "\n",
        "# Convert x_vec and y_vec to numpy one dimensional arrays\n",
        "x_vec = x_vec.squeeze().cpu().numpy()\n",
        "y_vec = y_vec.squeeze().cpu().numpy()\n",
        "\n",
        "# Plot output\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(x_vec, y_vec, label='Network output')\n",
        "plt.scatter(all_data_df.input, all_data_df.label, label='All Data', color='red')\n",
        "#plt.plot(x_vec, true_model, label='True model')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "BKOXLC-qsvmL",
        "outputId": "3290b5e3-4b28-4785-8558-921f7eb84c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1000, 1])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}